{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscrapper import WebScraper\n",
    "import fitz\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the immediate parent folder of the current working directory\n",
    "parent_folder_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Construct the path to the .env file in the parent folder\n",
    "dotenv_path = os.path.join(parent_folder_path, \".env\")\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to extract answers from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa_from_pdf(pdf_path):\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Close the document\n",
    "    doc.close()\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    qa_dict = {}\n",
    "    current_speaker = None\n",
    "    current_message = []\n",
    "    first_user_statement = True\n",
    "    current_question = None\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == 'Assistant:':\n",
    "            if current_speaker == 'User' and not first_user_statement:\n",
    "                qa_dict[current_question] = ' '.join(current_message).strip()\n",
    "            current_speaker = 'Assistant'\n",
    "            current_message = []\n",
    "        elif line.strip() == 'User:':\n",
    "            if current_speaker == 'Assistant':\n",
    "                current_question = ' '.join(current_message).strip()\n",
    "            current_speaker = 'User'\n",
    "            current_message = []\n",
    "            if first_user_statement:\n",
    "                first_user_statement = False\n",
    "        elif line.strip():\n",
    "            current_message.append(line.strip())\n",
    "\n",
    "    # Handle the last message\n",
    "    if current_speaker == 'User' and not first_user_statement and current_question:\n",
    "        qa_dict[current_question] = ' '.join(current_message).strip()\n",
    "    qa_dict.pop(None,None)\n",
    "    return qa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Hello! Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. To start, could you tell me about your experience with machine learning, particularly any projects or coursework you've completed in this area?\": \"I'm sure I have a total of six months of experience with machine learning after I entered the University of Kent. Right now I'm mainly working on Numpy and Pandas. Numpy is to analyze image information and Pandas to extract data from CSVs.\",\n",
       " \"Thank you for sharing that information. Could you elaborate on a specific machine learning project you've worked on, perhaps one that involved Numpy or Pandas? What was the goal of the project, and what challenges did you face?\": \"I'm sure so one of the projects that I worked on was classifying the minst data set of images. Yeah basically it was done. I extracted the training set from the minst data, used a CNN algorithm to find out features from the images and then use the test set to predict the output of the model and it worked.\",\n",
       " 'I see. For your next project, have you considered working with any advanced optimization methods or modern ML techniques beyond CNNs? If so, which ones interest you and why?': 'Yes, so LLM seem to be the rage these days. I am trying or will be interested in working on fine-tuning an LLM model to my specific needs as a chatbot. But I have not thought of what the chatbot will do.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "pdf_path = 'conversation.pdf'\n",
    "qa_dictionary = extract_qa_from_pdf(pdf_path)\n",
    "qa_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Hello! Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. To start, could you tell me about your experience with machine learning, particularly any projects or coursework you've completed in this area?\n",
      "A: I'm sure I have a total of six months of experience with machine learning after I entered the University of Kent. Right now I'm mainly working on Numpy and Pandas. Numpy is to analyze image information and Pandas to extract data from CSVs.\n",
      "\n",
      "Q: Thank you for sharing that information. Could you elaborate on a specific machine learning project you've worked on, perhaps one that involved Numpy or Pandas? What was the goal of the project, and what challenges did you face?\n",
      "A: I'm sure so one of the projects that I worked on was classifying the minst data set of images. Yeah basically it was done. I extracted the training set from the minst data, used a CNN algorithm to find out features from the images and then use the test set to predict the output of the model and it worked.\n",
      "\n",
      "Q: I see. For your next project, have you considered working with any advanced optimization methods or modern ML techniques beyond CNNs? If so, which ones interest you and why?\n",
      "A: Yes, so LLM seem to be the rage these days. I am trying or will be interested in working on fine-tuning an LLM model to my specific needs as a chatbot. But I have not thought of what the chatbot will do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, answer in qa_dictionary.items():\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to Decompose asnwers to find relevant sites on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-queries related to an answer by an interview candidate. \\n\n",
    "You will be provided the original question for context. The goal is to find the accuracy of the answer. For this\n",
    "you will break down the answer into a set of sub-problems / sub-queries that can be used as a search string in google to find the relevant information. \\n\n",
    "Here is the original question: {question}\n",
    "Generate multiple search queries related to: {answer} \\n\n",
    "Output (2 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. \"University of Kent machine learning projects or coursework\"', '2. \"Numpy and Pandas usage in machine learning projects\"']\n",
      "['1. \"Classifying MNIST dataset images using CNN algorithm project details\"', '2. \"Challenges faced in implementing CNN algorithm for image classification project\"']\n",
      "['1. \"Fine-tuning LLM model for chatbot applications\"', '2. \"Applications of LLM models in chatbots\"']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://stackoverflow.com/questions/46242284/pandas-and-python-image-to-numpy-array'}, page_content='\\n\\n\\n\\n\\n\\n \\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\nStack Overflow\\n\\n\\n\\nAbout\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tProducts\\n\\t\\t\\t\\t\\t\\n\\n\\nOverflowAI\\n\\n\\n\\n\\n\\n\\n\\nStack Overflow for Teams\\nWhere developers & technologists share private knowledge with coworkers\\n\\n\\n\\n\\nAdvertising & Talent\\nReach devs & technologists worldwide about your product, service or employer brand\\n\\n\\n\\n\\nOverflowAI\\nGenAI features for Teams\\n\\n\\n\\n\\nOverflowAPI\\nTrain & fine-tune LLMs\\n\\n\\n\\n\\nLabs\\nThe future of collective knowledge sharing\\n\\n\\n\\nAbout the company\\nVisit the blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading…\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncurrent community\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Stack Overflow\\n        \\n\\n\\n\\nhelp\\nchat\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Meta Stack Overflow\\n        \\n\\n\\n\\n\\n\\n\\nyour communities            \\n\\n\\n\\nSign up or log in to customize your list.                \\n\\n\\nmore stack exchange communities\\n\\ncompany blog\\n\\n\\n\\n\\n\\n\\n\\n\\nLog in\\n\\nSign up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    The 2024 Developer Survey results are live!\\n                \\nSee the results\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Home\\n\\n\\n\\n\\n\\n\\n Questions\\n\\n\\n\\n\\n\\n\\n Tags\\n\\n\\n\\n\\n\\n\\n\\n Users\\n\\n\\n\\n\\n\\n\\n Companies\\n\\n\\n\\n\\n\\nLabs\\n\\n\\n\\n\\n\\n\\n\\n\\n Jobs\\n\\n\\n\\n\\n\\n\\n Discussions\\n\\n\\n\\n\\n\\n\\nCollectives\\n\\n\\n\\n\\n\\n\\n\\n\\n                                        Communities for your favorite technologies.  Explore all Collectives\\n\\n\\n\\n\\n\\nTeams\\n\\n\\n\\n\\n\\nNow available on Stack Overflow for Teams! AI features where you work: search, IDE, and chat.\\n        \\nLearn more\\nExplore Teams\\n\\n\\n\\n\\nTeams\\n\\n\\n\\n\\n\\n\\n\\n            Ask questions, find answers and collaborate at work with Stack Overflow for Teams.\\n            Explore Teams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCollectives™ on Stack Overflow\\nFind centralized, trusted content and collaborate around the technologies you use most.\\n\\n                    Learn more about Collectives\\n                \\n\\n\\n\\n\\n\\nTeams\\nQ&A for work\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n                    Learn more about Teams\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\nGet early access and see previews of new features.\\n Learn more about Labs\\n\\n\\n\\n\\n\\n\\n\\nPandas and Python image to numpy array [closed]\\n\\n\\n\\n        Ask Question\\n    \\n\\n\\n\\n\\n\\nAsked\\n6 years, 10 months ago\\n\\n\\nModified\\n6 years, 10 months ago\\n\\n\\nViewed\\n                        6k times\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            0\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClosed. This question needs to be more focused. It is not currently accepting answers.\\n                                \\n                            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWant to improve this question? Update the question so it focuses on one problem only by editing this post.\\n\\n\\nClosed 6 years ago.\\n\\n\\n\\n\\n\\n\\n\\n                        Improve this question\\n                    \\n\\n\\n\\nI\\'m currently teaching myself pandas and python for machine learning. I\\'ve done fine with text data thus far, but dealing with image data with limited knowledge of python and pandas is tripping me.\\nI have read in a .csv file into pandas dataframe, with one of its columns containing url to an image. So this is what shows when I get info from the dataframe.\\ndataframe = pandas.read_csv(\"./sample.csv\")\\ndataframe.info()\\n\\n<class \\'pandas.core.frame.DataFrame\\'>\\nRangeIndex:  5000 entries, 0 to 4999\\nData columns (total of 5 columns):\\nname          5000 non-null object\\n...\\nimage         5000 non-null object\\nthe image column contains url to the image. The problem is, I do not know how to import the image data from this and save it as numpy array for processing.\\nAny help is appreciated. Thanks in advance!\\n\\n\\n\\n\\npythonimagepandasnumpy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\nImprove this question\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            asked Sep 15, 2017 at 14:45\\n\\n\\n\\n\\n\\n\\nIshiro KusabiIshiro Kusabi\\n\\n21122 gold badges66 silver badges1313 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n4\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncan you post a snippet of the csv\\n\\n–\\xa0johnashu\\n\\n\\nCommented\\nSep 15, 2017 at 15:09\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWelcome to SO. Unfortunately this isn\\'t a code writing service. If you haven\\'t had the opportunity, please read How to Ask and minimal reproducible example.  With a little research and studying the Python documentation you should find tools to help you grab an image from the web with a url.  If you come up with a solution and get stuck, come back and ask.\\n\\n–\\xa0wwii\\n\\n\\nCommented\\nSep 15, 2017 at 15:13\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhich version of Python are you using? Are you using the DataFrame for other purposes or is it just an intermediate step to parse the csv file?\\n\\n–\\xa0wwii\\n\\n\\nCommented\\nSep 15, 2017 at 15:42\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\nThanks johnashu and wwii! I\\'ve read through the links, and I apologize that my question was vague and information insufficient. I will try my best to better ask questions next time. Thanks for taking the time to read through my question!\\n\\n–\\xa0Ishiro Kusabi\\n\\n\\nCommented\\nSep 15, 2017 at 15:52\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                        2 Answers\\n                                    2\\n\\n\\n\\n\\n\\n\\n            Sorted by:\\n        \\n\\n            Reset to default\\n        \\n\\n\\n\\n\\n                        Highest score (default)\\n                    \\n\\n                        Trending (recent votes count more)\\n                    \\n\\n                        Date modified (newest first)\\n                    \\n\\n                        Date created (oldest first)\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            1\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you want to download the images from the web and then, for example, rotate your images from your dataframe, and save the results you can use the following code:\\nimport pandas as pd\\nimport matplotlib.pylab as plt\\nimport numpy as np\\nfrom PIL import Image\\nimport urllib2 as urllib\\nimport io\\n\\ndf = pd.DataFrame({\\n\"name\": [\"Butterfly\", \"Birds\"],\\n\"image\": [\"https://upload.wikimedia.org/wikipedia/commons/0/0c/Two-tailed_pasha_%28Charaxes_jasius_jasius%29_Greece.jpg\",\\n                                 \\'https://upload.wikimedia.org/wikipedia/commons/c/c5/Bat_cave_in_El_Maviri_Sinaloa_-_Mexico.jpg\\']})\\n\\ndef rotate_image(image, theta):\\n    \"\"\"\\n    3D rotation matrix around the X-axis by angle theta\\n    \"\"\"\\n    rotation_matrix = np.c_[\\n        [1,0,0],\\n        [0,np.cos(theta),-np.sin(theta)],\\n        [0,np.sin(theta),np.cos(theta)]\\n    ]\\n    return np.einsum(\"ijk,lk->ijl\", image, rotation_matrix)\\n\\nfor i, imageUrl in enumerate(df.image):\\n    print imageUrl\\n    fd = urllib.urlopen(imageUrl)\\n    image_file = io.BytesIO(fd.read())\\n    im = Image.open(image_file)\\n    im_rotated = rotate_image(im, np.pi)\\n    fig = plt.figure()\\n    plt.imshow(im_rotated)\\n    plt.axis(\\'off\\')\\n    fig.savefig(df.name.ix[i] + \".jpg\")\\n\\nIf instead you want to show the pictures you can do:\\nplt.show()\\n\\nThe resulting pictures are birds and butterfly which can be seen here as well:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\nImprove this answer\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            answered Sep 15, 2017 at 16:16\\n\\n\\n\\n\\n\\n\\nCedric ZoppoloCedric Zoppolo\\n\\n4,62377 gold badges3131 silver badges6262 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThank you Cedirc! I used a different method but this one also worked well and seems to be a lot cleaner than my method! Have a good day. Thanks again.\\n\\n–\\xa0Ishiro Kusabi\\n\\n\\nCommented\\nSep 15, 2017 at 19:07\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            1\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAs we don\\'t know your csv-file, you have to tune your pd.read_csv() for your case.\\nHere i\\'m using requests to download some image in-memory.\\nThese are then decoded with the help of scipy (which you already should have; if not: you can use Pillow too).\\nThe decoded images are then raw numpy-arrays and shown by matplotlib.\\nKeep in mind, that we are not using temporary-files here and everything is hold in memory. Read also this (answer by jfs).\\nFor people missing some required libs, one should be able to do the same with (code needs to be changed of course):\\n\\nrequests can be replaced with urllib (standard lib)\\n\\n\\ni\\'m not showing code, but this SO-question should be a good start\\nanother relevant SO-question talking about in-memory processing with urllib\\n\\npandas can be replaced by csv (standard lib)\\nscipy can be replaced by Pillow (although internal storage might differ then)\\nmatplotlib is just for demo-purposes (not sure if Pillow allows showing images; edit: it seems it can)\\n\\nI just selected some random images from some german newspage.\\nEdit: Free images from wikipedia now used!\\nCode:\\nimport requests                 # downloading images\\nimport pandas as pd             # csv- / data-input\\nfrom scipy.misc import imread   # image-decoding -> numpy-array\\nimport matplotlib.pyplot as plt # only for demo / plotting\\n\\n# Fake data -> pandas DataFrame\\nurls_df = pd.DataFrame({\\'urls\\': [\\'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Rescue_exercise_RCA_2012.jpg/500px-Rescue_exercise_RCA_2012.jpg\\',\\n                                 \\'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Clinotarsus_curtipes-Aralam-2016-10-29-001.jpg/300px-Clinotarsus_curtipes-Aralam-2016-10-29-001.jpg\\',\\n                                 \\'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/US_Capitol_east_side.JPG/300px-US_Capitol_east_side.JPG\\']}) \\n\\n# Download & Decode\\nimgs = []\\nfor i in urls_df.urls:               # iterate over column / pandas Series\\n    r = requests.get(i, stream=True) # See link for stream=True!\\n    r.raw.decode_content = True      # Content-Encoding\\n    imgs.append(imread(r.raw))       # Decoding to numpy-array\\n\\n# imgs: list of numpy arrays with varying shapes of form (x, y, 3)\\n#     as we got 3-color channels\\n# Beware!: downloading png\\'s might result in a shape of (x, y, 4)\\n#     as some alpha-channel might be available\\n# For more options: https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html\\n\\n# Plot\\nf, arr = plt.subplots(len(imgs))\\nfor i in range(len(imgs)):\\n    arr[i].imshow(imgs[i])\\nplt.show()\\n\\nOutput:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\nImprove this answer\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nedited Sep 15, 2017 at 15:53\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            answered Sep 15, 2017 at 15:16\\n\\n\\n\\n\\n\\n\\nsaschasascha\\n\\n33.2k66 gold badges7575 silver badges114114 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThank you sascha! The decoding was really the part I needed help on. I am sorry the information was insufficient. I guess I\\'m currently at a stage where I don\\'t know what I don\\'t know so my questions ended up being vague. Thanks again for your help!\\n\\n–\\xa0Ishiro Kusabi\\n\\n\\nCommented\\nSep 15, 2017 at 15:47\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\nNot the answer you\\'re looking for? Browse other questions tagged pythonimagepandasnumpy or ask your own question.                                \\n\\n\\n\\n\\n\\n\\n\\n                            The Overflow Blog\\n                        \\n\\n\\n \\n\\nThis developer tool is 40 years old: can it be improved?\\n\\n\\n\\n\\n \\n\\nUnpacking the 2024 Developer Survey results\\n\\n\\n\\n                            Featured on Meta\\n                        \\n\\n\\n \\n\\nAnnouncing a change to the data-dump process\\n\\n\\n\\n\\n \\n\\nWe\\'ve made changes to our Terms of Service & Privacy Policy - July 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nLinked\\n\\n\\n\\n221\\n\\nDownloading a picture via urllib and python\\n\\n\\n\\n41\\n\\nDownload and decompress gzipped file in memory?\\n\\n\\n\\n36\\n\\nPython - Download File Using Requests, Directly to Memory\\n\\n\\n\\n17\\n\\nHow can I display an image using Pillow?\\n\\n\\n\\n\\nRelated\\n\\n\\n\\n12956\\n\\nWhat does the \"yield\" keyword do in Python?\\n\\n\\n\\n7963\\n\\nDoes Python have a ternary conditional operator?\\n\\n\\n\\n7411\\n\\nWhat are metaclasses in Python?\\n\\n\\n\\n4141\\n\\nHow can I iterate over rows in a Pandas DataFrame?\\n\\n\\n\\n6991\\n\\nHow do I merge two dictionaries in a single expression in Python?\\n\\n\\n\\n4690\\n\\nWhat is the difference between @staticmethod and @classmethod in Python?\\n\\n\\n\\n2999\\n\\nRenaming column names in Pandas\\n\\n\\n\\n4617\\n\\nHow slicing in Python works\\n\\n\\n\\n5709\\n\\nHow do I create a directory, and any missing parent directories?\\n\\n\\n\\n2270\\n\\nDelete a column from a Pandas DataFrame\\n\\n\\n\\n\\n\\n\\n\\n            Hot Network Questions\\n        \\n\\n\\n\\n\\n                    1 John 4:9, \"God sent His ONLY begotten Son into the world.\" Jesus is the Son in the exclusive sense. Would this mean the Son has His Father\\'s nature?\\n                \\n\\n\\n\\n                    PhD in computational mathematics without a strong mathematical background\\n                \\n\\n\\n\\n                    What\\'s the difference between \"Model detail\" and \"Texture detail\" in Portal 1?\\n                \\n\\n\\n\\n                    What\\'s wrong with constructions like \"Dragons are big, green, and eat people.\"?\\n                \\n\\n\\n\\n                    What do the words \"tenant\" and \"ponies\" in US mean?\\n                \\n\\n\\n\\n                    How to extract pipe remnant from ground sleeve?\\n                \\n\\n\\n\\n                    Vscode how to remove Incoming/Outgoing changes graph\\n                \\n\\n\\n\\n                    What purpose did the lower-right \"Enter\" key serve on the original Mac 128k keyboard?\\n                \\n\\n\\n\\n                    On what basis does a paper get accepted into a top journal?\\n                \\n\\n\\n\\n                    Why would radio-capable transhumans still vocalise to each-other?\\n                \\n\\n\\n\\n                    Had this attempt to salvage naïve comprehension been studied before?\\n                \\n\\n\\n\\n                    Why do many CVT cars appear to index gears during normal automatic operation?\\n                \\n\\n\\n\\n                    Cubic Concatenation\\n                \\n\\n\\n\\n                    Finitely generated group that is not finitely presented\\n                \\n\\n\\n\\n                    What is the scriptural basis for the claim that Siva was a devotee of Vishnu?\\n                \\n\\n\\n\\n                    Can I add a PCIe card to a motherboard without rebooting, safely?\\n                \\n\\n\\n\\n                    Is leveling this ground and removing plastic by the side of my house a bad idea?\\n                \\n\\n\\n\\n                    Why doesn\\'t Gordon Freeman help the survivors?\\n                \\n\\n\\n\\n                    How could an earth-like planet accumulate Krypton in its atmosphere (beyond trace amounts)\\n                \\n\\n\\n\\n                    Why is There a Spelling Shift in the Stem of Verb \"reperire\"?\\n                \\n\\n\\n\\n                    Alignment of multi-line footnotes with margin\\n                \\n\\n\\n\\n                    Boundedness of sum of sin(sin(n))\\n                \\n\\n\\n\\n                    No room for radials\\n                \\n\\n\\n\\n                    Why is transfer of heat very slow as compared to transfer of sound in solids?\\n                \\n\\n\\n\\n            more hot questions\\n        \\n\\n\\n\\n\\nlang-py\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStack Overflow\\n\\nQuestions\\nHelp\\nChat\\n\\n\\n\\nProducts\\n\\nTeams\\nAdvertising\\nCollectives\\nTalent\\n\\n\\n\\nCompany\\n\\nAbout\\nPress\\nWork Here\\nLegal\\nPrivacy Policy\\nTerms of Service\\nContact Us\\nCookie Settings\\nCookie Policy\\n\\n\\n\\n\\nStack Exchange Network\\n\\n\\n\\n                                    Technology\\n                                \\n\\n\\n\\n                                    Culture & recreation\\n                                \\n\\n\\n\\n                                    Life & arts\\n                                \\n\\n\\n\\n                                    Science\\n                                \\n\\n\\n\\n                                    Professional\\n                                \\n\\n\\n\\n                                    Business\\n                                \\n\\n\\n\\n                                    API\\n                                \\n\\n\\n\\n                                    Data\\n                                \\n\\n\\n\\n\\n\\n\\n\\nBlog\\nFacebook\\nTwitter\\nLinkedIn\\nInstagram\\n\\n\\nSite design / logo © 2024 Stack Exchange Inc; user contributions licensed under CC BY-SA.                    rev\\xa02024.8.6.13652\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://github.com/datacamp/courses-introduction-to-python/blob/master/chapter4.md'}, page_content='\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation Menu\\n\\nToggle navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n            Sign in\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n        Product\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nActions\\n        Automate any workflow\\n      \\n\\n\\n\\n\\n\\n\\n\\nPackages\\n        Host and manage packages\\n      \\n\\n\\n\\n\\n\\n\\n\\nSecurity\\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\nCodespaces\\n        Instant dev environments\\n      \\n\\n\\n\\n\\n\\n\\n\\nGitHub Copilot\\n        Write better code with AI\\n      \\n\\n\\n\\n\\n\\n\\n\\nCode review\\n        Manage code changes\\n      \\n\\n\\n\\n\\n\\n\\n\\nIssues\\n        Plan and track work\\n      \\n\\n\\n\\n\\n\\n\\n\\nDiscussions\\n        Collaborate outside of code\\n      \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      All features\\n\\n    \\n\\n\\n\\n      Documentation\\n\\n    \\n\\n\\n\\n\\n\\n      GitHub Skills\\n\\n    \\n\\n\\n\\n\\n\\n      Blog\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Solutions\\n        \\n\\n\\n\\n\\n\\nBy size\\n\\n\\n\\n      Enterprise\\n\\n    \\n\\n\\n\\n      Teams\\n\\n    \\n\\n\\n\\n      Startups\\n\\n    \\n\\n\\n\\n\\nBy industry\\n\\n\\n\\n      Healthcare\\n\\n    \\n\\n\\n\\n      Financial services\\n\\n    \\n\\n\\n\\n      Manufacturing\\n\\n    \\n\\n\\n\\n\\nBy use case\\n\\n\\n\\n      CI/CD & Automation\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      DevSecOps\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n        Resources\\n        \\n\\n\\n\\n\\n\\nTopics\\n\\n\\n\\n      AI\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      Security\\n\\n    \\n\\n\\n\\n      Software Development\\n\\n    \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      Learning Pathways\\n\\n    \\n\\n\\n\\n\\n\\n      White papers, Ebooks, Webinars\\n\\n    \\n\\n\\n\\n\\n\\n      Customer Stories\\n\\n    \\n\\n\\n\\n      Partners\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Open Source\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub Sponsors\\n        Fund open source developers\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\nThe ReadME Project\\n        GitHub community articles\\n      \\n\\n\\n\\n\\nRepositories\\n\\n\\n\\n      Topics\\n\\n    \\n\\n\\n\\n      Trending\\n\\n    \\n\\n\\n\\n      Collections\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n        Enterprise\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEnterprise platform\\n        AI-powered developer platform\\n      \\n\\n\\n\\n\\nAvailable add-ons\\n\\n\\n\\n\\n\\n\\n\\nAdvanced Security\\n        Enterprise-grade security features\\n      \\n\\n\\n\\n\\n\\n\\n\\nGitHub Copilot\\n        Enterprise-grade AI features\\n      \\n\\n\\n\\n\\n\\n\\n\\nPremium Support\\n        Enterprise-grade 24/7 support\\n      \\n\\n\\n\\n\\n\\n\\nPricing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch or jump to...\\n\\n\\n\\n\\n\\n\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\n \\n\\n\\n\\n\\n        Search\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClear\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n              Search syntax tips\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Provide feedback\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nWe read every piece of feedback, and take your input very seriously.\\n\\n\\nInclude my email address so I can be contacted\\n\\n\\n     Cancel\\n\\n    Submit feedback\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Saved searches\\n      \\nUse saved searches to filter your results more quickly\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\nQuery\\n\\n\\n\\n            To see all available qualifiers, see our documentation.\\n          \\n \\n\\n\\n\\n\\n\\n     Cancel\\n\\n    Create saved search\\n\\n\\n\\n\\n\\n\\n\\n\\n                Sign in\\n              \\n\\n\\n                Sign up\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\n \\n\\n\\nDismiss alert\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        datacamp\\n \\n/\\n\\ncourses-introduction-to-python\\n\\nPublic\\n\\n\\n\\n\\n\\n \\n\\nNotifications\\n You must be signed in to change notification settings\\n\\n\\n \\n\\nFork\\n    264\\n\\n\\n\\n\\n \\n\\n\\n          Star\\n 409\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\n\\n\\n\\nIssues\\n3\\n\\n\\n\\n\\n\\n\\nPull requests\\n0\\n\\n\\n\\n\\n\\n\\nActions\\n\\n\\n\\n\\n\\n\\n\\nProjects\\n0\\n\\n\\n\\n\\n\\n\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\nInsights\\n\\n\\n\\n \\n\\n \\n\\n\\nAdditional navigation options\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Code\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Issues\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Pull requests\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Actions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Projects\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Security\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Insights\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n   Files\\xa0masterBreadcrumbscourses-introduction-to-python/chapter4.md Blame  Blame        Latest commit\\xa0HistoryHistory871 lines (638 loc) · 25.4 KB\\xa0masterBreadcrumbscourses-introduction-to-python/chapter4.mdTopFile metadata and controlsPreviewCodeBlame871 lines (638 loc) · 25.4 KBRaw\\n\\n\\ntitle_meta\\ntitle\\ndescription\\nattachments\\nlessons\\n\\n\\n\\n\\nChapter 4\\nNumPy\\nNumPy is a fundamental Python package to efficiently practice data science. Learn to work with powerful tools in the NumPy array, and get started with data exploration.\\n\\n\\n\\nslides_link\\n\\n\\n\\n\\nhttps://projector-video-pdf-converter.datacamp.com/735/chapter4.pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnb_of_exercises\\ntitle\\n\\n\\n\\n\\n5\\nNumpy\\n\\n\\n\\n\\n\\n\\n\\nnb_of_exercises\\ntitle\\n\\n\\n\\n\\n5\\n2D Numpy Arrays\\n\\n\\n\\n\\n\\n\\n\\nnb_of_exercises\\ntitle\\n\\n\\n\\n\\n3\\nNumpy: Basic Statistics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNumPy\\ntype: VideoExercise\\nkey: f4545baa53\\nxp: 50\\n@projector_key\\na0487c26210f6b71ea98f917734cea3a\\n\\nYour First NumPy Array\\ntype: NormalExercise\\nkey: 84cab9d170\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nYou\\'re now going to dive into the world of baseball. Along the way, you\\'ll get comfortable with the basics of numpy, a powerful package to do data science.\\nA list baseball has already been defined in the Python script, representing the height of some baseball players in centimeters. Can you add some code to create a numpy array from it?\\n@instructions\\n\\nImport the numpy package as np, so that you can refer to numpy with np.\\nUse np.array() to create a numpy array from baseball. Name this array np_baseball.\\nPrint out the type of np_baseball to check that you got it right.\\n\\n@hint\\n\\nimport numpy as np will do the trick. Now, you have to use np.fun_name() whenever you want to use a numpy function.\\nnp.array() should take on input baseball. Assign the result of the function call to np_baseball.\\nTo print out the type of a variable x, simply type print(type(x)).\\n\\n@pre_exercise_code\\nimport numpy as np\\n\\n@sample_code\\n# Import the numpy package as np\\n\\n\\nbaseball = [180, 215, 210, 210, 188, 176, 209, 200]\\n\\n# Create a numpy array from baseball: np_baseball\\n\\n\\n# Print out type of np_baseball\\n\\n\\n@solution\\n# Import the numpy package as np\\nimport numpy as np\\n\\nbaseball = [180, 215, 210, 210, 188, 176, 209, 200]\\n\\n# Create a NumPy array from baseball: np_baseball\\nnp_baseball = np.array(baseball)\\n\\n# Print out type of np_baseball\\nprint(type(np_baseball))\\n\\n@sct\\npredef_msg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().has_import(\"numpy\")\\nEx().check_correct(\\n  check_object(\"np_baseball\"),\\n  multi(\\n    check_object(\"baseball\", missing_msg=predef_msg).has_equal_value(incorrect_msg=predef_msg),\\n    check_function(\"numpy.array\").check_args(0).has_equal_ast()\\n  )\\n)\\n\\nEx().has_printout(0)\\nsuccess_msg(\"Great job!\")\\n\\n\\nBaseball players\\' height\\ntype: NormalExercise\\nkey: e7e25a89ea\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nYou are a huge baseball fan. You decide to call the MLB (Major League Baseball) and ask around for some more statistics on the height of the main players. They pass along data on more than a thousand players, which is stored as a regular Python list: height_in. The height is expressed in inches. Can you make a numpy array out of it and convert the units to meters?\\nheight_in is already available and the numpy package is loaded, so you can start straight away (Source: stat.ucla.edu).\\n@instructions\\n\\nCreate a numpy array from height_in. Name this new array np_height_in.\\nPrint np_height_in.\\nMultiply np_height_in with 0.0254 to convert all height measurements from inches to meters. Store the new values in a new array, np_height_m.\\nPrint out np_height_m and check if the output makes sense.\\n\\n@hint\\n\\nUse np.array() and pass it height. Store the result in np_height_in.\\nTo print out a variable x, type print(x) in the Python script.\\nPerform calculations as if np_height_in is a single number: np_height_in * conversion_factor is part of the answer.\\nTo print out a variable x, type print(x) in the Python script.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nmlb = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")\\nheight_in = mlb[\\'Height\\'].tolist()\\nimport numpy as np\\n\\n@sample_code\\n# Import numpy\\nimport numpy as np\\n\\n# Create a numpy array from height_in: np_height_in\\n\\n\\n# Print out np_height_in\\n\\n\\n# Convert np_height_in to m: np_height_m\\n\\n\\n# Print np_height_m\\n\\n\\n@solution\\n# Import numpy\\nimport numpy as np\\n\\n# Create a numpy array from height_in: np_height_in\\nnp_height_in = np.array(height_in)\\n\\n# Print out np_height_in\\nprint(np_height_in)\\n\\n# Convert np_height_in to m: np_height_m\\nnp_height_m = np_height_in * 0.0254\\n\\n# Print np_height_m\\nprint(np_height_m)\\n\\n@sct\\nEx().has_import(\"numpy\", same_as = False)\\n\\nEx().check_correct(\\n  has_printout(0),\\n  check_correct(\\n    check_object(\\'np_height_in\\').has_equal_value(),\\n    check_function(\\'numpy.array\\').check_args(0).has_equal_ast()\\n  )\\n)\\n\\nEx().check_correct(\\n  has_printout(1),\\n  check_object(\"np_height_m\").has_equal_value(incorrect_msg = \"Use `np_height_in * 0.0254` to calculate `np_height_m`.\")\\n)\\n\\nsuccess_msg(\"Nice! In the blink of an eye, `numpy` performs multiplications on more than 1000 height measurements.\")\\n\\n\\nNumPy Side Effects\\ntype: MultipleChoiceExercise\\nkey: 3662ff6637\\nlang: python\\nxp: 50\\nskills:\\n  - 2\\nnumpy is great for doing vector arithmetic. If you compare its functionality with regular Python lists, however, some things have changed.\\nFirst of all, numpy arrays cannot contain elements with different types.\\nSecond, the typical arithmetic operators, such as +, -, * and / have a different meaning for regular Python lists and numpy arrays.\\nSome lines of code have been provided for you. Try these out and select the one that would match this:\\nnp.array([True, 1, 2]) + np.array([3, 4, False])\\n\\nThe numpy package is already imported as np.\\n@possible_answers\\n\\nnp.array([True, 1, 2, 3, 4, False])\\nnp.array([4, 3, 0]) + np.array([0, 2, 2])\\nnp.array([1, 1, 2]) + np.array([3, 4, -1])\\nnp.array([0, 1, 2, 3, 4, 5])\\n\\n@hint\\n\\nCopy the different code chunks and paste them in the IPython Shell. Hit enter to run the code and see which output matches the one generated by np.array([True, 1, 2]) + np.array([3, 4, False]).\\n\\n@pre_exercise_code\\nimport numpy as np\\n\\n@sct\\nmsg1 = msg3 = msg4 = \"Incorrect. Try out the different code chunks and see which one matches the target code chunk.\"\\nmsg2 = \"Great job! `True` is converted to 1, `False` is converted to 0.\"\\nEx().has_chosen(2, [msg1, msg2, msg3, msg4])\\n\\n\\nSubsetting NumPy Arrays\\ntype: NormalExercise\\nkey: fcb2a9007b\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nSubsetting (using the square bracket notation on lists or arrays) works exactly the same with both lists and arrays.\\nThis exercise already has two lists, height_in and weight_lb, loaded in the background for you. These contain the height and weight of the MLB players as regular lists. It also has two numpy array lists, np_weight_lb and np_height_in prepared for you.\\n@instructions\\n\\nSubset np_weight_lb by printing out the element at index 50.\\nPrint out a sub-array of np_height_in that contains the elements at index 100 up to and including index 110.\\n\\n@hint\\n\\nMake sure to wrap a print() call around your subsetting operations.\\nUse [100:111] to get the elements from index 100 up to and including index 110.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nmlb = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")\\nheight_in = mlb[\\'Height\\'].tolist()\\nweight_lb = mlb[\\'Weight\\'].tolist()\\n\\n@sample_code\\nimport numpy as np\\n\\nnp_weight_lb = np.array(weight_lb)\\nnp_height_in = np.array(height_in)\\n\\n# Print out the weight at index 50\\n\\n\\n# Print out sub-array of np_height_in: index 100 up to and including index 110\\n\\n\\n@solution\\nimport numpy as np\\n\\nnp_weight_lb = np.array(weight_lb)\\nnp_height_in = np.array(height_in)\\n\\n# Print out the weight at index 50\\nprint(np_weight_lb[50])\\n\\n# Print out sub-array of np_height_in: index 100 up to and including index 110\\nprint(np_height_in[100:111])\\n\\n@sct\\nEx().has_import(\"numpy\", same_as=False)\\nmsg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().multi(\\n    check_object(\"np_height_in\", missing_msg=msg).has_equal_value(incorrect_msg = msg),\\n    check_object(\"np_weight_lb\", missing_msg=msg).has_equal_value(incorrect_msg = msg)\\n)\\n\\nEx().has_printout(0)\\nEx().has_printout(1)\\n\\nsuccess_msg(\"Nice! Time to learn something new: 2D NumPy arrays!\")\\n\\n\\n2D NumPy Arrays\\ntype: VideoExercise\\nkey: 1241efac7a\\nxp: 50\\n@projector_key\\nae3238dcc7feb9adecfee0c395fc8dc8\\n\\nYour First 2D NumPy Array\\ntype: NormalExercise\\nkey: 5cb045bb13\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nBefore working on the actual MLB data, let\\'s try to create a 2D numpy array from a small list of lists.\\nIn this exercise, baseball is a list of lists. The main list contains 4 elements. Each of these elements is a list containing the height and the weight of 4 baseball players, in this order. baseball is already coded for you in the script.\\n@instructions\\n\\nUse np.array() to create a 2D numpy array from baseball. Name it np_baseball.\\nPrint out the type of np_baseball.\\nPrint out the shape attribute of np_baseball. Use np_baseball.shape.\\n\\n@hint\\n\\nbaseball is already coded for you in the script. Call np.array() on it and store the resulting 2D numpy array in np_baseball.\\nUse print() in combination with type() for the second instruction.\\nnp_baseball.shape will give you the dimensions of the np_baseball. Make sure to wrap a print() call around it.\\n\\n@pre_exercise_code\\n\\n\\n@sample_code\\nimport numpy as np\\n\\nbaseball = [[180, 78.4],\\n            [215, 102.7],\\n            [210, 98.5],\\n            [188, 75.2]]\\n\\n# Create a 2D numpy array from baseball: np_baseball\\n\\n\\n# Print out the type of np_baseball\\n\\n\\n# Print out the shape of np_baseball\\n\\n\\n@solution\\nimport numpy as np\\n\\nbaseball = [[180, 78.4],\\n            [215, 102.7],\\n            [210, 98.5],\\n            [188, 75.2]]\\n\\n# Create a 2D numpy array from baseball: np_baseball\\nnp_baseball = np.array(baseball)\\n\\n# Print out the type of np_baseball\\nprint(type(np_baseball))\\n\\n# Print out the shape of np_baseball\\nprint(np_baseball.shape)\\n\\n@sct\\nmsg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().check_object(\"baseball\", missing_msg=msg).has_equal_value(incorrect_msg = msg)\\nEx().has_import(\"numpy\", same_as = False)\\n\\nEx().check_correct(\\n    multi(\\n        has_printout(0),\\n        has_printout(1)\\n    ),\\n    check_correct(\\n        check_object(\\'np_baseball\\').has_equal_value(),\\n        check_function(\\'numpy.array\\').check_args(0).has_equal_ast()\\n    )\\n)\\n\\nsuccess_msg(\"Great! You\\'re ready to convert the actual MLB data to a 2D `numpy` array now!\")\\n\\n\\nBaseball data in 2D form\\ntype: NormalExercise\\nkey: 5df25d0b7b\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nYou realize that it makes more sense to restructure all this information in a 2D numpy array.\\nYou have a Python list of lists. In this list of lists, each sublist represents the height and weight of a single baseball player. The name of this list is baseball and it has been loaded for you already (although you can\\'t see it).\\nStore the data as a 2D array to unlock numpy\\'s extra functionality.\\n@instructions\\n\\nUse np.array() to create a 2D numpy array from baseball. Name it np_baseball.\\nPrint out the shape attribute of np_baseball.\\n\\n@hint\\n\\nbaseball is already available in the Python environment. Call np.array() on it and store the resulting 2D numpy array in np_baseball.\\nnp_baseball.shape will give the dimensions of the np_baseball. Make sure to wrap a print()call around it.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nbaseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\']].to_numpy().tolist()\\nimport numpy as np\\n\\n@sample_code\\nimport numpy as np\\n\\n# Create a 2D numpy array from baseball: np_baseball\\nnp_baseball = \\n\\n# Print out the shape of np_baseball\\n\\n\\n@solution\\nimport numpy as np\\n\\n# Create a 2D numpy array from baseball: np_baseball\\nnp_baseball = np.array(baseball)\\n\\n# Print out the shape of np_baseball\\nprint(np_baseball.shape)\\n\\n@sct\\nEx().has_import(\"numpy\", same_as = False)\\n\\nEx().check_correct(\\n    has_printout(0),\\n    check_correct(\\n        check_object(\\'np_baseball\\').has_equal_value(),\\n        check_function(\\'numpy.array\\').check_args(0).has_equal_ast()\\n    )\\n)\\n\\nsuccess_msg(\"Slick! Time to show off some killer features of multi-dimensional `numpy` arrays!\")\\n\\n\\nSubsetting 2D NumPy Arrays\\ntype: NormalExercise\\nkey: aeca4977f0\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nIf your 2D numpy array has a regular structure, i.e. each row and column has a fixed number of values, complicated ways of subsetting become very easy. Have a look at the code below where the elements \"a\" and \"c\" are extracted from a list of lists.\\n# numpy\\nimport numpy as np\\nnp_x = np.array(x)\\nnp_x[:, 0]\\n\\nThe indexes before the comma refer to the rows, while those after the comma refer to the columns. The : is for slicing; in this example, it tells Python to include all rows.\\n@instructions\\n\\nPrint out the 50th row of np_baseball.\\nMake a new variable, np_weight_lb, containing the entire second column of np_baseball.\\nSelect the height (first column) of the 124th baseball player in np_baseball and print it out.\\n\\n@hint\\n\\nYou need row index 49 in the first instruction! More specifically, you\\'ll want to use [49, :].\\nTo select the entire second column, you\\'ll need [:, 1].\\nFor the last instruction, use [123, 0]; don\\'t forget to wrap it all in a print() statement.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nbaseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\']].to_numpy().tolist()\\nimport numpy as np\\n\\n@sample_code\\nimport numpy as np\\n\\nnp_baseball = np.array(baseball)\\n\\n# Print out the 50th row of np_baseball\\n\\n\\n# Select the entire second column of np_baseball: np_weight_lb\\n\\n\\n# Print out height of 124th player\\n\\n\\n@solution\\nimport numpy as np\\n\\nnp_baseball = np.array(baseball)\\n\\n# Print out the 50th row of np_baseball\\nprint(np_baseball[49,:])\\n\\n# Select the entire second column of np_baseball: np_weight_lb\\nnp_weight_lb = np_baseball[:,1]\\n\\n# Print out height of 124th player\\nprint(np_baseball[123, 0])\\n\\n@sct\\nmsg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().multi(\\n    has_import(\"numpy\", same_as = False),\\n    check_object(\"np_baseball\", missing_msg=msg).has_equal_value(incorrect_msg = msg)\\n)\\n\\nEx().has_printout(0)\\n\\nEx().check_object(\\'np_weight_lb\\').has_equal_value(incorrect_msg = \"You can use `np_baseball[:,1]` to define `np_weight_lb`. This will select the entire first column.\")\\n\\nEx().has_printout(1)\\n\\nsuccess_msg(\"This is going well!\")\\n\\n\\n2D Arithmetic\\ntype: NormalExercise\\nkey: 1c2378b677\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\n2D numpy arrays can perform calculations element by element, like numpy arrays.\\nnp_baseball is coded for you; it\\'s again a 2D numpy array with 3 columns representing height (in inches), weight (in pounds) and age (in years). baseball is available as a regular list of lists and updated is available as 2D numpy array.\\n@instructions\\n\\nYou managed to get hold of the changes in height, weight and age of all baseball players. It is available as a 2D numpy array, updated. Add np_baseball and updated and print out the result.\\nYou want to convert the units of height and weight to metric (meters and kilograms, respectively). As a first step, create a numpy array with three values: 0.0254, 0.453592 and 1. Name this array conversion.\\nMultiply np_baseball with conversion and print out the result.\\n\\n@hint\\n\\nnp_baseball + updated will do an element-wise summation of the two numpy arrays.\\nCreate a numpy array with np.array(); the input is a regular Python list with three elements.\\nnp_baseball * conversion will work, without extra work. Try out it! Make sure to wrap it in a print() call.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nimport numpy as np\\nbaseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\', \\'Age\\']].to_numpy().tolist()\\nn = len(baseball)\\nupdated = np.array(pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/update.csv\", header = None))\\nimport numpy as np\\n\\n@sample_code\\nimport numpy as np\\n\\nnp_baseball = np.array(baseball)\\n\\n# Print out addition of np_baseball and updated\\n\\n\\n# Create numpy array: conversion\\n\\n\\n# Print out product of np_baseball and conversion\\n\\n\\n@solution\\nimport numpy as np\\n\\nnp_baseball = np.array(baseball)\\n\\n# Print out addition of np_baseball and updated\\nprint(np_baseball + updated)\\n\\n# Create numpy array: conversion\\nconversion = np.array([0.0254, 0.453592, 1])\\n\\n# Print out product of np_baseball and conversion\\nprint(np_baseball * conversion)\\n\\n@sct\\nEx().has_import(\"numpy\")\\n\\nmsg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().check_object(\"np_baseball\", missing_msg=msg).has_equal_value(incorrect_msg = msg)\\n\\nEx().has_printout(0)\\n\\nEx().check_correct(\\n    has_printout(1),\\n    check_correct(\\n        check_object(\\'conversion\\').has_equal_value(),\\n        check_function(\\'numpy.array\\', index = 1).check_args(0).has_equal_value()\\n    )    \\n)\\n\\nsuccess_msg(\"Great job! Notice how with very little code, you can change all values in your `numpy` data structure in a very specific way. This will be very useful in your future as a data scientist!\")\\n\\n\\nNumPy: Basic Statistics\\ntype: VideoExercise\\nkey: 287995e488\\nxp: 50\\n@projector_key\\n34495ba457d74296794d2a122c9b6e19\\n\\nAverage versus median\\ntype: NormalExercise\\nkey: 509c588eb6\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nYou now know how to use numpy functions to get a better feeling for your data.\\nThe baseball data is available as a 2D numpy array with 3 columns (height, weight, age) and 1015 rows. The name of this numpy array is np_baseball. After restructuring the data, however, you notice that some height values are abnormally high. Follow the instructions and discover which summary statistic is best suited if you\\'re dealing with so-called outliers. np_baseball is available.\\n@instructions\\n\\nCreate numpy array np_height_in that is equal to first column of np_baseball.\\nPrint out the mean of np_height_in.\\nPrint out the median of np_height_in.\\n\\n@hint\\n\\nUse 2D numpy subsetting: [:,0] is a part of the solution.\\nIf numpy is imported as np, you can use np.mean() to get the mean of a NumPy array. Don\\'t forget to throw in a print() call.\\nFor the last instruction, use np.median().\\n\\n@pre_exercise_code\\nimport pandas as pd\\nnp_baseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\', \\'Age\\']].to_numpy()\\nnp_baseball[slice(0, 1015, 50), 0] = np_baseball[slice(0, 1015, 50), 0]*1000\\nimport numpy as np\\n\\n@sample_code\\nimport numpy as np\\n\\n# Create np_height_in from np_baseball\\n\\n\\n# Print out the mean of np_height_in\\n\\n\\n# Print out the median of np_height_in\\n\\n\\n@solution\\nimport numpy as np\\n\\n# Create np_height_in from np_baseball\\nnp_height_in = np_baseball[:,0]\\n\\n# Print out the mean of np_height_in\\nprint(np.mean(np_height_in))\\n\\n# Print out the median of np_height_in\\nprint(np.median(np_height_in))\\n\\n@sct\\nEx().has_import(\"numpy\", same_as = False)\\n\\nEx().check_object(\"np_height_in\").has_equal_value(incorrect_msg = \"You can use `np_baseball[:,0]` to select the first column from `np_baseball`\"),\\n\\nEx().check_correct(\\n    has_printout(0),\\n    check_function(\\'numpy.mean\\').has_equal_value()\\n)\\n\\nEx().check_correct(\\n    has_printout(1),\\n    check_function(\\'numpy.median\\').has_equal_value()\\n)\\n\\nsuccess_msg(\"An average height of 1586 inches, that doesn\\'t sound right, does it? However, the median does not seem affected by the outliers: 74 inches makes perfect sense. It\\'s always a good idea to check both the median and the mean, to get an idea about the overall distribution of the entire dataset.\")\\n\\n\\nExplore the baseball data\\ntype: NormalExercise\\nkey: \\'4409948807\\'\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nBecause the mean and median are so far apart, you decide to complain to the MLB. They find the error and send the corrected data over to you. It\\'s again available as a 2D NumPy array np_baseball, with three columns.\\nThe Python script in the editor already includes code to print out informative messages with the different summary statistics and numpy is already loaded as np. Can you finish the job? np_baseball is available.\\n@instructions\\n\\nThe code to print out the mean height is already included. Complete the code for the median height. Replace None with the correct code.\\nUse np.std() on the first column of np_baseball to calculate stddev. Replace None with the correct code.\\nDo big players tend to be heavier? Use np.corrcoef() to store the correlation between the first and second column of np_baseball in corr. Replace None with the correct code.\\n\\n@hint\\n\\nUse np.median() to calculate the median. Make sure to select to correct column first!\\nSubset the same column when calculating the standard deviation with np.std().\\nUse np_baseball[:, 0] and np_baseball[:, 1] to select the first and second columns; these are the inputs to np.corrcoef().\\n\\n@pre_exercise_code\\nimport pandas as pd\\nnp_baseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\', \\'Age\\']].to_numpy()\\nimport numpy as np\\n\\n@sample_code\\navg = np.mean(np_baseball[:,0])\\nprint(\"Average: \" + str(avg))\\n\\n# Print median height\\nmed = ____\\nprint(\"Median: \" + str(med))\\n\\n# Print out the standard deviation on height\\nstddev = ____\\nprint(\"Standard Deviation: \" + str(stddev))\\n\\n# Print out correlation between first and second column\\ncorr = ____\\nprint(\"Correlation: \" + str(corr))\\n\\n@solution\\navg = np.mean(np_baseball[:,0])\\nprint(\"Average: \" + str(avg))\\n\\n# Print median height\\nmed = np.median(np_baseball[:,0])\\nprint(\"Median: \" + str(med))\\n\\n# Print out the standard deviation on height\\nstddev = np.std(np_baseball[:,0])\\nprint(\"Standard Deviation: \" + str(stddev))\\n\\n# Print out correlation between first and second column\\ncorr = np.corrcoef(np_baseball[:,0], np_baseball[:,1])\\nprint(\"Correlation: \" + str(corr))\\n\\n@sct\\nmsg = \"You shouldn\\'t change or remove the predefined `avg` variable.\"\\nEx().check_object(\"avg\", missing_msg=msg).has_equal_value(incorrect_msg=msg)\\n\\nmissing = \"Have you used `np.median()` to calculate the median?\"\\nincorrect = \"To calculate `med`, pass the first column of `np_baseball` to `numpy.median()`. The example of `np.mean()` shows how it\\'s done.\"\\nEx().check_correct(\\n  check_object(\"med\").has_equal_value(),\\n  check_function(\"numpy.median\", index=0, missing_msg=missing).check_args(0).has_equal_value(incorrect_msg=incorrect)\\n)\\n\\nmissing = \"Have you used `np.std()` to calculate the standard deviation?\"\\nincorrect = \"To calculate `stddev`, pass the first column of `np_baseball` to `numpy.std()`. The example of `np.mean()` shows how it\\'s done.\"\\nEx().check_correct(\\n  check_object(\"stddev\").has_equal_value(),\\n  check_function(\"numpy.std\", index=0, missing_msg=missing).check_args(0).has_equal_value(incorrect_msg=incorrect)\\n)\\n\\nmissing = \"Have you used `np.corrcoef()` to calculate the correlation?\"\\nincorrect1 = \"To calculate `corr`, the first argument to `np.corrcoef()` should be the first column of `np_baseball`, similar to how did it before.\"\\nincorrect2 = \"To calculate `corr`, the second argument to `np.corrcoef()` should be the second column of `np_baseball`. Instead of `[:,0]`, use `[:,1]` this time.\"\\nEx().check_correct(\\n  check_object(\"corr\").has_equal_value(),\\n  check_function(\"numpy.corrcoef\", index=0, missing_msg=missing).multi(\\n    check_args(0, missing_msg=incorrect1).has_equal_value(incorrect_msg=incorrect1),\\n    check_args(1, missing_msg=incorrect2).has_equal_value(incorrect_msg=incorrect2)\\n  )\\n)\\n\\nsuccess_msg(\"Great! Time to use all of your new data science skills in the last exercise!\")\\n\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\nFooter\\n\\n\\n\\n\\n\\n\\n\\n\\n        © 2024 GitHub,\\xa0Inc.\\n      \\n\\n\\nFooter navigation\\n\\n\\nTerms\\n\\n\\nPrivacy\\n\\n\\nSecurity\\n\\n\\nStatus\\n\\n\\nDocs\\n\\n\\nContact\\n\\n\\n\\n\\n      Manage cookies\\n    \\n\\n\\n\\n\\n\\n      Do not share my personal information\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    You can’t perform that action at this time.\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://stackoverflow.com/questions/46242284/pandas-and-python-image-to-numpy-array'}, page_content='\\n\\n\\n\\n\\n\\n \\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\nStack Overflow\\n\\n\\n\\nAbout\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tProducts\\n\\t\\t\\t\\t\\t\\n\\n\\nOverflowAI\\n\\n\\n\\n\\n\\n\\n\\nStack Overflow for Teams\\nWhere developers & technologists share private knowledge with coworkers\\n\\n\\n\\n\\nAdvertising & Talent\\nReach devs & technologists worldwide about your product, service or employer brand\\n\\n\\n\\n\\nOverflowAI\\nGenAI features for Teams\\n\\n\\n\\n\\nOverflowAPI\\nTrain & fine-tune LLMs\\n\\n\\n\\n\\nLabs\\nThe future of collective knowledge sharing\\n\\n\\n\\nAbout the company\\nVisit the blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading…\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncurrent community\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Stack Overflow\\n        \\n\\n\\n\\nhelp\\nchat\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Meta Stack Overflow\\n        \\n\\n\\n\\n\\n\\n\\nyour communities            \\n\\n\\n\\nSign up or log in to customize your list.                \\n\\n\\nmore stack exchange communities\\n\\ncompany blog\\n\\n\\n\\n\\n\\n\\n\\n\\nLog in\\n\\nSign up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    The 2024 Developer Survey results are live!\\n                \\nSee the results\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Home\\n\\n\\n\\n\\n\\n\\n Questions\\n\\n\\n\\n\\n\\n\\n Tags\\n\\n\\n\\n\\n\\n\\n\\n Users\\n\\n\\n\\n\\n\\n\\n Companies\\n\\n\\n\\n\\n\\nLabs\\n\\n\\n\\n\\n\\n\\n\\n\\n Jobs\\n\\n\\n\\n\\n\\n\\n Discussions\\n\\n\\n\\n\\n\\n\\nCollectives\\n\\n\\n\\n\\n\\n\\n\\n\\n                                        Communities for your favorite technologies.  Explore all Collectives\\n\\n\\n\\n\\n\\nTeams\\n\\n\\n\\n\\n\\nNow available on Stack Overflow for Teams! AI features where you work: search, IDE, and chat.\\n        \\nLearn more\\nExplore Teams\\n\\n\\n\\n\\nTeams\\n\\n\\n\\n\\n\\n\\n\\n            Ask questions, find answers and collaborate at work with Stack Overflow for Teams.\\n            Explore Teams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCollectives™ on Stack Overflow\\nFind centralized, trusted content and collaborate around the technologies you use most.\\n\\n                    Learn more about Collectives\\n                \\n\\n\\n\\n\\n\\nTeams\\nQ&A for work\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n                    Learn more about Teams\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\nGet early access and see previews of new features.\\n Learn more about Labs\\n\\n\\n\\n\\n\\n\\n\\nPandas and Python image to numpy array [closed]\\n\\n\\n\\n        Ask Question\\n    \\n\\n\\n\\n\\n\\nAsked\\n6 years, 10 months ago\\n\\n\\nModified\\n6 years, 10 months ago\\n\\n\\nViewed\\n                        6k times\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            0\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClosed. This question needs to be more focused. It is not currently accepting answers.\\n                                \\n                            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWant to improve this question? Update the question so it focuses on one problem only by editing this post.\\n\\n\\nClosed 6 years ago.\\n\\n\\n\\n\\n\\n\\n\\n                        Improve this question\\n                    \\n\\n\\n\\nI\\'m currently teaching myself pandas and python for machine learning. I\\'ve done fine with text data thus far, but dealing with image data with limited knowledge of python and pandas is tripping me.\\nI have read in a .csv file into pandas dataframe, with one of its columns containing url to an image. So this is what shows when I get info from the dataframe.\\ndataframe = pandas.read_csv(\"./sample.csv\")\\ndataframe.info()\\n\\n<class \\'pandas.core.frame.DataFrame\\'>\\nRangeIndex:  5000 entries, 0 to 4999\\nData columns (total of 5 columns):\\nname          5000 non-null object\\n...\\nimage         5000 non-null object\\nthe image column contains url to the image. The problem is, I do not know how to import the image data from this and save it as numpy array for processing.\\nAny help is appreciated. Thanks in advance!\\n\\n\\n\\n\\npythonimagepandasnumpy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            asked Sep 15, 2017 at 14:45\\n\\n\\n\\n\\n\\n\\nIshiro KusabiIshiro Kusabi\\n\\n21122 gold badges66 silver badges1313 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n4\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncan you post a snippet of the csv\\n\\n–\\xa0johnashu\\n\\n\\nCommented\\nSep 15, 2017 at 15:09\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWelcome to SO. Unfortunately this isn\\'t a code writing service. If you haven\\'t had the opportunity, please read How to Ask and minimal reproducible example.  With a little research and studying the Python documentation you should find tools to help you grab an image from the web with a url.  If you come up with a solution and get stuck, come back and ask.\\n\\n–\\xa0wwii\\n\\n\\nCommented\\nSep 15, 2017 at 15:13\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhich version of Python are you using? Are you using the DataFrame for other purposes or is it just an intermediate step to parse the csv file?\\n\\n–\\xa0wwii\\n\\n\\nCommented\\nSep 15, 2017 at 15:42\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\nThanks johnashu and wwii! I\\'ve read through the links, and I apologize that my question was vague and information insufficient. I will try my best to better ask questions next time. Thanks for taking the time to read through my question!\\n\\n–\\xa0Ishiro Kusabi\\n\\n\\nCommented\\nSep 15, 2017 at 15:52\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                        2 Answers\\n                                    2\\n\\n\\n\\n\\n\\n\\n            Sorted by:\\n        \\n\\n            Reset to default\\n        \\n\\n\\n\\n\\n                        Highest score (default)\\n                    \\n\\n                        Trending (recent votes count more)\\n                    \\n\\n                        Date modified (newest first)\\n                    \\n\\n                        Date created (oldest first)\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            1\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you want to download the images from the web and then, for example, rotate your images from your dataframe, and save the results you can use the following code:\\nimport pandas as pd\\nimport matplotlib.pylab as plt\\nimport numpy as np\\nfrom PIL import Image\\nimport urllib2 as urllib\\nimport io\\n\\ndf = pd.DataFrame({\\n\"name\": [\"Butterfly\", \"Birds\"],\\n\"image\": [\"https://upload.wikimedia.org/wikipedia/commons/0/0c/Two-tailed_pasha_%28Charaxes_jasius_jasius%29_Greece.jpg\",\\n                                 \\'https://upload.wikimedia.org/wikipedia/commons/c/c5/Bat_cave_in_El_Maviri_Sinaloa_-_Mexico.jpg\\']})\\n\\ndef rotate_image(image, theta):\\n    \"\"\"\\n    3D rotation matrix around the X-axis by angle theta\\n    \"\"\"\\n    rotation_matrix = np.c_[\\n        [1,0,0],\\n        [0,np.cos(theta),-np.sin(theta)],\\n        [0,np.sin(theta),np.cos(theta)]\\n    ]\\n    return np.einsum(\"ijk,lk->ijl\", image, rotation_matrix)\\n\\nfor i, imageUrl in enumerate(df.image):\\n    print imageUrl\\n    fd = urllib.urlopen(imageUrl)\\n    image_file = io.BytesIO(fd.read())\\n    im = Image.open(image_file)\\n    im_rotated = rotate_image(im, np.pi)\\n    fig = plt.figure()\\n    plt.imshow(im_rotated)\\n    plt.axis(\\'off\\')\\n    fig.savefig(df.name.ix[i] + \".jpg\")\\n\\nIf instead you want to show the pictures you can do:\\nplt.show()\\n\\nThe resulting pictures are birds and butterfly which can be seen here as well:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            answered Sep 15, 2017 at 16:16\\n\\n\\n\\n\\n\\n\\nCedric ZoppoloCedric Zoppolo\\n\\n4,62377 gold badges3131 silver badges6262 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThank you Cedirc! I used a different method but this one also worked well and seems to be a lot cleaner than my method! Have a good day. Thanks again.\\n\\n–\\xa0Ishiro Kusabi\\n\\n\\nCommented\\nSep 15, 2017 at 19:07\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            1\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAs we don\\'t know your csv-file, you have to tune your pd.read_csv() for your case.\\nHere i\\'m using requests to download some image in-memory.\\nThese are then decoded with the help of scipy (which you already should have; if not: you can use Pillow too).\\nThe decoded images are then raw numpy-arrays and shown by matplotlib.\\nKeep in mind, that we are not using temporary-files here and everything is hold in memory. Read also this (answer by jfs).\\nFor people missing some required libs, one should be able to do the same with (code needs to be changed of course):\\n\\nrequests can be replaced with urllib (standard lib)\\n\\n\\ni\\'m not showing code, but this SO-question should be a good start\\nanother relevant SO-question talking about in-memory processing with urllib\\n\\npandas can be replaced by csv (standard lib)\\nscipy can be replaced by Pillow (although internal storage might differ then)\\nmatplotlib is just for demo-purposes (not sure if Pillow allows showing images; edit: it seems it can)\\n\\nI just selected some random images from some german newspage.\\nEdit: Free images from wikipedia now used!\\nCode:\\nimport requests                 # downloading images\\nimport pandas as pd             # csv- / data-input\\nfrom scipy.misc import imread   # image-decoding -> numpy-array\\nimport matplotlib.pyplot as plt # only for demo / plotting\\n\\n# Fake data -> pandas DataFrame\\nurls_df = pd.DataFrame({\\'urls\\': [\\'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Rescue_exercise_RCA_2012.jpg/500px-Rescue_exercise_RCA_2012.jpg\\',\\n                                 \\'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Clinotarsus_curtipes-Aralam-2016-10-29-001.jpg/300px-Clinotarsus_curtipes-Aralam-2016-10-29-001.jpg\\',\\n                                 \\'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/US_Capitol_east_side.JPG/300px-US_Capitol_east_side.JPG\\']}) \\n\\n# Download & Decode\\nimgs = []\\nfor i in urls_df.urls:               # iterate over column / pandas Series\\n    r = requests.get(i, stream=True) # See link for stream=True!\\n    r.raw.decode_content = True      # Content-Encoding\\n    imgs.append(imread(r.raw))       # Decoding to numpy-array\\n\\n# imgs: list of numpy arrays with varying shapes of form (x, y, 3)\\n#     as we got 3-color channels\\n# Beware!: downloading png\\'s might result in a shape of (x, y, 4)\\n#     as some alpha-channel might be available\\n# For more options: https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html\\n\\n# Plot\\nf, arr = plt.subplots(len(imgs))\\nfor i in range(len(imgs)):\\n    arr[i].imshow(imgs[i])\\nplt.show()\\n\\nOutput:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nedited Sep 15, 2017 at 15:53\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            answered Sep 15, 2017 at 15:16\\n\\n\\n\\n\\n\\n\\nsaschasascha\\n\\n33.2k66 gold badges7575 silver badges114114 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThank you sascha! The decoding was really the part I needed help on. I am sorry the information was insufficient. I guess I\\'m currently at a stage where I don\\'t know what I don\\'t know so my questions ended up being vague. Thanks again for your help!\\n\\n–\\xa0Ishiro Kusabi\\n\\n\\nCommented\\nSep 15, 2017 at 15:47\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\nNot the answer you\\'re looking for? Browse other questions tagged pythonimagepandasnumpy or ask your own question.                                \\n\\n\\n\\n\\n\\n\\n\\n                            The Overflow Blog\\n                        \\n\\n\\n \\n\\nThis developer tool is 40 years old: can it be improved?\\n\\n\\n\\n\\n \\n\\nUnpacking the 2024 Developer Survey results\\n\\n\\n\\n                            Featured on Meta\\n                        \\n\\n\\n \\n\\nAnnouncing a change to the data-dump process\\n\\n\\n\\n\\n \\n\\nWe\\'ve made changes to our Terms of Service & Privacy Policy - July 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVisit chat\\n\\n\\n\\n\\n\\nLinked\\n\\n\\n\\n221\\n\\nDownloading a picture via urllib and python\\n\\n\\n\\n41\\n\\nDownload and decompress gzipped file in memory?\\n\\n\\n\\n36\\n\\nPython - Download File Using Requests, Directly to Memory\\n\\n\\n\\n17\\n\\nHow can I display an image using Pillow?\\n\\n\\n\\n\\nRelated\\n\\n\\n\\n12956\\n\\nWhat does the \"yield\" keyword do in Python?\\n\\n\\n\\n7963\\n\\nDoes Python have a ternary conditional operator?\\n\\n\\n\\n7411\\n\\nWhat are metaclasses in Python?\\n\\n\\n\\n4141\\n\\nHow can I iterate over rows in a Pandas DataFrame?\\n\\n\\n\\n6991\\n\\nHow do I merge two dictionaries in a single expression in Python?\\n\\n\\n\\n4690\\n\\nWhat is the difference between @staticmethod and @classmethod in Python?\\n\\n\\n\\n2999\\n\\nRenaming column names in Pandas\\n\\n\\n\\n4617\\n\\nHow slicing in Python works\\n\\n\\n\\n5709\\n\\nHow do I create a directory, and any missing parent directories?\\n\\n\\n\\n2270\\n\\nDelete a column from a Pandas DataFrame\\n\\n\\n\\n\\n\\n\\n\\n            Hot Network Questions\\n        \\n\\n\\n\\n\\n                    Reason why \"An advantage of playing video games is the excitement derived from it\" is incorrect\\n                \\n\\n\\n\\n                    What really is the \"rate\" of time? and what is the \"rate\" of perception\\n                \\n\\n\\n\\n                    What\\'s the difference between \"Model detail\" and \"Texture detail\" in Portal 1?\\n                \\n\\n\\n\\n                    Running the plot of Final Fantasy X\\n                \\n\\n\\n\\n                    Hyphenation is switched off when text should fade away\\n                \\n\\n\\n\\n                    \"frei sein\" meaning \"be available\"\\n                \\n\\n\\n\\n                    Help with a first-order implicit differential equation\\n                \\n\\n\\n\\n                    How do Ashaya, Soul of the Wild and Realm Razer interact?\\n                \\n\\n\\n\\n                    Why is transfer of heat very slow as compared to transfer of sound in solids?\\n                \\n\\n\\n\\n                    Linebreak inside \\\\text inside equation\\n                \\n\\n\\n\\n                    What role can scrum master have/take when product owners differ from opinion?\\n                \\n\\n\\n\\n                    In a world where snowfall is \"reliably common\", how would an injured person with an immobile leg get around?\\n                \\n\\n\\n\\n                    Is there a ring with zero divisors but no nilpotents?\\n                \\n\\n\\n\\n                    Vscode how to remove Incoming/Outgoing changes graph\\n                \\n\\n\\n\\n                    Is ksh-syntax (Korn shell) compatible to bash?\\n                \\n\\n\\n\\n                    On what basis does a paper get accepted into a top journal?\\n                \\n\\n\\n\\n                    Space UN – non human focalpoints\\n                \\n\\n\\n\\n                    Why is my single speed bike incredibly hard to pedal\\n                \\n\\n\\n\\n                    What duration should I choose when applying for a 1 year multi entry Schengen visa?\\n                \\n\\n\\n\\n                    Is free will skepticism self-refuting?\\n                \\n\\n\\n\\n                    Finitely generated group that is not finitely presented\\n                \\n\\n\\n\\n                    How is clang able to evaluate loops without getting stuck in an infinite loop?\\n                \\n\\n\\n\\n                    What are examples of moral principles in religions that secular ethical systems find hard to accept or justify and why?\\n                \\n\\n\\n\\n                    Addressing Potential JavaScript Injection Vulnerabilities\\n                \\n\\n\\n\\n            more hot questions\\n        \\n\\n\\n\\n\\nlang-py\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStack Overflow\\n\\nQuestions\\nHelp\\nChat\\n\\n\\n\\nProducts\\n\\nTeams\\nAdvertising\\nCollectives\\nTalent\\n\\n\\n\\nCompany\\n\\nAbout\\nPress\\nWork Here\\nLegal\\nPrivacy Policy\\nTerms of Service\\nContact Us\\nCookie Settings\\nCookie Policy\\n\\n\\n\\n\\nStack Exchange Network\\n\\n\\n\\n                                    Technology\\n                                \\n\\n\\n\\n                                    Culture & recreation\\n                                \\n\\n\\n\\n                                    Life & arts\\n                                \\n\\n\\n\\n                                    Science\\n                                \\n\\n\\n\\n                                    Professional\\n                                \\n\\n\\n\\n                                    Business\\n                                \\n\\n\\n\\n                                    API\\n                                \\n\\n\\n\\n                                    Data\\n                                \\n\\n\\n\\n\\n\\n\\n\\nBlog\\nFacebook\\nTwitter\\nLinkedIn\\nInstagram\\n\\n\\nSite design / logo © 2024 Stack Exchange Inc; user contributions licensed under CC BY-SA.                    rev\\xa02024.8.6.13652\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://github.com/datacamp/courses-introduction-to-python/blob/master/chapter4.md'}, page_content='\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation Menu\\n\\nToggle navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n            Sign in\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n        Product\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nActions\\n        Automate any workflow\\n      \\n\\n\\n\\n\\n\\n\\n\\nPackages\\n        Host and manage packages\\n      \\n\\n\\n\\n\\n\\n\\n\\nSecurity\\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\nCodespaces\\n        Instant dev environments\\n      \\n\\n\\n\\n\\n\\n\\n\\nGitHub Copilot\\n        Write better code with AI\\n      \\n\\n\\n\\n\\n\\n\\n\\nCode review\\n        Manage code changes\\n      \\n\\n\\n\\n\\n\\n\\n\\nIssues\\n        Plan and track work\\n      \\n\\n\\n\\n\\n\\n\\n\\nDiscussions\\n        Collaborate outside of code\\n      \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      All features\\n\\n    \\n\\n\\n\\n      Documentation\\n\\n    \\n\\n\\n\\n\\n\\n      GitHub Skills\\n\\n    \\n\\n\\n\\n\\n\\n      Blog\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Solutions\\n        \\n\\n\\n\\n\\n\\nBy size\\n\\n\\n\\n      Enterprise\\n\\n    \\n\\n\\n\\n      Teams\\n\\n    \\n\\n\\n\\n      Startups\\n\\n    \\n\\n\\n\\n\\nBy industry\\n\\n\\n\\n      Healthcare\\n\\n    \\n\\n\\n\\n      Financial services\\n\\n    \\n\\n\\n\\n      Manufacturing\\n\\n    \\n\\n\\n\\n\\nBy use case\\n\\n\\n\\n      CI/CD & Automation\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      DevSecOps\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n        Resources\\n        \\n\\n\\n\\n\\n\\nTopics\\n\\n\\n\\n      AI\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      Security\\n\\n    \\n\\n\\n\\n      Software Development\\n\\n    \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      Learning Pathways\\n\\n    \\n\\n\\n\\n\\n\\n      White papers, Ebooks, Webinars\\n\\n    \\n\\n\\n\\n\\n\\n      Customer Stories\\n\\n    \\n\\n\\n\\n      Partners\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Open Source\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub Sponsors\\n        Fund open source developers\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\nThe ReadME Project\\n        GitHub community articles\\n      \\n\\n\\n\\n\\nRepositories\\n\\n\\n\\n      Topics\\n\\n    \\n\\n\\n\\n      Trending\\n\\n    \\n\\n\\n\\n      Collections\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n        Enterprise\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEnterprise platform\\n        AI-powered developer platform\\n      \\n\\n\\n\\n\\nAvailable add-ons\\n\\n\\n\\n\\n\\n\\n\\nAdvanced Security\\n        Enterprise-grade security features\\n      \\n\\n\\n\\n\\n\\n\\n\\nGitHub Copilot\\n        Enterprise-grade AI features\\n      \\n\\n\\n\\n\\n\\n\\n\\nPremium Support\\n        Enterprise-grade 24/7 support\\n      \\n\\n\\n\\n\\n\\n\\nPricing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch or jump to...\\n\\n\\n\\n\\n\\n\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\n \\n\\n\\n\\n\\n        Search\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClear\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n              Search syntax tips\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Provide feedback\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nWe read every piece of feedback, and take your input very seriously.\\n\\n\\nInclude my email address so I can be contacted\\n\\n\\n     Cancel\\n\\n    Submit feedback\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Saved searches\\n      \\nUse saved searches to filter your results more quickly\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\nQuery\\n\\n\\n\\n            To see all available qualifiers, see our documentation.\\n          \\n \\n\\n\\n\\n\\n\\n     Cancel\\n\\n    Create saved search\\n\\n\\n\\n\\n\\n\\n\\n\\n                Sign in\\n              \\n\\n\\n                Sign up\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\n \\n\\n\\nDismiss alert\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        datacamp\\n \\n/\\n\\ncourses-introduction-to-python\\n\\nPublic\\n\\n\\n\\n\\n\\n \\n\\nNotifications\\n You must be signed in to change notification settings\\n\\n\\n \\n\\nFork\\n    264\\n\\n\\n\\n\\n \\n\\n\\n          Star\\n 409\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\n\\n\\n\\nIssues\\n3\\n\\n\\n\\n\\n\\n\\nPull requests\\n0\\n\\n\\n\\n\\n\\n\\nActions\\n\\n\\n\\n\\n\\n\\n\\nProjects\\n0\\n\\n\\n\\n\\n\\n\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\nInsights\\n\\n\\n\\n \\n\\n \\n\\n\\nAdditional navigation options\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Code\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Issues\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Pull requests\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Actions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Projects\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Security\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Insights\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n   Files\\xa0masterBreadcrumbscourses-introduction-to-python/chapter4.md Blame  Blame        Latest commit\\xa0HistoryHistory871 lines (638 loc) · 25.4 KB\\xa0masterBreadcrumbscourses-introduction-to-python/chapter4.mdTopFile metadata and controlsPreviewCodeBlame871 lines (638 loc) · 25.4 KBRaw\\n\\n\\ntitle_meta\\ntitle\\ndescription\\nattachments\\nlessons\\n\\n\\n\\n\\nChapter 4\\nNumPy\\nNumPy is a fundamental Python package to efficiently practice data science. Learn to work with powerful tools in the NumPy array, and get started with data exploration.\\n\\n\\n\\nslides_link\\n\\n\\n\\n\\nhttps://projector-video-pdf-converter.datacamp.com/735/chapter4.pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnb_of_exercises\\ntitle\\n\\n\\n\\n\\n5\\nNumpy\\n\\n\\n\\n\\n\\n\\n\\nnb_of_exercises\\ntitle\\n\\n\\n\\n\\n5\\n2D Numpy Arrays\\n\\n\\n\\n\\n\\n\\n\\nnb_of_exercises\\ntitle\\n\\n\\n\\n\\n3\\nNumpy: Basic Statistics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNumPy\\ntype: VideoExercise\\nkey: f4545baa53\\nxp: 50\\n@projector_key\\na0487c26210f6b71ea98f917734cea3a\\n\\nYour First NumPy Array\\ntype: NormalExercise\\nkey: 84cab9d170\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nYou\\'re now going to dive into the world of baseball. Along the way, you\\'ll get comfortable with the basics of numpy, a powerful package to do data science.\\nA list baseball has already been defined in the Python script, representing the height of some baseball players in centimeters. Can you add some code to create a numpy array from it?\\n@instructions\\n\\nImport the numpy package as np, so that you can refer to numpy with np.\\nUse np.array() to create a numpy array from baseball. Name this array np_baseball.\\nPrint out the type of np_baseball to check that you got it right.\\n\\n@hint\\n\\nimport numpy as np will do the trick. Now, you have to use np.fun_name() whenever you want to use a numpy function.\\nnp.array() should take on input baseball. Assign the result of the function call to np_baseball.\\nTo print out the type of a variable x, simply type print(type(x)).\\n\\n@pre_exercise_code\\nimport numpy as np\\n\\n@sample_code\\n# Import the numpy package as np\\n\\n\\nbaseball = [180, 215, 210, 210, 188, 176, 209, 200]\\n\\n# Create a numpy array from baseball: np_baseball\\n\\n\\n# Print out type of np_baseball\\n\\n\\n@solution\\n# Import the numpy package as np\\nimport numpy as np\\n\\nbaseball = [180, 215, 210, 210, 188, 176, 209, 200]\\n\\n# Create a NumPy array from baseball: np_baseball\\nnp_baseball = np.array(baseball)\\n\\n# Print out type of np_baseball\\nprint(type(np_baseball))\\n\\n@sct\\npredef_msg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().has_import(\"numpy\")\\nEx().check_correct(\\n  check_object(\"np_baseball\"),\\n  multi(\\n    check_object(\"baseball\", missing_msg=predef_msg).has_equal_value(incorrect_msg=predef_msg),\\n    check_function(\"numpy.array\").check_args(0).has_equal_ast()\\n  )\\n)\\n\\nEx().has_printout(0)\\nsuccess_msg(\"Great job!\")\\n\\n\\nBaseball players\\' height\\ntype: NormalExercise\\nkey: e7e25a89ea\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nYou are a huge baseball fan. You decide to call the MLB (Major League Baseball) and ask around for some more statistics on the height of the main players. They pass along data on more than a thousand players, which is stored as a regular Python list: height_in. The height is expressed in inches. Can you make a numpy array out of it and convert the units to meters?\\nheight_in is already available and the numpy package is loaded, so you can start straight away (Source: stat.ucla.edu).\\n@instructions\\n\\nCreate a numpy array from height_in. Name this new array np_height_in.\\nPrint np_height_in.\\nMultiply np_height_in with 0.0254 to convert all height measurements from inches to meters. Store the new values in a new array, np_height_m.\\nPrint out np_height_m and check if the output makes sense.\\n\\n@hint\\n\\nUse np.array() and pass it height. Store the result in np_height_in.\\nTo print out a variable x, type print(x) in the Python script.\\nPerform calculations as if np_height_in is a single number: np_height_in * conversion_factor is part of the answer.\\nTo print out a variable x, type print(x) in the Python script.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nmlb = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")\\nheight_in = mlb[\\'Height\\'].tolist()\\nimport numpy as np\\n\\n@sample_code\\n# Import numpy\\nimport numpy as np\\n\\n# Create a numpy array from height_in: np_height_in\\n\\n\\n# Print out np_height_in\\n\\n\\n# Convert np_height_in to m: np_height_m\\n\\n\\n# Print np_height_m\\n\\n\\n@solution\\n# Import numpy\\nimport numpy as np\\n\\n# Create a numpy array from height_in: np_height_in\\nnp_height_in = np.array(height_in)\\n\\n# Print out np_height_in\\nprint(np_height_in)\\n\\n# Convert np_height_in to m: np_height_m\\nnp_height_m = np_height_in * 0.0254\\n\\n# Print np_height_m\\nprint(np_height_m)\\n\\n@sct\\nEx().has_import(\"numpy\", same_as = False)\\n\\nEx().check_correct(\\n  has_printout(0),\\n  check_correct(\\n    check_object(\\'np_height_in\\').has_equal_value(),\\n    check_function(\\'numpy.array\\').check_args(0).has_equal_ast()\\n  )\\n)\\n\\nEx().check_correct(\\n  has_printout(1),\\n  check_object(\"np_height_m\").has_equal_value(incorrect_msg = \"Use `np_height_in * 0.0254` to calculate `np_height_m`.\")\\n)\\n\\nsuccess_msg(\"Nice! In the blink of an eye, `numpy` performs multiplications on more than 1000 height measurements.\")\\n\\n\\nNumPy Side Effects\\ntype: MultipleChoiceExercise\\nkey: 3662ff6637\\nlang: python\\nxp: 50\\nskills:\\n  - 2\\nnumpy is great for doing vector arithmetic. If you compare its functionality with regular Python lists, however, some things have changed.\\nFirst of all, numpy arrays cannot contain elements with different types.\\nSecond, the typical arithmetic operators, such as +, -, * and / have a different meaning for regular Python lists and numpy arrays.\\nSome lines of code have been provided for you. Try these out and select the one that would match this:\\nnp.array([True, 1, 2]) + np.array([3, 4, False])\\n\\nThe numpy package is already imported as np.\\n@possible_answers\\n\\nnp.array([True, 1, 2, 3, 4, False])\\nnp.array([4, 3, 0]) + np.array([0, 2, 2])\\nnp.array([1, 1, 2]) + np.array([3, 4, -1])\\nnp.array([0, 1, 2, 3, 4, 5])\\n\\n@hint\\n\\nCopy the different code chunks and paste them in the IPython Shell. Hit enter to run the code and see which output matches the one generated by np.array([True, 1, 2]) + np.array([3, 4, False]).\\n\\n@pre_exercise_code\\nimport numpy as np\\n\\n@sct\\nmsg1 = msg3 = msg4 = \"Incorrect. Try out the different code chunks and see which one matches the target code chunk.\"\\nmsg2 = \"Great job! `True` is converted to 1, `False` is converted to 0.\"\\nEx().has_chosen(2, [msg1, msg2, msg3, msg4])\\n\\n\\nSubsetting NumPy Arrays\\ntype: NormalExercise\\nkey: fcb2a9007b\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nSubsetting (using the square bracket notation on lists or arrays) works exactly the same with both lists and arrays.\\nThis exercise already has two lists, height_in and weight_lb, loaded in the background for you. These contain the height and weight of the MLB players as regular lists. It also has two numpy array lists, np_weight_lb and np_height_in prepared for you.\\n@instructions\\n\\nSubset np_weight_lb by printing out the element at index 50.\\nPrint out a sub-array of np_height_in that contains the elements at index 100 up to and including index 110.\\n\\n@hint\\n\\nMake sure to wrap a print() call around your subsetting operations.\\nUse [100:111] to get the elements from index 100 up to and including index 110.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nmlb = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")\\nheight_in = mlb[\\'Height\\'].tolist()\\nweight_lb = mlb[\\'Weight\\'].tolist()\\n\\n@sample_code\\nimport numpy as np\\n\\nnp_weight_lb = np.array(weight_lb)\\nnp_height_in = np.array(height_in)\\n\\n# Print out the weight at index 50\\n\\n\\n# Print out sub-array of np_height_in: index 100 up to and including index 110\\n\\n\\n@solution\\nimport numpy as np\\n\\nnp_weight_lb = np.array(weight_lb)\\nnp_height_in = np.array(height_in)\\n\\n# Print out the weight at index 50\\nprint(np_weight_lb[50])\\n\\n# Print out sub-array of np_height_in: index 100 up to and including index 110\\nprint(np_height_in[100:111])\\n\\n@sct\\nEx().has_import(\"numpy\", same_as=False)\\nmsg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().multi(\\n    check_object(\"np_height_in\", missing_msg=msg).has_equal_value(incorrect_msg = msg),\\n    check_object(\"np_weight_lb\", missing_msg=msg).has_equal_value(incorrect_msg = msg)\\n)\\n\\nEx().has_printout(0)\\nEx().has_printout(1)\\n\\nsuccess_msg(\"Nice! Time to learn something new: 2D NumPy arrays!\")\\n\\n\\n2D NumPy Arrays\\ntype: VideoExercise\\nkey: 1241efac7a\\nxp: 50\\n@projector_key\\nae3238dcc7feb9adecfee0c395fc8dc8\\n\\nYour First 2D NumPy Array\\ntype: NormalExercise\\nkey: 5cb045bb13\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nBefore working on the actual MLB data, let\\'s try to create a 2D numpy array from a small list of lists.\\nIn this exercise, baseball is a list of lists. The main list contains 4 elements. Each of these elements is a list containing the height and the weight of 4 baseball players, in this order. baseball is already coded for you in the script.\\n@instructions\\n\\nUse np.array() to create a 2D numpy array from baseball. Name it np_baseball.\\nPrint out the type of np_baseball.\\nPrint out the shape attribute of np_baseball. Use np_baseball.shape.\\n\\n@hint\\n\\nbaseball is already coded for you in the script. Call np.array() on it and store the resulting 2D numpy array in np_baseball.\\nUse print() in combination with type() for the second instruction.\\nnp_baseball.shape will give you the dimensions of the np_baseball. Make sure to wrap a print() call around it.\\n\\n@pre_exercise_code\\n\\n\\n@sample_code\\nimport numpy as np\\n\\nbaseball = [[180, 78.4],\\n            [215, 102.7],\\n            [210, 98.5],\\n            [188, 75.2]]\\n\\n# Create a 2D numpy array from baseball: np_baseball\\n\\n\\n# Print out the type of np_baseball\\n\\n\\n# Print out the shape of np_baseball\\n\\n\\n@solution\\nimport numpy as np\\n\\nbaseball = [[180, 78.4],\\n            [215, 102.7],\\n            [210, 98.5],\\n            [188, 75.2]]\\n\\n# Create a 2D numpy array from baseball: np_baseball\\nnp_baseball = np.array(baseball)\\n\\n# Print out the type of np_baseball\\nprint(type(np_baseball))\\n\\n# Print out the shape of np_baseball\\nprint(np_baseball.shape)\\n\\n@sct\\nmsg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().check_object(\"baseball\", missing_msg=msg).has_equal_value(incorrect_msg = msg)\\nEx().has_import(\"numpy\", same_as = False)\\n\\nEx().check_correct(\\n    multi(\\n        has_printout(0),\\n        has_printout(1)\\n    ),\\n    check_correct(\\n        check_object(\\'np_baseball\\').has_equal_value(),\\n        check_function(\\'numpy.array\\').check_args(0).has_equal_ast()\\n    )\\n)\\n\\nsuccess_msg(\"Great! You\\'re ready to convert the actual MLB data to a 2D `numpy` array now!\")\\n\\n\\nBaseball data in 2D form\\ntype: NormalExercise\\nkey: 5df25d0b7b\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nYou realize that it makes more sense to restructure all this information in a 2D numpy array.\\nYou have a Python list of lists. In this list of lists, each sublist represents the height and weight of a single baseball player. The name of this list is baseball and it has been loaded for you already (although you can\\'t see it).\\nStore the data as a 2D array to unlock numpy\\'s extra functionality.\\n@instructions\\n\\nUse np.array() to create a 2D numpy array from baseball. Name it np_baseball.\\nPrint out the shape attribute of np_baseball.\\n\\n@hint\\n\\nbaseball is already available in the Python environment. Call np.array() on it and store the resulting 2D numpy array in np_baseball.\\nnp_baseball.shape will give the dimensions of the np_baseball. Make sure to wrap a print()call around it.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nbaseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\']].to_numpy().tolist()\\nimport numpy as np\\n\\n@sample_code\\nimport numpy as np\\n\\n# Create a 2D numpy array from baseball: np_baseball\\nnp_baseball = \\n\\n# Print out the shape of np_baseball\\n\\n\\n@solution\\nimport numpy as np\\n\\n# Create a 2D numpy array from baseball: np_baseball\\nnp_baseball = np.array(baseball)\\n\\n# Print out the shape of np_baseball\\nprint(np_baseball.shape)\\n\\n@sct\\nEx().has_import(\"numpy\", same_as = False)\\n\\nEx().check_correct(\\n    has_printout(0),\\n    check_correct(\\n        check_object(\\'np_baseball\\').has_equal_value(),\\n        check_function(\\'numpy.array\\').check_args(0).has_equal_ast()\\n    )\\n)\\n\\nsuccess_msg(\"Slick! Time to show off some killer features of multi-dimensional `numpy` arrays!\")\\n\\n\\nSubsetting 2D NumPy Arrays\\ntype: NormalExercise\\nkey: aeca4977f0\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nIf your 2D numpy array has a regular structure, i.e. each row and column has a fixed number of values, complicated ways of subsetting become very easy. Have a look at the code below where the elements \"a\" and \"c\" are extracted from a list of lists.\\n# numpy\\nimport numpy as np\\nnp_x = np.array(x)\\nnp_x[:, 0]\\n\\nThe indexes before the comma refer to the rows, while those after the comma refer to the columns. The : is for slicing; in this example, it tells Python to include all rows.\\n@instructions\\n\\nPrint out the 50th row of np_baseball.\\nMake a new variable, np_weight_lb, containing the entire second column of np_baseball.\\nSelect the height (first column) of the 124th baseball player in np_baseball and print it out.\\n\\n@hint\\n\\nYou need row index 49 in the first instruction! More specifically, you\\'ll want to use [49, :].\\nTo select the entire second column, you\\'ll need [:, 1].\\nFor the last instruction, use [123, 0]; don\\'t forget to wrap it all in a print() statement.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nbaseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\']].to_numpy().tolist()\\nimport numpy as np\\n\\n@sample_code\\nimport numpy as np\\n\\nnp_baseball = np.array(baseball)\\n\\n# Print out the 50th row of np_baseball\\n\\n\\n# Select the entire second column of np_baseball: np_weight_lb\\n\\n\\n# Print out height of 124th player\\n\\n\\n@solution\\nimport numpy as np\\n\\nnp_baseball = np.array(baseball)\\n\\n# Print out the 50th row of np_baseball\\nprint(np_baseball[49,:])\\n\\n# Select the entire second column of np_baseball: np_weight_lb\\nnp_weight_lb = np_baseball[:,1]\\n\\n# Print out height of 124th player\\nprint(np_baseball[123, 0])\\n\\n@sct\\nmsg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().multi(\\n    has_import(\"numpy\", same_as = False),\\n    check_object(\"np_baseball\", missing_msg=msg).has_equal_value(incorrect_msg = msg)\\n)\\n\\nEx().has_printout(0)\\n\\nEx().check_object(\\'np_weight_lb\\').has_equal_value(incorrect_msg = \"You can use `np_baseball[:,1]` to define `np_weight_lb`. This will select the entire first column.\")\\n\\nEx().has_printout(1)\\n\\nsuccess_msg(\"This is going well!\")\\n\\n\\n2D Arithmetic\\ntype: NormalExercise\\nkey: 1c2378b677\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\n2D numpy arrays can perform calculations element by element, like numpy arrays.\\nnp_baseball is coded for you; it\\'s again a 2D numpy array with 3 columns representing height (in inches), weight (in pounds) and age (in years). baseball is available as a regular list of lists and updated is available as 2D numpy array.\\n@instructions\\n\\nYou managed to get hold of the changes in height, weight and age of all baseball players. It is available as a 2D numpy array, updated. Add np_baseball and updated and print out the result.\\nYou want to convert the units of height and weight to metric (meters and kilograms, respectively). As a first step, create a numpy array with three values: 0.0254, 0.453592 and 1. Name this array conversion.\\nMultiply np_baseball with conversion and print out the result.\\n\\n@hint\\n\\nnp_baseball + updated will do an element-wise summation of the two numpy arrays.\\nCreate a numpy array with np.array(); the input is a regular Python list with three elements.\\nnp_baseball * conversion will work, without extra work. Try out it! Make sure to wrap it in a print() call.\\n\\n@pre_exercise_code\\nimport pandas as pd\\nimport numpy as np\\nbaseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\', \\'Age\\']].to_numpy().tolist()\\nn = len(baseball)\\nupdated = np.array(pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/update.csv\", header = None))\\nimport numpy as np\\n\\n@sample_code\\nimport numpy as np\\n\\nnp_baseball = np.array(baseball)\\n\\n# Print out addition of np_baseball and updated\\n\\n\\n# Create numpy array: conversion\\n\\n\\n# Print out product of np_baseball and conversion\\n\\n\\n@solution\\nimport numpy as np\\n\\nnp_baseball = np.array(baseball)\\n\\n# Print out addition of np_baseball and updated\\nprint(np_baseball + updated)\\n\\n# Create numpy array: conversion\\nconversion = np.array([0.0254, 0.453592, 1])\\n\\n# Print out product of np_baseball and conversion\\nprint(np_baseball * conversion)\\n\\n@sct\\nEx().has_import(\"numpy\")\\n\\nmsg = \"You don\\'t have to change or remove the predefined variables.\"\\nEx().check_object(\"np_baseball\", missing_msg=msg).has_equal_value(incorrect_msg = msg)\\n\\nEx().has_printout(0)\\n\\nEx().check_correct(\\n    has_printout(1),\\n    check_correct(\\n        check_object(\\'conversion\\').has_equal_value(),\\n        check_function(\\'numpy.array\\', index = 1).check_args(0).has_equal_value()\\n    )    \\n)\\n\\nsuccess_msg(\"Great job! Notice how with very little code, you can change all values in your `numpy` data structure in a very specific way. This will be very useful in your future as a data scientist!\")\\n\\n\\nNumPy: Basic Statistics\\ntype: VideoExercise\\nkey: 287995e488\\nxp: 50\\n@projector_key\\n34495ba457d74296794d2a122c9b6e19\\n\\nAverage versus median\\ntype: NormalExercise\\nkey: 509c588eb6\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nYou now know how to use numpy functions to get a better feeling for your data.\\nThe baseball data is available as a 2D numpy array with 3 columns (height, weight, age) and 1015 rows. The name of this numpy array is np_baseball. After restructuring the data, however, you notice that some height values are abnormally high. Follow the instructions and discover which summary statistic is best suited if you\\'re dealing with so-called outliers. np_baseball is available.\\n@instructions\\n\\nCreate numpy array np_height_in that is equal to first column of np_baseball.\\nPrint out the mean of np_height_in.\\nPrint out the median of np_height_in.\\n\\n@hint\\n\\nUse 2D numpy subsetting: [:,0] is a part of the solution.\\nIf numpy is imported as np, you can use np.mean() to get the mean of a NumPy array. Don\\'t forget to throw in a print() call.\\nFor the last instruction, use np.median().\\n\\n@pre_exercise_code\\nimport pandas as pd\\nnp_baseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\', \\'Age\\']].to_numpy()\\nnp_baseball[slice(0, 1015, 50), 0] = np_baseball[slice(0, 1015, 50), 0]*1000\\nimport numpy as np\\n\\n@sample_code\\nimport numpy as np\\n\\n# Create np_height_in from np_baseball\\n\\n\\n# Print out the mean of np_height_in\\n\\n\\n# Print out the median of np_height_in\\n\\n\\n@solution\\nimport numpy as np\\n\\n# Create np_height_in from np_baseball\\nnp_height_in = np_baseball[:,0]\\n\\n# Print out the mean of np_height_in\\nprint(np.mean(np_height_in))\\n\\n# Print out the median of np_height_in\\nprint(np.median(np_height_in))\\n\\n@sct\\nEx().has_import(\"numpy\", same_as = False)\\n\\nEx().check_object(\"np_height_in\").has_equal_value(incorrect_msg = \"You can use `np_baseball[:,0]` to select the first column from `np_baseball`\"),\\n\\nEx().check_correct(\\n    has_printout(0),\\n    check_function(\\'numpy.mean\\').has_equal_value()\\n)\\n\\nEx().check_correct(\\n    has_printout(1),\\n    check_function(\\'numpy.median\\').has_equal_value()\\n)\\n\\nsuccess_msg(\"An average height of 1586 inches, that doesn\\'t sound right, does it? However, the median does not seem affected by the outliers: 74 inches makes perfect sense. It\\'s always a good idea to check both the median and the mean, to get an idea about the overall distribution of the entire dataset.\")\\n\\n\\nExplore the baseball data\\ntype: NormalExercise\\nkey: \\'4409948807\\'\\nlang: python\\nxp: 100\\nskills:\\n  - 2\\nBecause the mean and median are so far apart, you decide to complain to the MLB. They find the error and send the corrected data over to you. It\\'s again available as a 2D NumPy array np_baseball, with three columns.\\nThe Python script in the editor already includes code to print out informative messages with the different summary statistics and numpy is already loaded as np. Can you finish the job? np_baseball is available.\\n@instructions\\n\\nThe code to print out the mean height is already included. Complete the code for the median height. Replace None with the correct code.\\nUse np.std() on the first column of np_baseball to calculate stddev. Replace None with the correct code.\\nDo big players tend to be heavier? Use np.corrcoef() to store the correlation between the first and second column of np_baseball in corr. Replace None with the correct code.\\n\\n@hint\\n\\nUse np.median() to calculate the median. Make sure to select to correct column first!\\nSubset the same column when calculating the standard deviation with np.std().\\nUse np_baseball[:, 0] and np_baseball[:, 1] to select the first and second columns; these are the inputs to np.corrcoef().\\n\\n@pre_exercise_code\\nimport pandas as pd\\nnp_baseball = pd.read_csv(\"http://assets.datacamp.com/course/intro_to_python/baseball.csv\")[[\\'Height\\', \\'Weight\\', \\'Age\\']].to_numpy()\\nimport numpy as np\\n\\n@sample_code\\navg = np.mean(np_baseball[:,0])\\nprint(\"Average: \" + str(avg))\\n\\n# Print median height\\nmed = ____\\nprint(\"Median: \" + str(med))\\n\\n# Print out the standard deviation on height\\nstddev = ____\\nprint(\"Standard Deviation: \" + str(stddev))\\n\\n# Print out correlation between first and second column\\ncorr = ____\\nprint(\"Correlation: \" + str(corr))\\n\\n@solution\\navg = np.mean(np_baseball[:,0])\\nprint(\"Average: \" + str(avg))\\n\\n# Print median height\\nmed = np.median(np_baseball[:,0])\\nprint(\"Median: \" + str(med))\\n\\n# Print out the standard deviation on height\\nstddev = np.std(np_baseball[:,0])\\nprint(\"Standard Deviation: \" + str(stddev))\\n\\n# Print out correlation between first and second column\\ncorr = np.corrcoef(np_baseball[:,0], np_baseball[:,1])\\nprint(\"Correlation: \" + str(corr))\\n\\n@sct\\nmsg = \"You shouldn\\'t change or remove the predefined `avg` variable.\"\\nEx().check_object(\"avg\", missing_msg=msg).has_equal_value(incorrect_msg=msg)\\n\\nmissing = \"Have you used `np.median()` to calculate the median?\"\\nincorrect = \"To calculate `med`, pass the first column of `np_baseball` to `numpy.median()`. The example of `np.mean()` shows how it\\'s done.\"\\nEx().check_correct(\\n  check_object(\"med\").has_equal_value(),\\n  check_function(\"numpy.median\", index=0, missing_msg=missing).check_args(0).has_equal_value(incorrect_msg=incorrect)\\n)\\n\\nmissing = \"Have you used `np.std()` to calculate the standard deviation?\"\\nincorrect = \"To calculate `stddev`, pass the first column of `np_baseball` to `numpy.std()`. The example of `np.mean()` shows how it\\'s done.\"\\nEx().check_correct(\\n  check_object(\"stddev\").has_equal_value(),\\n  check_function(\"numpy.std\", index=0, missing_msg=missing).check_args(0).has_equal_value(incorrect_msg=incorrect)\\n)\\n\\nmissing = \"Have you used `np.corrcoef()` to calculate the correlation?\"\\nincorrect1 = \"To calculate `corr`, the first argument to `np.corrcoef()` should be the first column of `np_baseball`, similar to how did it before.\"\\nincorrect2 = \"To calculate `corr`, the second argument to `np.corrcoef()` should be the second column of `np_baseball`. Instead of `[:,0]`, use `[:,1]` this time.\"\\nEx().check_correct(\\n  check_object(\"corr\").has_equal_value(),\\n  check_function(\"numpy.corrcoef\", index=0, missing_msg=missing).multi(\\n    check_args(0, missing_msg=incorrect1).has_equal_value(incorrect_msg=incorrect1),\\n    check_args(1, missing_msg=incorrect2).has_equal_value(incorrect_msg=incorrect2)\\n  )\\n)\\n\\nsuccess_msg(\"Great! Time to use all of your new data science skills in the last exercise!\")\\n\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\nFooter\\n\\n\\n\\n\\n\\n\\n\\n\\n        © 2024 GitHub,\\xa0Inc.\\n      \\n\\n\\nFooter navigation\\n\\n\\nTerms\\n\\n\\nPrivacy\\n\\n\\nSecurity\\n\\n\\nStatus\\n\\n\\nDocs\\n\\n\\nContact\\n\\n\\n\\n\\n      Manage cookies\\n    \\n\\n\\n\\n\\n\\n      Do not share my personal information\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    You can’t perform that action at this time.\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://stackoverflow.com/questions/49089025/testing-a-single-image-on-the-mnist-tensorflow-cnn'}, page_content='\\n\\n\\n\\n\\n\\n \\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\nStack Overflow\\n\\n\\n\\nAbout\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tProducts\\n\\t\\t\\t\\t\\t\\n\\n\\nOverflowAI\\n\\n\\n\\n\\n\\n\\n\\nStack Overflow for Teams\\nWhere developers & technologists share private knowledge with coworkers\\n\\n\\n\\n\\nAdvertising & Talent\\nReach devs & technologists worldwide about your product, service or employer brand\\n\\n\\n\\n\\nOverflowAI\\nGenAI features for Teams\\n\\n\\n\\n\\nOverflowAPI\\nTrain & fine-tune LLMs\\n\\n\\n\\n\\nLabs\\nThe future of collective knowledge sharing\\n\\n\\n\\nAbout the company\\nVisit the blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading…\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncurrent community\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Stack Overflow\\n        \\n\\n\\n\\nhelp\\nchat\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Meta Stack Overflow\\n        \\n\\n\\n\\n\\n\\n\\nyour communities            \\n\\n\\n\\nSign up or log in to customize your list.                \\n\\n\\nmore stack exchange communities\\n\\ncompany blog\\n\\n\\n\\n\\n\\n\\n\\n\\nLog in\\n\\nSign up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    The 2024 Developer Survey results are live!\\n                \\nSee the results\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Home\\n\\n\\n\\n\\n\\n\\n Questions\\n\\n\\n\\n\\n\\n\\n Tags\\n\\n\\n\\n\\n\\n\\n\\n Users\\n\\n\\n\\n\\n\\n\\n Companies\\n\\n\\n\\n\\n\\nLabs\\n\\n\\n\\n\\n\\n\\n\\n\\n Jobs\\n\\n\\n\\n\\n\\n\\n Discussions\\n\\n\\n\\n\\n\\n\\nCollectives\\n\\n\\n\\n\\n\\n\\n\\n\\n                                        Communities for your favorite technologies.  Explore all Collectives\\n\\n\\n\\n\\n\\nTeams\\n\\n\\n\\n\\n\\nNow available on Stack Overflow for Teams! AI features where you work: search, IDE, and chat.\\n        \\nLearn more\\nExplore Teams\\n\\n\\n\\n\\nTeams\\n\\n\\n\\n\\n\\n\\n\\n            Ask questions, find answers and collaborate at work with Stack Overflow for Teams.\\n            Explore Teams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCollectives™ on Stack Overflow\\nFind centralized, trusted content and collaborate around the technologies you use most.\\n\\n                    Learn more about Collectives\\n                \\n\\n\\n\\n\\n\\nTeams\\nQ&A for work\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n                    Learn more about Teams\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\nGet early access and see previews of new features.\\n Learn more about Labs\\n\\n\\n\\n\\n\\n\\n\\nTesting a single image on the MNIST tensorflow CNN\\n\\n\\n\\n        Ask Question\\n    \\n\\n\\n\\n\\n\\nAsked\\n6 years, 5 months ago\\n\\n\\nModified\\n6 years, 5 months ago\\n\\n\\nViewed\\n                        1k times\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            0\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nI\\'ve already trained a CNN based on the classic MNIST dataset, and what i\\'m trying to do is build a program that loads the saved model, takes an image (a handwritten digit not part of the dataset) and can predict what digit is written and output it. I\\'ve found myself stuck trying to get the code to output the guess of what digit it is(0-9).\\nI\\'ve already worked out how to feed in a single image in, what exactly do i write to find out what single class the model has classified the image as?\\nThank you\\nnum_channels = 1\\nimage_size = 28\\npic_root = #insert file directory here\\n\\nimg=mpimg.imread(pic_root)\\nimage = img.reshape(-1,image_size,image_size, num_channels)\\nimg = tf.cast(image, tf.float32)\\n\\nwith tf.Session() as session:\\n    saver = tf.train.import_meta_graph(save_file) #loading the saved model\\n    image_predict = tf.nn.softmax(img)\\n    print(image_predict)\\n    soft_max = tf.nn.softmax(logits, name=\"softmax_tensor\")\\n    arg_max = tf.argmax(input=logits, axis=1)\\n    print(arg_max)\\n    print(soft_max)\\n\\nimage_predict, soft_max and arg_max all return something but i don\\'t know how to get the actual prediction from this. \\n\\n\\n\\n\\npythontensorflowconv-neural-network\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nedited Mar 3, 2018 at 21:56\\n\\n\\n\\n\\n\\nLauren\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            asked Mar 3, 2018 at 20:43\\n\\n\\n\\n\\n\\n\\nLaurenLauren\\n\\n122 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n2\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\nCan you post the code you have so far?\\n\\n–\\xa0Adnan S\\n\\n\\nCommented\\nMar 3, 2018 at 20:55\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosted :) sorry it\\'s a bit messy, would you like the code from the CNN itself as well? thank you\\n\\n–\\xa0Lauren\\n\\n\\nCommented\\nMar 3, 2018 at 21:57\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                        1 Answer\\n                                    1\\n\\n\\n\\n\\n\\n\\n            Sorted by:\\n        \\n\\n            Reset to default\\n        \\n\\n\\n\\n\\n                        Highest score (default)\\n                    \\n\\n                        Trending (recent votes count more)\\n                    \\n\\n                        Date modified (newest first)\\n                    \\n\\n                        Date created (oldest first)\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            0\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPer your code, soft_max and arg_max should be returned as arrays of length 10. The values in the array correspond to the 10 digits from 0 to 9. \\nEach value in soft_max array is the probability that the input image matches that particular digit. The array indexing starts at zero so the first value in array is the probability that the image is the digit 0 and the second value is the probability that the image is the digit 1 and so forth so that the tenth value is the probability that the image is 9. The predicted image is the value with the highest probability.\\narg_max saves you a processing step by returning a sorted list of predicted indices (which in this case match the predicted digit). So if arg_max has [4, 9, 5, ...], the predicted digit is 4.\\nprint(arg_max[0]) #should give you the predicted digit\\n\\nOnce you know that the return values are arrays as explained, the output can be decoded.\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nedited Mar 5, 2018 at 22:00\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            answered Mar 5, 2018 at 7:06\\n\\n\\n\\n\\n\\n\\nAdnan SAdnan S\\n\\n1,88211 gold badge1515 silver badges1919 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThank you so much for your help! When i print arg_max[0] it prints \\'Tensor(\"strided_slice:0\", shape=(), dtype=int64)\\' , any idea what this means?\\n\\n–\\xa0Lauren\\n\\n\\nCommented\\nMar 7, 2018 at 21:47\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Your Answer\\n                                \\n\\n\\n\\n\\n\\n\\n\\n\\nReminder: Answers generated by artificial intelligence tools are not allowed on Stack Overflow. Learn more\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThanks for contributing an answer to Stack Overflow!Please be sure to answer the question. Provide details and share your research!But avoid …Asking for help, clarification, or responding to other answers.Making statements based on opinion; back them up with references or personal experience.To learn more, see our tips on writing great answers.\\n\\n\\n\\n\\n\\n\\nDraft saved\\nDraft discarded\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up or log in\\n\\n\\n Sign up using Google\\n                        \\n\\n Sign up using Email and Password\\n                        \\n\\n\\n\\nSubmit\\n\\nPost as a guest\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEmail\\nRequired, but never shown\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPost as a guest\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEmail\\nRequired, but never shown\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                            Post Your Answer\\n                                        \\n\\n                                            Discard\\n                                        \\n\\n                                                By clicking “Post Your Answer”, you agree to our terms of service and acknowledge you have read our privacy policy.\\n\\n\\n\\n\\n\\n\\nNot the answer you\\'re looking for? Browse other questions tagged pythontensorflowconv-neural-network or ask your own question.                                \\n\\n\\n\\n\\n\\n\\n\\n                            The Overflow Blog\\n                        \\n\\n\\n \\n\\nThis developer tool is 40 years old: can it be improved?\\n\\n\\n\\n\\n \\n\\nUnpacking the 2024 Developer Survey results\\n\\n\\n\\n                            Featured on Meta\\n                        \\n\\n\\n \\n\\nAnnouncing a change to the data-dump process\\n\\n\\n\\n\\n \\n\\nWe\\'ve made changes to our Terms of Service & Privacy Policy - July 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated\\n\\n\\n\\n2\\n\\nhow to test mnist on my own dataset images\\n\\n\\n\\n10\\n\\nTensorflow - Testing a mnist neural net with my own images\\n\\n\\n\\n3\\n\\nPython/Tensorflow - I have trained the convolutional neural network, how to test it?\\n\\n\\n\\n0\\n\\nTensorflow MNIST - accuracy of particular test image\\n\\n\\n\\n2\\n\\nHow to test multiple images at once with label_image.py in Tensorflow\\n\\n\\n\\n0\\n\\nCNN-Divide images into training/validation/testing\\n\\n\\n\\n1\\n\\nHow do i test my CNN model with an image?\\n\\n\\n\\n1\\n\\nIn Pytorch, how to test simple image with my loaded model?\\n\\n\\n\\n7\\n\\nHow to test one single image in pytorch\\n\\n\\n\\n2\\n\\nTesting my CNN on a small set of image but training has no effect\\n\\n\\n\\n\\n\\n\\n\\n            Hot Network Questions\\n        \\n\\n\\n\\n\\n                    Linebreak inside \\\\text inside equation\\n                \\n\\n\\n\\n                    Addressing Potential JavaScript Injection Vulnerabilities\\n                \\n\\n\\n\\n                    How much and how candid should my feedback be when leaving a team?\\n                \\n\\n\\n\\n                    Ratio of real world to risk-neutral density\\n                \\n\\n\\n\\n                    Why is this regex [[:upper:]] matching with lowercase string?\\n                \\n\\n\\n\\n                    Why do doctors seem to overcharge for services?\\n                \\n\\n\\n\\n                    What\\'s the difference between \"Model detail\" and \"Texture detail\" in Portal 1?\\n                \\n\\n\\n\\n                    Cubic Concatenation\\n                \\n\\n\\n\\n                    Identify identicon icons\\n                \\n\\n\\n\\n                    Is it possible to put a crescendo on top of the staff markings?\\n                \\n\\n\\n\\n                    Lexicographically earliest permutation of the initial segment of nonnegative integers subject to divisibility constraints\\n                \\n\\n\\n\\n                    Are there official, standard, or conventional names for the screen RAM addresses on the ZX Spectrum?\\n                \\n\\n\\n\\n                    Can \"the\" mean \"enough\"? — E.g.: \"She will bake a pie, if she has the ingredients.\"\\n                \\n\\n\\n\\n                    \"frei sein\" meaning \"be available\"\\n                \\n\\n\\n\\n                    Fantasy book series about a lord (and maybe a lady) who rules over a world where it\\'s eternally spring, summer, fall, etc\\n                \\n\\n\\n\\n                    What would a city/arcology designed to survive atomic bombings look like\\n                \\n\\n\\n\\n                    What role can scrum master have/take when product owners differ from opinion?\\n                \\n\\n\\n\\n                    How to align each bullet point in the table\\n                \\n\\n\\n\\n                    竹马青梅 - what is the 青梅?\\n                \\n\\n\\n\\n                    On what basis does a paper get accepted into a top journal?\\n                \\n\\n\\n\\n                    Had this attempt to salvage naïve comprehension been studied before?\\n                \\n\\n\\n\\n                    Neutron half-life outside a nucleus: can it be extended?\\n                \\n\\n\\n\\n                    Vscode how to remove Incoming/Outgoing changes graph\\n                \\n\\n\\n\\n                    Is there a ring with zero divisors but no nilpotents?\\n                \\n\\n\\n\\n            more hot questions\\n        \\n\\n\\n\\n\\n            Question feed\\n        \\n\\n\\n\\n\\n                Subscribe to RSS\\n            \\n\\n\\n\\n                        Question feed\\n                        To subscribe to this RSS feed, copy and paste this URL into your RSS reader.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nlang-py\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStack Overflow\\n\\nQuestions\\nHelp\\nChat\\n\\n\\n\\nProducts\\n\\nTeams\\nAdvertising\\nCollectives\\nTalent\\n\\n\\n\\nCompany\\n\\nAbout\\nPress\\nWork Here\\nLegal\\nPrivacy Policy\\nTerms of Service\\nContact Us\\nCookie Settings\\nCookie Policy\\n\\n\\n\\n\\nStack Exchange Network\\n\\n\\n\\n                                    Technology\\n                                \\n\\n\\n\\n                                    Culture & recreation\\n                                \\n\\n\\n\\n                                    Life & arts\\n                                \\n\\n\\n\\n                                    Science\\n                                \\n\\n\\n\\n                                    Professional\\n                                \\n\\n\\n\\n                                    Business\\n                                \\n\\n\\n\\n                                    API\\n                                \\n\\n\\n\\n                                    Data\\n                                \\n\\n\\n\\n\\n\\n\\n\\nBlog\\nFacebook\\nTwitter\\nLinkedIn\\nInstagram\\n\\n\\nSite design / logo © 2024 Stack Exchange Inc; user contributions licensed under CC BY-SA.                    rev\\xa02024.8.6.13652\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/'}, page_content=\"\\n\\n\\n\\n [New Book] Click to get Mastering Digital Art with Stable Diffusion!\\n Use the offer code 20offearlybird to get 20% off. Hurry, sale ends soon!\\nNavigation\\n\\n\\n\\nMachineLearningMastery.com\\nMaking developers awesome at machine learning\\n\\n\\n\\n Click to Take the FREE Computer Vision Crash-Course\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nHome\\nMain MenuGet Started\\nBlog\\nTopics\\n\\nAttention\\nBetter Deep Learning\\nCalculus\\nChatGPT\\nCode Algorithms\\nComputer Vision\\nData Preparation\\nData Science\\nDeep Learning (keras)\\nDeep Learning with PyTorch\\nEnsemble Learning\\nGANs\\nNeural Net Time Series\\nNLP (Text)\\nImbalanced Learning\\nIntro to Time Series\\nIntro to Algorithms\\nLinear Algebra\\nLSTMs\\nOpenCV\\nOptimization\\nProbability\\nPython (scikit-learn)\\nPython for Machine Learning\\nR (caret)\\nStable Diffusion\\nStatistics\\nWeka (no code)\\nXGBoost\\n\\n\\neBooks\\nFAQ\\nAbout\\nContact\\n \\n\\n\\nReturn to Content\\n\\n\\n\\n\\n\\n\\nHow to Develop a CNN for MNIST Handwritten Digit Classification \\nBy Jason Brownlee on November 14, 2021 in Deep Learning for Computer Vision  188\\n\\n\\n\\n\\nShare  \\n\\nTweet \\n\\n        \\nShare \\n\\nHow to Develop a Convolutional Neural Network From Scratch for MNIST Handwritten Digit Classification.\\nThe MNIST handwritten digit classification problem is a standard dataset used in computer vision and deep learning.\\nAlthough the dataset is effectively solved, it can be used as the basis for learning and practicing how to develop, evaluate, and use convolutional deep learning neural networks for image classification from scratch. This includes how to develop a robust test harness for estimating the performance of the model, how to explore improvements to the model, and how to save the model and later load it to make predictions on new data.\\nIn this tutorial, you will discover how to develop a convolutional neural network for handwritten digit classification from scratch.\\nAfter completing this tutorial, you will know:\\n\\nHow to develop a test harness to develop a robust evaluation of a model and establish a baseline of performance for a classification task.\\nHow to explore extensions to a baseline model to improve learning and model capacity.\\nHow to develop a finalized model, evaluate the performance of the final model, and use it to make predictions on new images.\\n\\nKick-start your project with my new book Deep Learning for Computer Vision, including step-by-step tutorials and the Python source code files for all examples.\\nLet’s get started.\\n\\nUpdated Dec/2019: Updated examples for TensorFlow 2.0 and Keras 2.3.\\nUpdated Jan/2020: Fixed a bug where models were defined outside the cross-validation loop.\\nUpdated Nov/2021: Updated to use Tensorflow 2.6\\n\\nHow to Develop a Convolutional Neural Network From Scratch for MNIST Handwritten Digit ClassificationPhoto by Richard Allaway, some rights reserved.\\nTutorial Overview\\nThis tutorial is divided into five parts; they are:\\n\\nMNIST Handwritten Digit Classification Dataset\\nModel Evaluation Methodology\\nHow to Develop a Baseline Model\\nHow to Develop an Improved Model\\nHow to Finalize the Model and Make Predictions\\n\\n\\n\\nWant Results with Deep Learning for Computer Vision?\\nTake my free 7-day email crash course now (with sample code).\\nClick to sign-up and also get a free PDF Ebook version of the course.\\n Click here to subscribe \\n\\n\\nDevelopment Environment\\nThis tutorial assumes that you are using standalone Keras running on top of TensorFlow with Python 3. If you need help setting up your development environment see this tutorial:\\n\\nHow to Setup Your Python Environment for Machine Learning with Anaconda\\n\\nMNIST Handwritten Digit Classification Dataset\\nThe MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset.\\nIt is a dataset of 60,000 small square 28×28 pixel grayscale images of handwritten single digits between 0 and 9.\\nThe task is to classify a given image of a handwritten digit into one of 10 classes representing integer values from 0 to 9, inclusively.\\nIt is a widely used and deeply understood dataset and, for the most part, is “solved.” Top-performing models are deep learning convolutional neural networks that achieve a classification accuracy of above 99%, with an error rate between 0.4 %and 0.2% on the hold out test dataset.\\nThe example below loads the MNIST dataset using the Keras API and creates a plot of the first nine images in the training dataset.\\n\\n\\n\\n\\n\\n# example of loading the mnist dataset\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom matplotlib import pyplot as plt\\r\\n# load dataset\\r\\n(trainX, trainy), (testX, testy) = mnist.load_data()\\r\\n# summarize loaded dataset\\r\\nprint('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\\r\\nprint('Test: X=%s, y=%s' % (testX.shape, testy.shape))\\r\\n# plot first few images\\r\\nfor i in range(9):\\r\\n\\t# define subplot\\r\\n\\tplt.subplot(330 + 1 + i)\\r\\n\\t# plot raw pixel data\\r\\n\\tplt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\\r\\n# show the figure\\r\\nplt.show()\\n\\n\\n\\n\\n12345678910111213141516\\n\\n# example of loading the mnist datasetfrom tensorflow.keras.datasets import mnistfrom matplotlib import pyplot as plt# load dataset(trainX, trainy), (testX, testy) = mnist.load_data()# summarize loaded datasetprint('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))print('Test: X=%s, y=%s' % (testX.shape, testy.shape))# plot first few imagesfor i in range(9): # define subplot plt.subplot(330 + 1 + i) # plot raw pixel data plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))# show the figureplt.show()\\n\\n\\n\\nRunning the example loads the MNIST train and test dataset and prints their shape.\\nWe can see that there are 60,000 examples in the training dataset and 10,000 in the test dataset and that images are indeed square with 28×28 pixels.\\n\\n\\n\\n\\n\\nTrain: X=(60000, 28, 28), y=(60000,)\\r\\nTest: X=(10000, 28, 28), y=(10000,)\\n\\n\\n\\n\\n12\\n\\nTrain: X=(60000, 28, 28), y=(60000,)Test: X=(10000, 28, 28), y=(10000,)\\n\\n\\n\\nA plot of the first nine images in the dataset is also created showing the natural handwritten nature of the images to be classified.\\nPlot of a Subset of Images From the MNIST Dataset\\nModel Evaluation Methodology\\nAlthough the MNIST dataset is effectively solved, it can be a useful starting point for developing and practicing a methodology for solving image classification tasks using convolutional neural networks.\\nInstead of reviewing the literature on well-performing models on the dataset, we can develop a new model from scratch.\\nThe dataset already has a well-defined train and test dataset that we can use.\\nIn order to estimate the performance of a model for a given training run, we can further split the training set into a train and validation dataset. Performance on the train and validation dataset over each run can then be plotted to provide learning curves and insight into how well a model is learning the problem.\\nThe Keras API supports this by specifying the “validation_data” argument to the model.fit() function when training the model, that will, in turn, return an object that describes model performance for the chosen loss and metrics on each training epoch.\\n\\n\\n\\n\\n\\n# record model performance on a validation dataset during training\\r\\nhistory = model.fit(..., validation_data=(valX, valY))\\n\\n\\n\\n\\n12\\n\\n# record model performance on a validation dataset during traininghistory = model.fit(..., validation_data=(valX, valY))\\n\\n\\n\\nIn order to estimate the performance of a model on the problem in general, we can use k-fold cross-validation, perhaps five-fold cross-validation. This will give some account of the models variance with both respect to differences in the training and test datasets, and in terms of the stochastic nature of the learning algorithm. The performance of a model can be taken as the mean performance across k-folds, given the standard deviation, that could be used to estimate a confidence interval if desired.\\nWe can use the KFold class from the scikit-learn API to implement the k-fold cross-validation evaluation of a given neural network model. There are many ways to achieve this, although we can choose a flexible approach where the KFold class is only used to specify the row indexes used for each spit.\\n\\n\\n\\n\\n\\n# example of k-fold cv for a neural net\\r\\ndata = ...\\r\\n# prepare cross validation\\r\\nkfold = KFold(5, shuffle=True, random_state=1)\\r\\n# enumerate splits\\r\\nfor train_ix, test_ix in kfold.split(data):\\r\\n        model = ...\\r\\n\\t...\\n\\n\\n\\n\\n12345678\\n\\n# example of k-fold cv for a neural netdata = ...# prepare cross validationkfold = KFold(5, shuffle=True, random_state=1)# enumerate splitsfor train_ix, test_ix in kfold.split(data):\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0model = ... ...\\n\\n\\n\\nWe will hold back the actual test dataset and use it as an evaluation of our final model.\\nHow to Develop a Baseline Model\\nThe first step is to develop a baseline model.\\nThis is critical as it both involves developing the infrastructure for the test harness so that any model we design can be evaluated on the dataset, and it establishes a baseline in model performance on the problem, by which all improvements can be compared.\\nThe design of the test harness is modular, and we can develop a separate function for each piece. This allows a given aspect of the test harness to be modified or inter-changed, if we desire, separately from the rest.\\nWe can develop this test harness with five key elements. They are the loading of the dataset, the preparation of the dataset, the definition of the model, the evaluation of the model, and the presentation of results.\\nLoad Dataset\\nWe know some things about the dataset.\\nFor example, we know that the images are all pre-aligned (e.g. each image only contains a hand-drawn digit), that the images all have the same square size of 28×28 pixels, and that the images are grayscale.\\nTherefore, we can load the images and reshape the data arrays to have a single color channel.\\n\\n\\n\\n\\n\\n# load dataset\\r\\n(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n# reshape dataset to have a single channel\\r\\ntrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\ntestX = testX.reshape((testX.shape[0], 28, 28, 1))\\n\\n\\n\\n\\n12345\\n\\n# load dataset(trainX, trainY), (testX, testY) = mnist.load_data()# reshape dataset to have a single channeltrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))testX = testX.reshape((testX.shape[0], 28, 28, 1))\\n\\n\\n\\nWe also know that there are 10 classes and that classes are represented as unique integers.\\nWe can, therefore, use a one hot encoding for the class element of each sample, transforming the integer into a 10 element binary vector with a 1 for the index of the class value, and 0 values for all other classes. We can achieve this with the to_categorical() utility function.\\n\\n\\n\\n\\n\\n# one hot encode target values\\r\\ntrainY = to_categorical(trainY)\\r\\ntestY = to_categorical(testY)\\n\\n\\n\\n\\n123\\n\\n# one hot encode target valuestrainY = to_categorical(trainY)testY = to_categorical(testY)\\n\\n\\n\\nThe load_dataset() function implements these behaviors and can be used to load the dataset.\\n\\n\\n\\n\\n\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\n\\n\\n\\n\\n1234567891011\\n\\n# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\n\\n\\n\\n\\nPrepare Pixel Data\\nWe know that the pixel values for each image in the dataset are unsigned integers in the range between black and white, or 0 and 255.\\nWe do not know the best way to scale the pixel values for modeling, but we know that some scaling will be required.\\nA good starting point is to normalize the pixel values of grayscale images, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value.\\n\\n\\n\\n\\n\\n# convert from integers to floats\\r\\ntrain_norm = train.astype('float32')\\r\\ntest_norm = test.astype('float32')\\r\\n# normalize to range 0-1\\r\\ntrain_norm = train_norm / 255.0\\r\\ntest_norm = test_norm / 255.0\\n\\n\\n\\n\\n123456\\n\\n# convert from integers to floatstrain_norm = train.astype('float32')test_norm = test.astype('float32')# normalize to range 0-1train_norm = train_norm / 255.0test_norm = test_norm / 255.0\\n\\n\\n\\nThe prep_pixels() function below implements these behaviors and is provided with the pixel values for both the train and test datasets that will need to be scaled.\\n\\n\\n\\n\\n\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\n\\n\\n\\n\\n12345678910\\n\\n# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\n\\n\\n\\nThis function must be called to prepare the pixel values prior to any modeling.\\nDefine Model\\nNext, we need to define a baseline convolutional neural network model for the problem.\\nThe model has two main aspects: the feature extraction front end comprised of convolutional and pooling layers, and the classifier backend that will make a prediction.\\nFor the convolutional front-end, we can start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer. The filter maps can then be flattened to provide features to the classifier.\\nGiven that the problem is a multi-class classification task, we know that we will require an output layer with 10 nodes in order to predict the probability distribution of an image belonging to each of the 10 classes. This will also require the use of a softmax activation function. Between the feature extractor and the output layer, we can add a dense layer to interpret the features, in this case with 100 nodes.\\nAll layers will use the ReLU activation function and the He weight initialization scheme, both best practices.\\nWe will use a conservative configuration for the stochastic gradient descent optimizer with a learning rate of 0.01 and a momentum of 0.9. The categorical cross-entropy loss function will be optimized, suitable for multi-class classification, and we will monitor the classification accuracy metric, which is appropriate given we have the same number of examples in each of the 10 classes.\\nThe define_model() function below will define and return this model.\\n\\n\\n\\n\\n\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\n\\n\\n\\n\\n123456789101112\\n\\n# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\n\\n\\n\\n\\nEvaluate Model\\nAfter the model is defined, we need to evaluate it.\\nThe model will be evaluated using five-fold cross-validation. The value of k=5 was chosen to provide a baseline for both repeated evaluation and to not be so large as to require a long running time. Each test set will be 20% of the training dataset, or about 12,000 examples, close to the size of the actual test set for this problem.\\nThe training dataset is shuffled prior to being split, and the sample shuffling is performed each time, so that any model we evaluate will have the same train and test datasets in each fold, providing an apples-to-apples comparison between models.\\nWe will train the baseline model for a modest 10 training epochs with a default batch size of 32 examples. The test set for each fold will be used to evaluate the model both during each epoch of the training run, so that we can later create learning curves, and at the end of the run, so that we can estimate the performance of the model. As such, we will keep track of the resulting history from each run, as well as the classification accuracy of the fold.\\nThe evaluate_model() function below implements these behaviors, taking the training dataset as arguments and returning a list of accuracy scores and training histories that can be later summarized.\\n\\n\\n\\n\\n\\n# evaluate a model using k-fold cross-validation\\r\\ndef evaluate_model(dataX, dataY, n_folds=5):\\r\\n\\tscores, histories = list(), list()\\r\\n\\t# prepare cross validation\\r\\n\\tkfold = KFold(n_folds, shuffle=True, random_state=1)\\r\\n\\t# enumerate splits\\r\\n\\tfor train_ix, test_ix in kfold.split(dataX):\\r\\n\\t\\t# define model\\r\\n\\t\\tmodel = define_model()\\r\\n\\t\\t# select rows for train and test\\r\\n\\t\\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\\r\\n\\t\\t# fit model\\r\\n\\t\\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\r\\n\\t\\t# evaluate model\\r\\n\\t\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\t\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\t\\t# stores scores\\r\\n\\t\\tscores.append(acc)\\r\\n\\t\\thistories.append(history)\\r\\n\\treturn scores, histories\\n\\n\\n\\n\\n1234567891011121314151617181920\\n\\n# evaluate a model using k-fold cross-validationdef evaluate_model(dataX, dataY, n_folds=5): scores, histories = list(), list() # prepare cross validation kfold = KFold(n_folds, shuffle=True, random_state=1) # enumerate splits for train_ix, test_ix in kfold.split(dataX): # define model model = define_model() # select rows for train and test trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix] # fit model history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0) # evaluate model _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0)) # stores scores scores.append(acc) histories.append(history) return scores, histories\\n\\n\\n\\n\\nPresent Results\\nOnce the model has been evaluated, we can present the results.\\nThere are two key aspects to present: the diagnostics of the learning behavior of the model during training and the estimation of the model performance. These can be implemented using separate functions.\\nFirst, the diagnostics involve creating a line plot showing model performance on the train and test set during each fold of the k-fold cross-validation. These plots are valuable for getting an idea of whether a model is overfitting, underfitting, or has a good fit for the dataset.\\nWe will create a single figure with two subplots, one for loss and one for accuracy. Blue lines will indicate model performance on the training dataset and orange lines will indicate performance on the hold out test dataset. The summarize_diagnostics() function below creates and shows this plot given the collected training histories.\\n\\n\\n\\n\\n\\n# plot diagnostic learning curves\\r\\ndef summarize_diagnostics(histories):\\r\\n\\tfor i in range(len(histories)):\\r\\n\\t\\t# plot loss\\r\\n\\t\\tplt.subplot(2, 1, 1)\\r\\n\\t\\tplt.title('Cross Entropy Loss')\\r\\n\\t\\tplt.plot(histories[i].history['loss'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\\r\\n\\t\\t# plot accuracy\\r\\n\\t\\tplt.subplot(2, 1, 2)\\r\\n\\t\\tplt.title('Classification Accuracy')\\r\\n\\t\\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\\r\\n\\tplt.show()\\n\\n\\n\\n\\n1234567891011121314\\n\\n# plot diagnostic learning curvesdef summarize_diagnostics(histories): for i in range(len(histories)): # plot loss plt.subplot(2, 1, 1) plt.title('Cross Entropy Loss') plt.plot(histories[i].history['loss'], color='blue', label='train') plt.plot(histories[i].history['val_loss'], color='orange', label='test') # plot accuracy plt.subplot(2, 1, 2) plt.title('Classification Accuracy') plt.plot(histories[i].history['accuracy'], color='blue', label='train') plt.plot(histories[i].history['val_accuracy'], color='orange', label='test') plt.show()\\n\\n\\n\\nNext, the classification accuracy scores collected during each fold can be summarized by calculating the mean and standard deviation. This provides an estimate of the average expected performance of the model trained on this dataset, with an estimate of the average variance in the mean. We will also summarize the distribution of scores by creating and showing a box and whisker plot.\\nThe summarize_performance() function below implements this for a given list of scores collected during model evaluation.\\n\\n\\n\\n\\n\\n# summarize model performance\\r\\ndef summarize_performance(scores):\\r\\n\\t# print summary\\r\\n\\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\\r\\n\\t# box and whisker plots of results\\r\\n\\tplt.boxplot(scores)\\r\\n\\tplt.show()\\n\\n\\n\\n\\n1234567\\n\\n# summarize model performancedef summarize_performance(scores): # print summary print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores))) # box and whisker plots of results plt.boxplot(scores) plt.show()\\n\\n\\n\\n\\nComplete Example\\nWe need a function that will drive the test harness.\\nThis involves calling all of the define functions.\\n\\n\\n\\n\\n\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# evaluate model\\r\\n\\tscores, histories = evaluate_model(trainX, trainY)\\r\\n\\t# learning curves\\r\\n\\tsummarize_diagnostics(histories)\\r\\n\\t# summarize estimated performance\\r\\n\\tsummarize_performance(scores)\\n\\n\\n\\n\\n123456789101112\\n\\n# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # evaluate model scores, histories = evaluate_model(trainX, trainY) # learning curves summarize_diagnostics(histories) # summarize estimated performance summarize_performance(scores)\\n\\n\\n\\nWe now have everything we need; the complete code example for a baseline convolutional neural network model on the MNIST dataset is listed below.\\n\\n\\n\\n\\n\\n# baseline cnn model for mnist\\r\\nfrom numpy import mean\\r\\nfrom numpy import std\\r\\nfrom matplotlib import pyplot as plt\\r\\nfrom sklearn.model_selection import KFold\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\nfrom tensorflow.keras.models import Sequential\\r\\nfrom tensorflow.keras.layers import Conv2D\\r\\nfrom tensorflow.keras.layers import MaxPooling2D\\r\\nfrom tensorflow.keras.layers import Dense\\r\\nfrom tensorflow.keras.layers import Flatten\\r\\nfrom tensorflow.keras.optimizers import SGD\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\r\\n\\r\\n# evaluate a model using k-fold cross-validation\\r\\ndef evaluate_model(dataX, dataY, n_folds=5):\\r\\n\\tscores, histories = list(), list()\\r\\n\\t# prepare cross validation\\r\\n\\tkfold = KFold(n_folds, shuffle=True, random_state=1)\\r\\n\\t# enumerate splits\\r\\n\\tfor train_ix, test_ix in kfold.split(dataX):\\r\\n\\t\\t# define model\\r\\n\\t\\tmodel = define_model()\\r\\n\\t\\t# select rows for train and test\\r\\n\\t\\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\\r\\n\\t\\t# fit model\\r\\n\\t\\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\r\\n\\t\\t# evaluate model\\r\\n\\t\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\t\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\t\\t# stores scores\\r\\n\\t\\tscores.append(acc)\\r\\n\\t\\thistories.append(history)\\r\\n\\treturn scores, histories\\r\\n\\r\\n# plot diagnostic learning curves\\r\\ndef summarize_diagnostics(histories):\\r\\n\\tfor i in range(len(histories)):\\r\\n\\t\\t# plot loss\\r\\n\\t\\tplt.subplot(2, 1, 1)\\r\\n\\t\\tplt.title('Cross Entropy Loss')\\r\\n\\t\\tplt.plot(histories[i].history['loss'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\\r\\n\\t\\t# plot accuracy\\r\\n\\t\\tplt.subplot(2, 1, 2)\\r\\n\\t\\tplt.title('Classification Accuracy')\\r\\n\\t\\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\\r\\n\\tplt.show()\\r\\n\\r\\n# summarize model performance\\r\\ndef summarize_performance(scores):\\r\\n\\t# print summary\\r\\n\\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\\r\\n\\t# box and whisker plots of results\\r\\n\\tplt.boxplot(scores)\\r\\n\\tplt.show()\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# evaluate model\\r\\n\\tscores, histories = evaluate_model(trainX, trainY)\\r\\n\\t# learning curves\\r\\n\\tsummarize_diagnostics(histories)\\r\\n\\t# summarize estimated performance\\r\\n\\tsummarize_performance(scores)\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109\\n\\n# baseline cnn model for mnistfrom numpy import meanfrom numpy import stdfrom matplotlib import pyplot as pltfrom sklearn.model_selection import KFoldfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dfrom tensorflow.keras.layers import Densefrom tensorflow.keras.layers import Flattenfrom tensorflow.keras.optimizers import SGD\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\xa0# evaluate a model using k-fold cross-validationdef evaluate_model(dataX, dataY, n_folds=5): scores, histories = list(), list() # prepare cross validation kfold = KFold(n_folds, shuffle=True, random_state=1) # enumerate splits for train_ix, test_ix in kfold.split(dataX): # define model model = define_model() # select rows for train and test trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix] # fit model history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0) # evaluate model _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0)) # stores scores scores.append(acc) histories.append(history) return scores, histories\\xa0# plot diagnostic learning curvesdef summarize_diagnostics(histories): for i in range(len(histories)): # plot loss plt.subplot(2, 1, 1) plt.title('Cross Entropy Loss') plt.plot(histories[i].history['loss'], color='blue', label='train') plt.plot(histories[i].history['val_loss'], color='orange', label='test') # plot accuracy plt.subplot(2, 1, 2) plt.title('Classification Accuracy') plt.plot(histories[i].history['accuracy'], color='blue', label='train') plt.plot(histories[i].history['val_accuracy'], color='orange', label='test') plt.show()\\xa0# summarize model performancedef summarize_performance(scores): # print summary print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores))) # box and whisker plots of results plt.boxplot(scores) plt.show()\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # evaluate model scores, histories = evaluate_model(trainX, trainY) # learning curves summarize_diagnostics(histories) # summarize estimated performance summarize_performance(scores)\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nRunning the example prints the classification accuracy for each fold of the cross-validation process. This is helpful to get an idea that the model evaluation is progressing.\\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\\nWe can see two cases where the model achieves perfect skill and one case where it achieved lower than 98% accuracy. These are good results.\\n\\n\\n\\n\\n\\n> 98.550\\r\\n> 98.600\\r\\n> 98.642\\r\\n> 98.850\\r\\n> 98.742\\n\\n\\n\\n\\n12345\\n\\n> 98.550> 98.600> 98.642> 98.850> 98.742\\n\\n\\n\\nNext, a diagnostic plot is shown, giving insight into the learning behavior of the model across each fold.\\nIn this case, we can see that the model generally achieves a good fit, with train and test learning curves converging. There is no obvious sign of over- or underfitting.\\nLoss and Accuracy Learning Curves for the Baseline Model During k-Fold Cross-Validation\\nNext, a summary of the model performance is calculated.\\nWe can see in this case, the model has an estimated skill of about 98.6%, which is reasonable.\\n\\n\\n\\n\\n\\nAccuracy: mean=98.677 std=0.107, n=5\\n\\n\\n\\n\\n1\\n\\nAccuracy: mean=98.677 std=0.107, n=5\\n\\n\\n\\nFinally, a box and whisker plot is created to summarize the distribution of accuracy scores.\\nBox and Whisker Plot of Accuracy Scores for the Baseline Model Evaluated Using k-Fold Cross-Validation\\nWe now have a robust test harness and a well-performing baseline model.\\nHow to Develop an Improved Model\\nThere are many ways that we might explore improvements to the baseline model.\\nWe will look at areas of model configuration that often result in an improvement, so-called low-hanging fruit. The first is a change to the learning algorithm, and the second is an increase in the depth of the model.\\nImprovement to Learning\\nThere are many aspects of the learning algorithm that can be explored for improvement.\\nPerhaps the point of biggest leverage is the learning rate, such as evaluating the impact that smaller or larger values of the learning rate may have, as well as schedules that change the learning rate during training.\\nAnother approach that can rapidly accelerate the learning of a model and can result in large performance improvements is batch normalization. We will evaluate the effect that batch normalization has on our baseline model.\\nBatch normalization can be used after convolutional and fully connected layers. It has the effect of changing the distribution of the output of the layer, specifically by standardizing the outputs. This has the effect of stabilizing and accelerating the learning process.\\nWe can update the model definition to use batch normalization after the activation function for the convolutional and dense layers of our baseline model. The updated version of define_model() function with batch normalization is listed below.\\n\\n\\n\\n\\n\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(BatchNormalization())\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(BatchNormalization())\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\n\\n\\n\\n\\n1234567891011121314\\n\\n# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(BatchNormalization()) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(BatchNormalization()) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\n\\n\\n\\nThe complete code listing with this change is provided below.\\n\\n\\n\\n\\n\\n# cnn model with batch normalization for mnist\\r\\nfrom numpy import mean\\r\\nfrom numpy import std\\r\\nfrom matplotlib import pyplot as plt\\r\\nfrom sklearn.model_selection import KFold\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\nfrom tensorflow.keras.models import Sequential\\r\\nfrom tensorflow.keras.layers import Conv2D\\r\\nfrom tensorflow.keras.layers import MaxPooling2D\\r\\nfrom tensorflow.keras.layers import Dense\\r\\nfrom tensorflow.keras.layers import Flatten\\r\\nfrom tensorflow.keras.optimizers import SGD\\r\\nfrom tensorflow.keras.layers import BatchNormalization\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(BatchNormalization())\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(BatchNormalization())\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\r\\n\\r\\n# evaluate a model using k-fold cross-validation\\r\\ndef evaluate_model(dataX, dataY, n_folds=5):\\r\\n\\tscores, histories = list(), list()\\r\\n\\t# prepare cross validation\\r\\n\\tkfold = KFold(n_folds, shuffle=True, random_state=1)\\r\\n\\t# enumerate splits\\r\\n\\tfor train_ix, test_ix in kfold.split(dataX):\\r\\n\\t\\t# define model\\r\\n\\t\\tmodel = define_model()\\r\\n\\t\\t# select rows for train and test\\r\\n\\t\\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\\r\\n\\t\\t# fit model\\r\\n\\t\\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\r\\n\\t\\t# evaluate model\\r\\n\\t\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\t\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\t\\t# stores scores\\r\\n\\t\\tscores.append(acc)\\r\\n\\t\\thistories.append(history)\\r\\n\\treturn scores, histories\\r\\n\\r\\n# plot diagnostic learning curves\\r\\ndef summarize_diagnostics(histories):\\r\\n\\tfor i in range(len(histories)):\\r\\n\\t\\t# plot loss\\r\\n\\t\\tplt.subplot(2, 1, 1)\\r\\n\\t\\tplt.title('Cross Entropy Loss')\\r\\n\\t\\tplt.plot(histories[i].history['loss'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\\r\\n\\t\\t# plot accuracy\\r\\n\\t\\tplt.subplot(2, 1, 2)\\r\\n\\t\\tplt.title('Classification Accuracy')\\r\\n\\t\\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\\r\\n\\tplt.show()\\r\\n\\r\\n# summarize model performance\\r\\ndef summarize_performance(scores):\\r\\n\\t# print summary\\r\\n\\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\\r\\n\\t# box and whisker plots of results\\r\\n\\tplt.boxplot(scores)\\r\\n\\tplt.show()\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# evaluate model\\r\\n\\tscores, histories = evaluate_model(trainX, trainY)\\r\\n\\t# learning curves\\r\\n\\tsummarize_diagnostics(histories)\\r\\n\\t# summarize estimated performance\\r\\n\\tsummarize_performance(scores)\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112\\n\\n# cnn model with batch normalization for mnistfrom numpy import meanfrom numpy import stdfrom matplotlib import pyplot as pltfrom sklearn.model_selection import KFoldfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dfrom tensorflow.keras.layers import Densefrom tensorflow.keras.layers import Flattenfrom tensorflow.keras.optimizers import SGDfrom tensorflow.keras.layers import BatchNormalization\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(BatchNormalization()) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(BatchNormalization()) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\xa0# evaluate a model using k-fold cross-validationdef evaluate_model(dataX, dataY, n_folds=5): scores, histories = list(), list() # prepare cross validation kfold = KFold(n_folds, shuffle=True, random_state=1) # enumerate splits for train_ix, test_ix in kfold.split(dataX): # define model model = define_model() # select rows for train and test trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix] # fit model history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0) # evaluate model _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0)) # stores scores scores.append(acc) histories.append(history) return scores, histories\\xa0# plot diagnostic learning curvesdef summarize_diagnostics(histories): for i in range(len(histories)): # plot loss plt.subplot(2, 1, 1) plt.title('Cross Entropy Loss') plt.plot(histories[i].history['loss'], color='blue', label='train') plt.plot(histories[i].history['val_loss'], color='orange', label='test') # plot accuracy plt.subplot(2, 1, 2) plt.title('Classification Accuracy') plt.plot(histories[i].history['accuracy'], color='blue', label='train') plt.plot(histories[i].history['val_accuracy'], color='orange', label='test') plt.show()\\xa0# summarize model performancedef summarize_performance(scores): # print summary print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores))) # box and whisker plots of results plt.boxplot(scores) plt.show()\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # evaluate model scores, histories = evaluate_model(trainX, trainY) # learning curves summarize_diagnostics(histories) # summarize estimated performance summarize_performance(scores)\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nRunning the example again reports model performance for each fold of the cross-validation process.\\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\\nWe can see perhaps a small drop in model performance as compared to the baseline across the cross-validation folds.\\n\\n\\n\\n\\n\\n> 98.475\\r\\n> 98.608\\r\\n> 98.683\\r\\n> 98.783\\r\\n> 98.667\\n\\n\\n\\n\\n12345\\n\\n> 98.475> 98.608> 98.683> 98.783> 98.667\\n\\n\\n\\nA plot of the learning curves is created, in this case showing that the speed of learning (improvement over epochs) does not appear to be different from the baseline model.\\nThe plots suggest that batch normalization, at least as implemented in this case, does not offer any benefit.\\nLoss and Accuracy Learning Curves for the BatchNormalization Model During k-Fold Cross-Validation\\nNext, the estimated performance of the model is presented, showing performance with a slight decrease in the mean accuracy of the model: 98.643 as compared to 98.677 with the baseline model.\\n\\n\\n\\n\\n\\nAccuracy: mean=98.643 std=0.101, n=5\\n\\n\\n\\n\\n1\\n\\nAccuracy: mean=98.643 std=0.101, n=5\\n\\n\\n\\nBox and Whisker Plot of Accuracy Scores for the BatchNormalization Model Evaluated Using k-Fold Cross-Validation\\nIncrease in Model Depth\\nThere are many ways to change the model configuration in order to explore improvements over the baseline model.\\nTwo common approaches involve changing the capacity of the feature extraction part of the model or changing the capacity or function of the classifier part of the model. Perhaps the point of biggest influence is a change to the feature extractor.\\nWe can increase the depth of the feature extractor part of the model, following a VGG-like pattern of adding more convolutional and pooling layers with the same sized filter, while increasing the number of filters. In this case, we will add a double convolutional layer with 64 filters each, followed by another max pooling layer.\\nThe updated version of the define_model() function with this change is listed below.\\n\\n\\n\\n\\n\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\n\\n\\n\\n\\n123456789101112131415\\n\\n# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\n\\n\\n\\nFor completeness, the entire code listing, including this change, is provided below.\\n\\n\\n\\n\\n\\n# deeper cnn model for mnist\\r\\nfrom numpy import mean\\r\\nfrom numpy import std\\r\\nfrom matplotlib import pyplot as plt\\r\\nfrom sklearn.model_selection import KFold\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\nfrom tensorflow.keras.models import Sequential\\r\\nfrom tensorflow.keras.layers import Conv2D\\r\\nfrom tensorflow.keras.layers import MaxPooling2D\\r\\nfrom tensorflow.keras.layers import Dense\\r\\nfrom tensorflow.keras.layers import Flatten\\r\\nfrom tensorflow.keras.optimizers import SGD\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\r\\n\\r\\n# evaluate a model using k-fold cross-validation\\r\\ndef evaluate_model(dataX, dataY, n_folds=5):\\r\\n\\tscores, histories = list(), list()\\r\\n\\t# prepare cross validation\\r\\n\\tkfold = KFold(n_folds, shuffle=True, random_state=1)\\r\\n\\t# enumerate splits\\r\\n\\tfor train_ix, test_ix in kfold.split(dataX):\\r\\n\\t\\t# define model\\r\\n\\t\\tmodel = define_model()\\r\\n\\t\\t# select rows for train and test\\r\\n\\t\\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\\r\\n\\t\\t# fit model\\r\\n\\t\\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\r\\n\\t\\t# evaluate model\\r\\n\\t\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\t\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\t\\t# stores scores\\r\\n\\t\\tscores.append(acc)\\r\\n\\t\\thistories.append(history)\\r\\n\\treturn scores, histories\\r\\n\\r\\n# plot diagnostic learning curves\\r\\ndef summarize_diagnostics(histories):\\r\\n\\tfor i in range(len(histories)):\\r\\n\\t\\t# plot loss\\r\\n\\t\\tplt.subplot(2, 1, 1)\\r\\n\\t\\tplt.title('Cross Entropy Loss')\\r\\n\\t\\tplt.plot(histories[i].history['loss'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\\r\\n\\t\\t# plot accuracy\\r\\n\\t\\tplt.subplot(2, 1, 2)\\r\\n\\t\\tplt.title('Classification Accuracy')\\r\\n\\t\\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\\r\\n\\tplt.show()\\r\\n\\r\\n# summarize model performance\\r\\ndef summarize_performance(scores):\\r\\n\\t# print summary\\r\\n\\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\\r\\n\\t# box and whisker plots of results\\r\\n\\tplt.boxplot(scores)\\r\\n\\tplt.show()\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# evaluate model\\r\\n\\tscores, histories = evaluate_model(trainX, trainY)\\r\\n\\t# learning curves\\r\\n\\tsummarize_diagnostics(histories)\\r\\n\\t# summarize estimated performance\\r\\n\\tsummarize_performance(scores)\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112\\n\\n# deeper cnn model for mnistfrom numpy import meanfrom numpy import stdfrom matplotlib import pyplot as pltfrom sklearn.model_selection import KFoldfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dfrom tensorflow.keras.layers import Densefrom tensorflow.keras.layers import Flattenfrom tensorflow.keras.optimizers import SGD\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\xa0# evaluate a model using k-fold cross-validationdef evaluate_model(dataX, dataY, n_folds=5): scores, histories = list(), list() # prepare cross validation kfold = KFold(n_folds, shuffle=True, random_state=1) # enumerate splits for train_ix, test_ix in kfold.split(dataX): # define model model = define_model() # select rows for train and test trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix] # fit model history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0) # evaluate model _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0)) # stores scores scores.append(acc) histories.append(history) return scores, histories\\xa0# plot diagnostic learning curvesdef summarize_diagnostics(histories): for i in range(len(histories)): # plot loss plt.subplot(2, 1, 1) plt.title('Cross Entropy Loss') plt.plot(histories[i].history['loss'], color='blue', label='train') plt.plot(histories[i].history['val_loss'], color='orange', label='test') # plot accuracy plt.subplot(2, 1, 2) plt.title('Classification Accuracy') plt.plot(histories[i].history['accuracy'], color='blue', label='train') plt.plot(histories[i].history['val_accuracy'], color='orange', label='test') plt.show()\\xa0# summarize model performancedef summarize_performance(scores): # print summary print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores))) # box and whisker plots of results plt.boxplot(scores) plt.show()\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # evaluate model scores, histories = evaluate_model(trainX, trainY) # learning curves summarize_diagnostics(histories) # summarize estimated performance summarize_performance(scores)\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nRunning the example reports model performance for each fold of the cross-validation process.\\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\\nThe per-fold scores may suggest some improvement over the baseline.\\n\\n\\n\\n\\n\\n> 99.058\\r\\n> 99.042\\r\\n> 98.883\\r\\n> 99.192\\r\\n> 99.133\\n\\n\\n\\n\\n12345\\n\\n> 99.058> 99.042> 98.883> 99.192> 99.133\\n\\n\\n\\nA plot of the learning curves is created, in this case showing that the models still have a good fit on the problem, with no clear signs of overfitting. The plots may even suggest that further training epochs could be helpful.\\nLoss and Accuracy Learning Curves for the Deeper Model During k-Fold Cross-Validation\\nNext, the estimated performance of the model is presented, showing a small improvement in performance as compared to the baseline from 98.677 to 99.062, with a small drop in the standard deviation as well.\\n\\n\\n\\n\\n\\nAccuracy: mean=99.062 std=0.104, n=5\\n\\n\\n\\n\\n1\\n\\nAccuracy: mean=99.062 std=0.104, n=5\\n\\n\\n\\nBox and Whisker Plot of Accuracy Scores for the Deeper Model Evaluated Using k-Fold Cross-Validation\\nHow to Finalize the Model and Make Predictions\\nThe process of model improvement may continue for as long as we have ideas and the time and resources to test them out.\\nAt some point, a final model configuration must be chosen and adopted. In this case, we will choose the deeper model as our final model.\\nFirst, we will finalize our model, but fitting a model on the entire training dataset and saving the model to file for later use. We will then load the model and evaluate its performance on the hold out test dataset to get an idea of how well the chosen model actually performs in practice. Finally, we will use the saved model to make a prediction on a single image.\\nSave Final Model\\nA final model is typically fit on all available data, such as the combination of all train and test dataset.\\nIn this tutorial, we are intentionally holding back a test dataset so that we can estimate the performance of the final model, which can be a good idea in practice. As such, we will fit our model on the training dataset only.\\n\\n\\n\\n\\n\\n# fit model\\r\\nmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\\n\\n\\n\\n\\n12\\n\\n# fit modelmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\\n\\n\\n\\nOnce fit, we can save the final model to an H5 file by calling the save() function on the model and pass in the chosen filename.\\n\\n\\n\\n\\n\\n# save model\\r\\nmodel.save('final_model.h5')\\n\\n\\n\\n\\n12\\n\\n# save modelmodel.save('final_model.h5')\\n\\n\\n\\nNote, saving and loading a Keras model requires that the h5py library is installed on your workstation.\\nThe complete example of fitting the final deep model on the training dataset and saving it to file is listed below.\\n\\n\\n\\n\\n\\n# save the final model to file\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\nfrom tensorflow.keras.models import Sequential\\r\\nfrom tensorflow.keras.layers import Conv2D\\r\\nfrom tensorflow.keras.layers import MaxPooling2D\\r\\nfrom tensorflow.keras.layers import Dense\\r\\nfrom tensorflow.keras.layers import Flatten\\r\\nfrom tensorflow.keras.optimizers import SGD\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# define model\\r\\n\\tmodel = define_model()\\r\\n\\t# fit model\\r\\n\\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\\r\\n\\t# save model\\r\\n\\tmodel.save('final_model.h5')\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364\\n\\n# save the final model to filefrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dfrom tensorflow.keras.layers import Densefrom tensorflow.keras.layers import Flattenfrom tensorflow.keras.optimizers import SGD\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # define model model = define_model() # fit model model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0) # save model model.save('final_model.h5')\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nAfter running this example, you will now have a 1.2-megabyte file with the name ‘final_model.h5‘ in your current working directory.\\nEvaluate Final Model\\nWe can now load the final model and evaluate it on the hold out test dataset.\\nThis is something we might do if we were interested in presenting the performance of the chosen model to project stakeholders.\\nThe model can be loaded via the load_model() function.\\nThe complete example of loading the saved model and evaluating it on the test dataset is listed below.\\n\\n\\n\\n\\n\\n# evaluate the deep model on the test dataset\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.models import load_model\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# load model\\r\\n\\tmodel = load_model('final_model.h5')\\r\\n\\t# evaluate model on test dataset\\r\\n\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n123456789101112131415161718192021222324252627282930313233343536373839404142\\n\\n# evaluate the deep model on the test datasetfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.models import load_modelfrom tensorflow.keras.utils import to_categorical\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # load model model = load_model('final_model.h5') # evaluate model on test dataset _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0))\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nRunning the example loads the saved model and evaluates the model on the hold out test dataset.\\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\\nThe classification accuracy for the model on the test dataset is calculated and printed. In this case, we can see that the model achieved an accuracy of 99.090%, or just less than 1%, which is not bad at all and reasonably close to the estimated 99.753% with a standard deviation of about half a percent (e.g. 99% of scores).\\n\\n\\n\\n\\n\\n> 99.090\\n\\n\\n\\n\\n1\\n\\n> 99.090\\n\\n\\n\\n\\nMake Prediction\\nWe can use our saved model to make a prediction on new images.\\nThe model assumes that new images are grayscale, that they have been aligned so that one image contains one centered handwritten digit, and that the size of the image is square with the size 28×28 pixels.\\nBelow is an image extracted from the MNIST test dataset. You can save it in your current working directory with the filename ‘sample_image.png‘.\\nSample Handwritten Digit\\n\\nDownload the sample image (sample_image.png)\\n\\nWe will pretend this is an entirely new and unseen image, prepared in the required way, and see how we might use our saved model to predict the integer that the image represents (e.g. we expect “7“).\\nFirst, we can load the image, force it to be in grayscale format, and force the size to be 28×28 pixels. The loaded image can then be resized to have a single channel and represent a single sample in a dataset. The load_image() function implements this and will return the loaded image ready for classification.\\nImportantly, the pixel values are prepared in the same way as the pixel values were prepared for the training dataset when fitting the final model, in this case, normalized.\\n\\n\\n\\n\\n\\n# load and prepare the image\\r\\ndef load_image(filename):\\r\\n\\t# load the image\\r\\n\\timg = load_img(filename, grayscale=True, target_size=(28, 28))\\r\\n\\t# convert to array\\r\\n\\timg = img_to_array(img)\\r\\n\\t# reshape into a single sample with 1 channel\\r\\n\\timg = img.reshape(1, 28, 28, 1)\\r\\n\\t# prepare pixel data\\r\\n\\timg = img.astype('float32')\\r\\n\\timg = img / 255.0\\r\\n\\treturn img\\n\\n\\n\\n\\n123456789101112\\n\\n# load and prepare the imagedef load_image(filename): # load the image img = load_img(filename, grayscale=True, target_size=(28, 28)) # convert to array img = img_to_array(img) # reshape into a single sample with 1 channel img = img.reshape(1, 28, 28, 1) # prepare pixel data img = img.astype('float32') img = img / 255.0 return img\\n\\n\\n\\nNext, we can load the model as in the previous section and call the predict() function to get the predicted score, and then use argmax() to obtain the digit that the image represents.\\n\\n\\n\\n\\n\\n# predict the class\\r\\npredict_value = model.predict(img)\\r\\ndigit = argmax(predict_value)\\n\\n\\n\\n\\n123\\n\\n# predict the classpredict_value = model.predict(img)digit = argmax(predict_value)\\n\\n\\n\\nThe complete example is listed below.\\n\\n\\n\\n\\n\\n# make a prediction for a new image.\\r\\nfrom numpy import argmax\\r\\nfrom keras.preprocessing.image import load_img\\r\\nfrom keras.preprocessing.image import img_to_array\\r\\nfrom keras.models import load_model\\r\\n\\r\\n# load and prepare the image\\r\\ndef load_image(filename):\\r\\n\\t# load the image\\r\\n\\timg = load_img(filename, grayscale=True, target_size=(28, 28))\\r\\n\\t# convert to array\\r\\n\\timg = img_to_array(img)\\r\\n\\t# reshape into a single sample with 1 channel\\r\\n\\timg = img.reshape(1, 28, 28, 1)\\r\\n\\t# prepare pixel data\\r\\n\\timg = img.astype('float32')\\r\\n\\timg = img / 255.0\\r\\n\\treturn img\\r\\n\\r\\n# load an image and predict the class\\r\\ndef run_example():\\r\\n\\t# load the image\\r\\n\\timg = load_image('sample_image.png')\\r\\n\\t# load model\\r\\n\\tmodel = load_model('final_model.h5')\\r\\n\\t# predict the class\\r\\n\\tpredict_value = model.predict(img)\\r\\n\\tdigit = argmax(predict_value)\\r\\n\\tprint(digit)\\r\\n\\r\\n# entry point, run the example\\r\\nrun_example()\\n\\n\\n\\n\\n1234567891011121314151617181920212223242526272829303132\\n\\n# make a prediction for a new image.from numpy import argmaxfrom keras.preprocessing.image import load_imgfrom keras.preprocessing.image import img_to_arrayfrom keras.models import load_model\\xa0# load and prepare the imagedef load_image(filename): # load the image img = load_img(filename, grayscale=True, target_size=(28, 28)) # convert to array img = img_to_array(img) # reshape into a single sample with 1 channel img = img.reshape(1, 28, 28, 1) # prepare pixel data img = img.astype('float32') img = img / 255.0 return img\\xa0# load an image and predict the classdef run_example(): # load the image img = load_image('sample_image.png') # load model model = load_model('final_model.h5') # predict the class predict_value = model.predict(img) digit = argmax(predict_value) print(digit)\\xa0# entry point, run the examplerun_example()\\n\\n\\n\\nRunning the example first loads and prepares the image, loads the model, and then correctly predicts that the loaded image represents the digit ‘7‘.\\n\\n\\n\\n\\n\\n7\\n\\n\\n\\n\\n1\\n\\n7\\n\\n\\n\\n\\nExtensions\\nThis section lists some ideas for extending the tutorial that you may wish to explore.\\n\\nTune Pixel Scaling. Explore how alternate pixel scaling methods impact model performance as compared to the baseline model, including centering and standardization.\\nTune the Learning Rate. Explore how different learning rates impact the model performance as compared to the baseline model, such as 0.001 and 0.0001.\\nTune Model Depth. Explore how adding more layers to the model impact the model performance as compared to the baseline model, such as another block of convolutional and pooling layers or another dense layer in the classifier part of the model.\\n\\nIf you explore any of these extensions, I’d love to know.\\nPost your findings in the comments below.\\nFurther Reading\\nThis section provides more resources on the topic if you are looking to go deeper.\\nAPIs\\n\\nKeras Datasets API\\nKeras Datasets Code\\nsklearn.model_selection.KFold API\\n\\nArticles\\n\\nMNIST database, Wikipedia.\\nClassification datasets results, What is the class of this image?\\n\\nSummary\\nIn this tutorial, you discovered how to develop a convolutional neural network for handwritten digit classification from scratch.\\nSpecifically, you learned:\\n\\nHow to develop a test harness to develop a robust evaluation of a model and establish a baseline of performance for a classification task.\\nHow to explore extensions to a baseline model to improve learning and model capacity.\\nHow to develop a finalized model, evaluate the performance of the final model, and use it to make predictions on new images.\\n\\nDo you have any questions?\\nAsk your questions in the comments below and I will do my best to answer.\\n\\n\\nDevelop Deep Learning Models for Vision Today!\\n\\nDevelop Your Own Vision Models in Minutes\\n...with just a few lines of python code\\nDiscover how in my new Ebook:\\nDeep Learning for Computer Vision\\nIt provides self-study tutorials on topics like:\\nclassification, object detection (yolo and rcnn), face recognition (vggface and facenet), data preparation and much more...\\nFinally Bring Deep Learning to your Vision Projects\\nSkip the Academics. Just Results.\\nSee What's Inside\\n\\n\\n\\n\\nShare  \\n\\nTweet \\n\\n        \\nShare \\n\\nMore On This TopicHow to Develop a GAN for Generating MNIST Handwritten DigitsHandwritten Digit Recognition Using Convolutional…Handwritten Digit Recognition with LeNet5 Model in PyTorchDeep Learning CNN for Fashion-MNIST Clothing ClassificationHow to Develop a Multichannel CNN Model for Text…How to Develop a CNN From Scratch for CIFAR-10 Photo… \\n\\n\\n\\n\\nAbout Jason Brownlee\\nJason Brownlee, PhD is a machine learning specialist who teaches developers how to get results with modern machine learning methods via hands-on tutorials. \\n\\nView all posts by Jason Brownlee → \\n\\n\\n\\n\\n\\n\\n\\n How to Visualize Filters and Feature Maps in Convolutional Neural Networks\\nDeep Learning CNN for Fashion-MNIST Clothing Classification \\n\\n\\n 188 Responses to How to Develop a CNN for MNIST Handwritten Digit Classification\\n\\n\\n\\n\\n\\nSHAHEEN ALHIRMIZY\\nMay 10, 2019 at 4:32 pm\\n#\\n\\n\\n\\nDear Jason Thank You Very Much For your wonderful Tutorial Please can you build for us A model for Edge detection from scratch using real images.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 11, 2019 at 6:05 am\\n#\\n\\n\\n\\nGreat suggestion, thanks.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSHAHEEN ALHIRMIZY\\nMay 10, 2019 at 4:47 pm\\n#\\n\\n\\n\\nI have two questions :\\nfirst suppose I have images sizes equal to 7611 x 7811 how to deal with this big size images in CNN models.\\nsecond question about if our images different sizes not same size.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 11, 2019 at 6:06 am\\n#\\n\\n\\n\\nI recommend reducing the size of your images first, before modeling, e.g. less than 1000 pixels, even less than 500 pixels if you can.\\nI then recommend normalizing images to the same size.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nvinay\\nSeptember 30, 2019 at 11:47 am\\n#\\n\\n\\n\\nto reduce the size of the images, which approach is better. Using machine learning or normal image compression methods.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nSeptember 30, 2019 at 2:26 pm\\n#\\n\\n\\n\\nUse image compression algorithms.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSHAHEEN ALHIRMIZY\\nMay 11, 2019 at 4:13 pm\\n#\\n\\n\\n\\nwhen we reducing the size of images that means losing many fine details from these images\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 12, 2019 at 6:38 am\\n#\\n\\n\\n\\nOften it does.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTaranpreetkaur\\nOctober 12, 2019 at 10:57 pm\\n#\\n\\n\\n\\nHow u make this project please help us … We can’t understand how we make this project … Taranpreetkaur\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 13, 2019 at 8:30 am\\n#\\n\\n\\n\\nWhat problem are you having exactly?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAjoy\\nOctober 20, 2019 at 4:08 am\\n#\\n\\n\\n\\nOriginal error was: No module named _multiarray_umath, keras .imageprocessing\\nImporting the numpy c-extensions failed.\\nAny ideas please\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 20, 2019 at 6:23 am\\n#\\n\\n\\n\\nSorry to hear that.\\nPerhaps try checking that your version of Keras and TensorFlow are up to date?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAjoy\\nOctober 20, 2019 at 7:18 pm\\n#\\n\\n\\n\\nSorry dont worry, I somehow got to resolve it. I think I reinstalled stuff.\\nI have another problem though. How do I add data for learning if in case the data predicted the wrong valiue pelase. I think I need the advise for both how to add as well as how to add the data in the mnist data format. Thanks\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 21, 2019 at 6:17 am\\n#\\n\\n\\n\\nHappy to hear that.\\nPerhaps you can refit your model as you get access to new data?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAjoy\\nOctober 20, 2019 at 7:51 pm\\n#\\n\\n\\n\\nJason you know what, for “17” it returned “7”. Thats actually good, but if you could please tip me as to how can I turn this into “Awesome.” Can I divide the pixel data into 2 dividions based on whitespace or what would be the best way please to recognize “17”. Thanks\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 21, 2019 at 6:17 am\\n#\\n\\n\\n\\nI believe the model supports one character at a time, try splitting multiple characters up into single character input.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJubayed\\nNovember 26, 2019 at 10:13 pm\\n#\\n\\n\\n\\nGreat!! I enjoyed very well.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nNovember 27, 2019 at 6:05 am\\n#\\n\\n\\n\\nThanks!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVictor Johns\\nNovember 27, 2019 at 3:43 am\\n#\\n\\n\\n\\nJason,\\nThanks much for this tutorial. I had a question on the structure of the CNN. In this (and other descriptions of this problem for the MNIST digit data set) a common structure seems to be that the number of CNN filters is 32. Where each filter is a 5×5 of stride 1. However (and I apologize if this is explained somewhere) I cannot seem to find why 32 filters are chosen. i.e. Why not 16 or 64 ( or 14 or 28). Is it possible to explain why this is so. \\nRegards\\nVictor\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nNovember 27, 2019 at 6:13 am\\n#\\n\\n\\n\\nIt is arbitrary.\\nTry different numbers of filters and compare the results.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSamuel\\nDecember 11, 2019 at 8:36 am\\n#\\n\\n\\n\\nJason,\\nThank you for the detailed explanation of this. I wanted to run your code and follow along to see how it worked. When I tried to run the complete example for the baseline cnn model for mnist, I get the following error:\\nKeyError Traceback (most recent call last)\\nin\\n107\\n108 # entry point, run the test harness\\n–> 109 run_test_harness()\\n in run_test_harness()\\n102 scores, histories = evaluate_model(model, trainX, trainY)\\n103 # learning curves\\n–> 104 summarize_diagnostics(histories)\\n105 # summarize estimated performance\\n106 summarize_performance(scores)\\n in summarize_diagnostics(histories)\\n79 pyplot.subplot(212)\\n80 pyplot.title(‘Classification Accuracy’)\\n—> 81 pyplot.plot(histories[i].history[‘acc’], color=’blue’, label=’train’)\\n82 pyplot.plot(histories[i].history[‘val_acc’], color=’orange’, label=’test’)\\n83 pyplot.show()\\nKeyError: ‘acc’\\nAny ideas what it means?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 11, 2019 at 1:41 pm\\n#\\n\\n\\n\\nYes, the API has changed. \\nI have updated the example. \\nThanks for letting me know!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nXenon\\nDecember 12, 2019 at 5:16 am\\n#\\n\\n\\n\\nplease how can i Train a simple convolutional network for number recognition (MNIST). Thanks. that’s what i want to see.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 12, 2019 at 6:33 am\\n#\\n\\n\\n\\nSee the above tutorial for an example.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVivek\\nDecember 23, 2019 at 10:30 pm\\n#\\n\\n\\n\\nI want to create a image exactly same as mnist using mspaint for example and test it using the mnist evaluation model using predict_classes API.\\nIs it possible without using python API.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 24, 2019 at 6:42 am\\n#\\n\\n\\n\\nI don’t see why not.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlexander Soare\\nDecember 27, 2019 at 8:00 am\\n#\\n\\n\\n\\nHi Jason,\\nThanks for the excellent tutorial! I have two questions about K-fold cross-validation. In your “gentle introduction” article you say that the model is discarded each time we switch the hold out set. So here are my questions\\n1) Here it looks like you don’t discard the model between iterations of the k-fold cross validation. Why?\\n2) The model’s accuracy gets better each time you do an iteration. Why is taking a simple average fair then? To take it to the extreme: What if you only trained on 1 epoch? Then you’d get 94% on your first fold, then 98.5% on your second fold. And so on, yielding a much poorer average and a huge standard deviation. On the back of this question, I’d also ask why the standard deviation is a fair representation of the model under these circumstances.\\nThanks again for the great material!\\nAlex\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 28, 2019 at 7:38 am\\n#\\n\\n\\n\\nYou’re welcome.\\nThat looks like an error. I will update the tutorial.\\nThanks for point it out!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlexander Soare\\nDecember 29, 2019 at 5:43 am\\n#\\n\\n\\n\\nThanks for picking up my previous question Jason. I have another. You say at some point that there are no clear signs of overfitting. But it looks like the orange lines for the validation accuracy are staying relatively low compared to the blue lines for the testing accuracy. Is this not an indicator of overfitting? Or am I misinterpreting the charts?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 29, 2019 at 6:09 am\\n#\\n\\n\\n\\nExcellent question Alexander.\\nThey are close enough that I would not classify it as overfitting, instead it is a good fit:\\nhttps://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnja\\nJanuary 3, 2020 at 3:02 pm\\n#\\n\\n\\n\\nHello Jason,\\nWhen I execute the final code I get following error: “AttributeError: module ‘tensorflow’ has no attribute ‘get_default_graph”. I have installed Tensorflow 2.0, will downgrading it to the previous version solve this problem?\\nThank you for your time and this amazing post!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJanuary 4, 2020 at 8:24 am\\n#\\n\\n\\n\\nConfirm you have Keras 2.3 and Tensorflow 2.0 installed.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAnja\\nJanuary 6, 2020 at 12:51 pm\\n#\\n\\n\\n\\nHello Jason,\\nI have Tensorflow 2.0 and Keras 2.2.4. I tried updating Keras to 2.3 but can not find the way on Windows 10. I tried also switching to Linux on VB but I have a hard time with permissions there. Do you have any advice for me, I would be really grateful?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJanuary 6, 2020 at 1:31 pm\\n#\\n\\n\\n\\nYou can try:\\n\\n\\n\\n\\n\\n\\npip install keras\\n\\n\\n\\n\\n1\\n\\npip install keras\\n\\n\\n\\n\\nOr, if you are on anaconda:\\n\\n\\n\\n\\n\\n\\nconda install -c conda-forge keras\\n\\n\\n\\n\\n1\\n\\nconda install -c conda-forge keras\\n\\n\\n\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDmytro\\nFebruary 4, 2020 at 7:44 am\\n#\\n\\n\\n\\nHello Jason,\\nThank you for the tutorial and all the answers!\\nI have my own set of images, each class in a separate folder. What should I do to upload the dataset instead of writing\\n# load dataset\\n(trainX, trainY), (testX, testY) = mnist.load_data()\\nIt would be great if you can give some advice!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 4, 2020 at 8:02 am\\n#\\n\\n\\n\\nHere is an example:\\nhttps://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDmytro\\nFebruary 5, 2020 at 4:00 pm\\n#\\n\\n\\n\\nThank you!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 6, 2020 at 8:18 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSARVANI CH\\nMarch 14, 2020 at 9:11 pm\\n#\\n\\n\\n\\nHi Jason,\\nThanks for the article!!!\\nDo you have any plans to implement “Information bottleneck theory” i.e, finding mainly the mutual information among various layers in an architecture?\\nDoes it seem simpler or a harder one for you??\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 15, 2020 at 6:13 am\\n#\\n\\n\\n\\nI have not heard of it sorry, do you have a link?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSWETHA\\nMarch 20, 2020 at 1:05 pm\\n#\\n\\n\\n\\ndef load_image(filename):\\n# load the image\\nimg = load_img(filename, grayscale=True, target_size=(28, 28))\\n# convert to array\\nimg = img_to_array(img)\\n# reshape into a single sample with 1 channel\\nimg = img.reshape(1, 28, 28, 1)\\n# prepare pixel data\\nimg = img.astype(‘float32’)\\nimg = img / 255.0\\nreturn img\\nwhat does the ‘filename’ mean in the above code?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 20, 2020 at 1:20 pm\\n#\\n\\n\\n\\nIt’s an argument to the function – the name of the file you want to load.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nSWETHA\\nMarch 20, 2020 at 2:17 pm\\n#\\n\\n\\n\\nDid you mean the saved model’s filename?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 21, 2020 at 8:17 am\\n#\\n\\n\\n\\nNo, the function loads an image as it’s name suggests.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSWETHA\\nMarch 20, 2020 at 1:48 pm\\n#\\n\\n\\n\\nThank you!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 21, 2020 at 8:16 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nElbhednam\\nMarch 26, 2020 at 6:52 am\\n#\\n\\n\\n\\nWhat is the purpose of reshaping the data to a single color channel? Is it necessary for the 2D convolution step in the model definition? I ask because other digit classification examples I’ve looked at go straight to flattening the train/test data but those didn’t have a 2D convolution layer.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 26, 2020 at 8:07 am\\n#\\n\\n\\n\\nThe CNN layer expects data to have a 3d shape including a channels dimension:\\nhttps://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEdward\\nApril 13, 2020 at 5:00 am\\n#\\n\\n\\n\\nIf one wanted to create a new MNIST how would they set the data up? In these examples we get to use curated datasets from a dispensary but that does not explain how to set up your data to run the model.\\nFor example what if I wanted to create my own MNIST to determine if the picture is a poker card, how would I go about setting the pictures and telling the machine what that picture is?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 13, 2020 at 6:22 am\\n#\\n\\n\\n\\nGood question, see this:\\nhttps://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmit Baghel\\nApril 15, 2020 at 3:53 pm\\n#\\n\\n\\n\\nhi Jason Brownlee,\\ni want to make model handwriting alphbet so please suggest which dataset is good\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 16, 2020 at 5:57 am\\n#\\n\\n\\n\\nPerhaps this will help:\\nhttps://machinelearningmastery.com/faq/single-faq/where-can-i-get-a-dataset-on-___\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNawal\\nApril 17, 2020 at 6:03 pm\\n#\\n\\n\\n\\nJason, Thank you so much for sharing your knowledge. I just started learning python, tensorflow and machine learning. I understood all the maths and processes but was having difficulty in coding. Your example worked first time. Brilliant.\\nDo you have a simpler example of CNN with just 4 hidden layers as follows:\\n1. Input layer of 784 nodes\\n2. First convolution later : 5x5x32\\n3. First max pooling layer\\n4. Second convolution layer 5x5x64\\n5. Second max pooling layer\\n6. Out put layer of 10 nodes\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 18, 2020 at 5:42 am\\n#\\n\\n\\n\\nThanks.\\nYou can adapt the above example to this directly if you like.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJoyce\\nMay 4, 2020 at 6:03 am\\n#\\n\\n\\n\\nHi Jason. Can I ask why did you reshape the data? The image from the MNIST are already grey scale which are 1 channel. I am not quite understand why you need to do this step. Also what does the trainx.shape[0]/testX.shape[0] do here?\\n# reshape dataset to have a single channel\\ntrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\ntestX = testX.reshape((testX.shape[0], 28, 28, 1))\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 4, 2020 at 6:28 am\\n#\\n\\n\\n\\nInputs to CNNs must have the channel defined explicitly, which is not the case by default for grayscale images.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmy\\nMay 4, 2020 at 6:30 am\\n#\\n\\n\\n\\nCan I ask why the hot encode is 10 binary vectors? Why choose 10?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 4, 2020 at 6:33 am\\n#\\n\\n\\n\\nBecause there are 10 classes.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRuslaniv\\nMay 7, 2020 at 9:20 pm\\n#\\n\\n\\n\\nHi Jason! Thank you so much, this is a great tutorial!\\nJust one question, i’m somewhat confused.\\nAre training our model twice? Once with k-fold validation and then right before saving it, with model.fit?\\n====\\nmodel = define_model()\\nmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\\nmodel.save(‘final_model.h5’)\\n====\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 8, 2020 at 6:31 am\\n#\\n\\n\\n\\nCross-validation will train k models and is used to estimate the performance when making predictions on new data. These models are discarded.\\nOnce we choose a final model config, we fit a model on all data and use it to start making predictions.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nRuslaniv\\nMay 11, 2020 at 8:20 pm\\n#\\n\\n\\n\\nGreat, that’s what I thought! Thank you again for this amazing tutorial.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 12, 2020 at 6:43 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThenerd\\nFebruary 5, 2021 at 3:05 am\\n#\\n\\n\\n\\nIn the k fold cross validation a new model is defined for each k iteration. So does that mean a new model is trained each time? But then what is the use of training new models in each iteration? \\nBy model config you mean an optimal define_model? And once an optimal model is fixed we train on the entire training set? I am not able to relate how will K iterations in the K-fold reflect our understanding of what model configuration is the best.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 5, 2021 at 5:46 am\\n#\\n\\n\\n\\nYes, a new model is trained each iteration, evaluated, and discarded.\\nThe purpose is to estimate the performance of the model configuration when making predictions on unseen data for your prediction problem.\\nOnce we have this estimate, we can choose to use the configuration (compared to other configurations). A final model can be fit on all data and we can start making predictions for real on new data where we don’t know the label.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nThenerd\\nFebruary 10, 2021 at 7:21 am\\n#\\n\\n\\n\\nThankyou very much. I had another question. I was trying to run the final model on the unseen test data. however for each run the results vary ofcourse. therefore i decided to run this over 10 runs and average the test results, something like monte carlo simulation. but again in that case where would model = define_model() be places? would that be placed inside the for loop for average or just be defined once before running these 10 iterations, considering this average results is on the test data. since in kfold you discard it.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 10, 2021 at 8:13 am\\n#\\n\\n\\n\\nYou’re welcome.\\nYes, you can reduce variance in prediction by fitting multiple final models and averaging their predictions:\\nhttps://machinelearningmastery.com/how-to-reduce-model-variance/\\nThis has a code example:\\nhttps://machinelearningmastery.com/model-averaging-ensemble-for-deep-learning-neural-networks/\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGohel vivek\\nMay 11, 2020 at 6:02 pm\\n#\\n\\n\\n\\nIf i am writing this all by making a class name -mnist_classification then \\nAttributeError: ‘mnist_classification’ object has no attribute ‘astype’\\nthis .astype error is coming please sir can you help me to figure this out\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 12, 2020 at 6:40 am\\n#\\n\\n\\n\\nSorry to hear that, this will help:\\nhttps://machinelearningmastery.com/faq/single-faq/why-does-the-code-in-the-tutorial-not-work-for-me\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRamya\\nJune 2, 2020 at 7:01 am\\n#\\n\\n\\n\\nHi Jason,\\nThanks for this tutorial. It’s very helpful.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 2, 2020 at 7:55 am\\n#\\n\\n\\n\\nYou’re welcome, I’m happy to hear that.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMilind Naidu\\nJune 21, 2020 at 11:28 pm\\n#\\n\\n\\n\\nHi, i am trying to build a CNN fo the same problem. My output layer has 10 neurons. When i try to fit my model after One-Hot_encoding of y_train and y_test, i get an error that the labels and the logits don’t match. However, without the one-hot encoding the model fits perfectly. Can you please explain?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 22, 2020 at 6:14 am\\n#\\n\\n\\n\\nPerhaps you can use the above tutorial as a starting point and adapt it for your project?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWilliam\\nJuly 19, 2020 at 8:48 pm\\n#\\n\\n\\n\\nThis is the best article about MNIST, but I have a question “Is it necessary to use a GPU with high performance in order to running these codes?”\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJuly 20, 2020 at 6:12 am\\n#\\n\\n\\n\\nThanks!\\nNo, you can run on CPU, it might just take more minutes to run.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSandhya\\nJuly 31, 2020 at 3:58 pm\\n#\\n\\n\\n\\nHi Jason\\nThanks for this amazing tutorial. It will definitely help a lot of budding researchers.\\nI have a question\\nCan you please help if instead of single character i have to work on complete self taken handwritten word image (20 different classes,total around 20000 images). How to do it?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nAugust 1, 2020 at 6:07 am\\n#\\n\\n\\n\\nPerhaps the letters in each word images can first be segmented, then classified.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nSandhya\\nAugust 1, 2020 at 5:39 pm\\n#\\n\\n\\n\\nthanks for the reply but i want to do it using segmentation free approach\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nAugust 2, 2020 at 5:39 am\\n#\\n\\n\\n\\nPerhaps use a CNN to read the images and an LSTM to interpret the image features and output one letter at a time.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nPrasad Bapardekar\\nMarch 16, 2023 at 3:07 am\\n#\\n\\n\\n\\nPerhaps use a CNN to read the images and an LSTM to interpret the image features and output one letter at a time.\\nCan you please share more detail how to do it.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMarch 16, 2023 at 7:08 am\\n#\\n\\n\\n\\nHi Prasad…You may want to consider a CNN-LSTM model for your purpose:\\nhttps://machinelearningmastery.com/cnn-long-short-term-memory-networks/\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSandhya\\nJuly 31, 2020 at 4:14 pm\\n#\\n\\n\\n\\nhi Jason\\nThanks for this amazing tutorial.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nAugust 1, 2020 at 6:07 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nzulfiqar ali\\nOctober 18, 2020 at 9:46 am\\n#\\n\\n\\n\\nThanks, Jason Brownlee for this excellent tutorial. I am your huge fan and I regularly following your all machine learning and deep earning models.I got a lot of knowledge from this site but After completion of machine learning tutorials there always raise a question in my mind that how can we apply these models in Mobile APPs(Andriod, iOS, etc) so that we get more fun and knowledge by this models. Are you suggest to me any link to have such kind of projects such as weather prediction app . Thanks again.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 18, 2020 at 1:25 pm\\n#\\n\\n\\n\\nThanks.\\nSorry, I don’t know about using models on mobile.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nNovember 28, 2021 at 5:17 pm\\n#\\n\\n\\n\\nI know this is a year late, but see this for a mobile app based on tensorflow and keras: https://medium.com/@timanglade/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nZunaira Shafqat\\nOctober 23, 2020 at 4:49 am\\n#\\n\\n\\n\\nThanks for the tutorial Jason Brownlee.\\nCan I use same model but pass my own dataset (of humans) to it & use it for detecting fall or not fall by making small changes?\\nThanks.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 23, 2020 at 6:17 am\\n#\\n\\n\\n\\nSure.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPreethi\\nNovember 12, 2020 at 3:28 pm\\n#\\n\\n\\n\\nHi do you have any projects done based on Wireless and Mobile Network except human activity recognition using smart phone\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nNovember 13, 2020 at 6:32 am\\n#\\n\\n\\n\\nI don’t think so. Perhaps try the blog search.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArchna\\nNovember 13, 2020 at 7:01 pm\\n#\\n\\n\\n\\nThanks for the detailed explanation !!\\nCan you pls do a tutorial on colorization without using pretratined model\\nThanks in advance\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nNovember 14, 2020 at 6:30 am\\n#\\n\\n\\n\\nGreat suggestion, thanks!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nArchna\\nNovember 24, 2020 at 6:31 pm\\n#\\n\\n\\n\\nWaiting for the same 🙂\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEbdulmomen\\nDecember 7, 2020 at 8:53 am\\n#\\n\\n\\n\\nhey jason that was a very good tutorial, i did not understand how in the predict_classes we got 7? the model had a softmax activation function as the last layer which will be a probability distribution of 10 float numbers, what i can’t grasp is how did we get back 7?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nEbdulmomen\\nDecember 7, 2020 at 8:57 am\\n#\\n\\n\\n\\nwhat i mean is how this 10 probabilities turned into 1 predicted number?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nEbdulmomen\\nDecember 7, 2020 at 9:09 am\\n#\\n\\n\\n\\nand how does it know it is 7, didn’t we hot encode the Y values?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 7, 2020 at 1:35 pm\\n#\\n\\n\\n\\nVia argmax:\\nhttps://machinelearningmastery.com/argmax-in-machine-learning/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 7, 2020 at 1:35 pm\\n#\\n\\n\\n\\nThanks.\\nThe predict_classes() performs an argmax on the predicted probabilities for you.\\nIf you are new to argmax, see this:\\nhttps://machinelearningmastery.com/argmax-in-machine-learning/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nEbdulmomen\\nDecember 7, 2020 at 6:41 pm\\n#\\n\\n\\n\\nthank you jason, everything is clear, really appreciate it!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 8, 2020 at 7:40 am\\n#\\n\\n\\n\\nI’m happy to hear that.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNaveen\\nDecember 13, 2020 at 2:43 am\\n#\\n\\n\\n\\nHey is this code not compatible for Tensorflow 2? I am getting the following error.\\nE tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 13, 2020 at 6:06 am\\n#\\n\\n\\n\\nYes, you can learn more here:\\nhttps://machinelearningmastery.com/faq/single-faq/do-you-support-tensorflow-2\\nThat error looks like a problem with your development environment.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYash\\nDecember 23, 2020 at 9:40 am\\n#\\n\\n\\n\\nHello!\\nThanks for the wonderful article helped me a lot with my project!\\nI have a question though, I am trying to take an image from my phone and then use that image to predict the number but it doesn’t work with that. What should I do to that image?\\nI resized it to 28×28 using online tools and even tried the grayscale version of the image to predict.\\nAny suggestion or lead will be appreciated!\\nThanks in advance!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 23, 2020 at 1:27 pm\\n#\\n\\n\\n\\nYou will have to prepare the image in an identical manner to the images in the training set. e.g. white foreground, black background, grayscale and same image size.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJG\\nDecember 31, 2020 at 7:53 am\\n#\\n\\n\\n\\nHi Jason,\\nGreat tutorial as always!\\nI implemented your tutorial with two variants. \\nI load the images from digits dataset of sklearn library (it uses less images number only 1,797 and with much lower resolution 8 x 8 bits vs MNIST 70,000 and 28,28 pixels resolution. On the contrary it is much faster this dataset because it use less data features.\\nAnd also I apply for this multi-class problem other library classifier models from Sklearn such as SVC(), logisticRegression(), ExtraTreesClassifier(), XGBClassifier(), RandomForestClassifier(), etc.\\nMy main results are:\\n– I got 98.4% accuracy and 1.1 of sigma for the simple CNN baseline model (not other deep layers, not other BatchNormalization()) and I got 98.8% from SVC…but only suing the 8×8 pixels resolution which is a great new!.\\nBut when I reduce the final image to be predicted to 8 x 8 pixels, in order to apply my trained model, whereI got such a great score I poorly predict the 7 digit as 9 digit.\\nMy guess is when I load_image of 7 and I clip it to such smaller size of 8×8 pixels, I lost important images features in the process of cutting back the image….where the the MNIST 28×28 pixels still retain key digit features of the image, what do you think?\\nthank you Jason\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 31, 2020 at 9:26 am\\n#\\n\\n\\n\\nThanks.\\nVery nice experiments!\\nYes, the larger images perhaps provide more context on challenging cases in the dataset.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHannes\\nJanuary 26, 2021 at 1:15 am\\n#\\n\\n\\n\\nHi Jason,\\nYou have always very interesting articles.\\nI was able to train a CNN based on the Char74K-dataset. I’m happy of that because the model-file is only 42MB and the time to predict a number is fast.\\nI did use a kNN-model before (on the same dataset) that had a file size of 680MB!\\nThanks,\\nHannes\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJanuary 26, 2021 at 5:58 am\\n#\\n\\n\\n\\nThanks.\\nWell done!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMukesh\\nFebruary 5, 2021 at 8:42 pm\\n#\\n\\n\\n\\nHi Jason,\\nGreat article!!\\ni just have one doubt, in the evaluate method why are we creating a new model for every fold?\\nThanks,\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 6, 2021 at 5:49 am\\n#\\n\\n\\n\\nThis is how k-fold cross-validation works, we have a new training set and fit a new model for each fold, then average the performance of all models to get an estimate of model performance when used on unseen data.\\nYou can learn more here:\\nhttps://machinelearningmastery.com/k-fold-cross-validation/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDmitry\\nFebruary 6, 2021 at 6:20 pm\\n#\\n\\n\\n\\nThanks for this amazing tutorial!\\nI have some experience in MLP but not with CNN. Is there a reason try to use CNN if each sample of my data have shape 16×1 (row) with values between 0,01 to 0,99 and the model shoud perform classification for 15 classes. If I reshape samples from 16×1 to 4×4 then which filter size and a modest number of filters shoud I use? Or better dont reshape and try model with Conv1D layers? Thanks.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 7, 2021 at 5:17 am\\n#\\n\\n\\n\\nCNN can be effective if there is a spatial relationship between the inputs in an image or a sequence.\\nIf you have tabular data (e.g. not a images and not sequences), then a CNN does not make sense.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAhmed Shafeek\\nFebruary 18, 2021 at 2:19 pm\\n#\\n\\n\\n\\nHi Jason,\\nThank you very much for your amazing tutorial. I am running your code using pycharm and I have a GPU with the right CUDA but your code is only running on my CPU.\\nIs there something that I am missing here?\\nthank you. 🙂\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAhmed Shafeek\\nFebruary 18, 2021 at 4:52 pm\\n#\\n\\n\\n\\nSorry Jason, it turned out I had a problem in the CuDNN installation and i did a work around to fix it and it worked. 🙂\\nThanks again for this great tutorial. 🙂\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 19, 2021 at 5:55 am\\n#\\n\\n\\n\\nNo problem! \\nHappy to hear you fixed the issue.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 19, 2021 at 5:54 am\\n#\\n\\n\\n\\nThe code is agnostic to hardware – runs on both.\\nIf it is running on your CPU, then you need to change the configuration of your tensorflow library. I don’t have tutorials on this topic, sorry.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nKarl\\nFebruary 24, 2021 at 1:20 am\\n#\\n\\n\\n\\nHi Jason, \\nThank you very much for this tutorial, helped a lot! I developed my own CNN, which seems to perform pretty well according to the mean accuracy. However, the cross-entropy loss of the validation set is below the loss of the training set. Is this a sign of underfitting? And if so, should I change the model if I would like to apply the model to unseen data?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 24, 2021 at 5:34 am\\n#\\n\\n\\n\\nYou’re welcome.\\nWell done!\\nIf performance is poor, a learning curve can help diagnose issues, this can help you interpret the learning curve:\\nhttps://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNoah\\nFebruary 24, 2021 at 1:51 am\\n#\\n\\n\\n\\nHi Jason,\\nThank you very much for this tutorial, helped a lot! I developed my own CNN, which seems to perform pretty well according to the mean accuracy. However, the cross-entropy loss of the validation set is below the loss of the training set. Is this a sign of underfitting? And if so, should I change the model if I would like to apply the model to unseen data?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 24, 2021 at 5:35 am\\n#\\n\\n\\n\\nYou’re welcome.\\nPerhaps focus on the out of sample performance of the model first and optimize that.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGeo\\nMarch 2, 2021 at 12:20 am\\n#\\n\\n\\n\\nHi Jason,\\nPreviously I was grateful for the tutorial you provided, I learned a lot from here. What if I want to display the probability value of the prediction result? (for example 50.67% something like that)\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 2, 2021 at 5:45 am\\n#\\n\\n\\n\\nThanks!\\nYou can call model.predict() then multiply the result by 100 to get a percentage.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWilliam\\nMarch 2, 2021 at 3:01 pm\\n#\\n\\n\\n\\nThank you for the tutorial!\\nI created an image with same characteristics as sample_image.png (1490×1480, black background, white foreground), opened it in Paint, typed a “6” (without the quotes, of course), increased the font size to 1000 (so it would occupy most of the canvas), then saved it. However, the code doesn’t seem to recognize it. It seems to think it’s a “1”, “8”, or other numbers.\\nAny suggestions on why?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 3, 2021 at 5:25 am\\n#\\n\\n\\n\\nPerhaps there was some important difference in the image itself or it’s preparation (e.g. pixel scaling) that differed from the training dataset?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVenkat\\nApril 1, 2021 at 10:07 pm\\n#\\n\\n\\n\\nHi Jason – fantastic article!! Just wondering why you had to do evaluate to get the accuracy, while it is already being returned by the fit call? I just checked the histories and they have exactly the same stuff returned by the evaluate call. Was there any other reason for the evaluate call?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 2, 2021 at 5:39 am\\n#\\n\\n\\n\\nThanks!\\nNo, accuracy on a hold out dataset is not calculated when calling fit. We must make predictions on new data manually or use the evaluate function.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nVenkat\\nApril 15, 2021 at 4:17 am\\n#\\n\\n\\n\\nThanks for the reply!! I was seeing the same data is passed (testX, testY) for both fit and evaluate calls for validation. As a result, the return object from fit call already has the data to be returned by the evaluate call. Am I making sense?\\n# fit model\\nhistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\n# evaluate model\\n_, acc = model.evaluate(testX, testY, verbose=0)\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 15, 2021 at 5:30 am\\n#\\n\\n\\n\\nGenerally it is not a good idea to use test data as validation, I do to keep the examples simple.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBerke\\nApril 4, 2021 at 9:47 pm\\n#\\n\\n\\n\\nHi Jason, thanks for this great tutorial!\\nI don’t get why we don’t use the models that we created during the k-fold. I was expecting something like we combine this k models results into one single model and save it. If we don’t do that how’s that useful?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 5, 2021 at 6:11 am\\n#\\n\\n\\n\\nModels created during k-fold cross-validation are discarded. They are only used to estimate the performance of the model/pipeline on unseen examples.\\nOnce we choose a configuration, we can fit a final model on all data and use it to make predictions on new examples:\\nhttps://machinelearningmastery.com/train-final-machine-learning-model/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVishwa\\nApril 15, 2021 at 9:38 pm\\n#\\n\\n\\n\\nThanks a lot Jason !!! This tutorial was very very helpful and it solved half of my project problems !!! Thanks a lot again !..\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 16, 2021 at 5:30 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nismail\\nJune 9, 2021 at 8:47 am\\n#\\n\\n\\n\\nThank you for the great tutorial. Is it possible to use it with a webcam for recognition task?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 10, 2021 at 5:20 am\\n#\\n\\n\\n\\nPerhaps try it and see.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTaylor Rayne\\nJune 12, 2021 at 12:20 pm\\n#\\n\\n\\n\\nHello! Thank you Jason for this amazing resource. I am currently working on a rented computer from school – do you think I could do implement this code in CoLabs?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 13, 2021 at 5:46 am\\n#\\n\\n\\n\\nYou’re welcome.\\nGood question, see this:\\nhttps://machinelearningmastery.com/faq/single-faq/do-code-examples-run-on-google-colab\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nManal\\nJune 15, 2021 at 4:14 pm\\n#\\n\\n\\n\\nHi Jason,\\nThank you very much\\nIf possible, advise on the implementation HMM.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 16, 2021 at 6:17 am\\n#\\n\\n\\n\\nThanks for the suggestion, perhaps in the future.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\namberbir\\nJune 15, 2021 at 11:11 pm\\n#\\n\\n\\n\\ni am developing a model of handwritten character recognition but the accuracy is very low i think it is not only because i have a small datatset, there is something i am not understanding can u help me on the improvement\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 16, 2021 at 6:21 am\\n#\\n\\n\\n\\nPerhaps try some of these suggestions:\\nhttps://machinelearningmastery.com/improve-deep-learning-performance/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShri\\nJuly 8, 2021 at 11:15 pm\\n#\\n\\n\\n\\nCan I use this code for any character dataset ?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJuly 9, 2021 at 5:11 am\\n#\\n\\n\\n\\nPerhaps try it and see.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShireesh Apte\\nAugust 8, 2021 at 8:34 am\\n#\\n\\n\\n\\nCould you provide a peer review for a manuscript that has been submitted to the Journal of High School Science (http://jhss.scholasticahq.com) ? The title of the manuscript is : Implementing a Quantum Convolutional Neural Network for Efficient Image Recognition. Abstract: Machine learning has many real-world applications ranging from modeling the universe to computational chemistry. As probability is the bedrock for machine learning, it is essential to optimize both hardware and software to obtain the best results. Classical computers are generally used for machine learning programs. However, learning from high-dimensional data often demands excessive compute time and power, and it may not achieve the highest accuracy. The Quantum Computing environment can be utilized to create a more accurate model than that created via classical computing. To test this quantum advantage, we implemented a Quantum Convolutional Neural Network (QCNN), which parallels the structure of the classical Convolution Neural Network (CNN) in the quantum domain. Due to the lack of quantum computers with many qubits, physicists, namely John Preskill, have introduced the Noisy Intermediate Scale Quantum (NISQ) concept, which constitutes a hybrid interface between classical and quantum computers. In the context of QCNN, the data processing and the cost function optimization would be performed on the classical computer, while the probabilities generated by the Variational Quantum Circuits (VQC) would be evaluated on the quantum computer. The QCNN consists of a classical-to-quantum data encoder, a cluster state quantum circuit to entangle qubit states, a series of Variational Quantum Circuits using Quantum Convolutional and Pooling Layers for efficient feature extraction, a quantum-to-classical data decoder, which would lead to the output. Both the CNN and the QCNN extract features from data like 2D images, and performances can be compared using metrics like accuracy and time.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nAugust 9, 2021 at 5:52 am\\n#\\n\\n\\n\\nSorry I cannot peer review your manuscript.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnbe\\nSeptember 11, 2021 at 6:48 pm\\n#\\n\\n\\n\\nwhat if we are asked to design a project to identify digit classification from MNIST using classification algorithm should we use the above oen\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nSeptember 14, 2021 at 1:08 pm\\n#\\n\\n\\n\\nYes\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbhi\\nNovember 12, 2021 at 11:26 pm\\n#\\n\\n\\n\\nWonderful tutorial!!\\nWhen i implemented the code i got this error ” AttributeError: ‘Sequential’ object has no attribute ‘predict_classes’ ”\\nAny suggestions to rectify this error please?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nNovember 14, 2021 at 2:27 pm\\n#\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nfrom numpy import argmax\\n\\npred_value = model.predict(img)\\ndigit = argmax(pred_value)\\n\\n\\n\\n\\n1234\\n\\nfrom numpy import argmax\\xa0pred_value = model.predict(img)digit = argmax(pred_value)\\n\\n\\n\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnnya Karn\\nNovember 17, 2021 at 12:06 am\\n#\\n\\n\\n\\nI used this model as an example and when I fed it a handwritten number, it continuously gave wrong predictions. Can you please tell me what could possibly be the problem?\\nIt reads accurately when I used printed numbers with black background.\\nI did however change the cnn model a little bit to make it Multiple Pooling model.\\nI can share the code as well, if you like.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nNovember 17, 2021 at 6:55 am\\n#\\n\\n\\n\\nCan’t tell because I didn’t see your handwriting. But this MNIST dataset is a 28×28 pixel grayscale with white on black. Try to mimick this set up and it should be much better. If your image is more complex (e.g., you scan it, then the background is not a single color, or the alphabet is more complicated with more strokes than digits) then you will need a larger network to recognize it.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLouca\\nNovember 23, 2021 at 12:01 pm\\n#\\n\\n\\n\\nYou mention in other answers that the inputs have to be reshaped because the convolutional layers expect an input with a dimension for channels. Do you know if this is unique to keras?\\nI am trying to classify 56×56 grayscale images (0->255), and so far I have normalized them to [-1,1]. However, they are still 2D as a 56×56 matrix. I am using pytorch. Do you know if I would also need to reshape them to add the single channel?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nNovember 23, 2021 at 1:40 pm\\n#\\n\\n\\n\\nDepends on the way you construct the model, it may or may not necessary.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nNovember 29, 2021 at 5:29 am\\n#\\n\\n\\n\\nWhy are there two copies of the 64-filter conv2D in the “Increase Model Depth” section:\\nmodel.add(Conv2D(64, (3, 3), activation=’relu’, kernel_initializer=’he_uniform’))\\nI tried this model with both one and two of these layers and got the same results.\\nAs a side note, I did increase the number of epochs to 15 and saw a slight improvement to both the accuracy mean and std deviation.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nNovember 29, 2021 at 8:56 am\\n#\\n\\n\\n\\nIf you see no difference for more layers, try to stay with the fewer layers one because it save time and memory.\\nIncreasing epochs can help train better, but you may also run into overfitting. So you need to check with validation set to confirm about the “improvement”.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nNovember 30, 2021 at 5:47 am\\n#\\n\\n\\n\\nI tried up to 25 epochs and looked at the loss with verbose=1 in the model.fit call. The loss bottoms out at around 20 epochs and then bounces around after that.\\nHere’s one run from epoch 10 through 25. The model got 99.260% on the test set:\\nEpoch 10/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0079 – accuracy: 0.9972\\nEpoch 11/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0061 – accuracy: 0.9980\\nEpoch 12/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0060 – accuracy: 0.9980\\nEpoch 13/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0058 – accuracy: 0.9978\\nEpoch 14/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0045 – accuracy: 0.9984\\nEpoch 15/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0042 – accuracy: 0.9987\\nEpoch 16/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0035 – accuracy: 0.9988\\nEpoch 17/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0031 – accuracy: 0.9991\\nEpoch 18/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0024 – accuracy: 0.9992\\nEpoch 19/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0026 – accuracy: 0.9993\\nEpoch 20/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0020 – accuracy: 0.9994\\nEpoch 21/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0020 – accuracy: 0.9994\\nEpoch 22/25\\n1875/1875 [==============================] – 7s 3ms/step – loss: 0.0027 – accuracy: 0.9991\\nEpoch 23/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0032 – accuracy: 0.9989\\nEpoch 24/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0022 – accuracy: 0.9993\\nEpoch 25/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0020 – accuracy: 0.9993\\n> 99.260\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nDecember 2, 2021 at 1:59 am\\n#\\n\\n\\n\\nNot bad a result here!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nDecember 2, 2021 at 3:11 am\\n#\\n\\n\\n\\nThese guys: https://arxiv.org/pdf/2008.10400v2.pdf are getting 99.91% accuracy using a combination of fairly simple techniques: deeper model depth, increased convolution kernel size, data augmentation, batch normalization between all conv2D layers, disabling edge padding in the convolution output to reduce the map sizes between conv2D layers instead of max pooling (which I found quite elegant), and voting between multiple models. They do a good job of analyzing each technique and comparing the results to other common CNNs.\\nThey’re currently at the top of the rankings here: https://paperswithcode.com/sota/image-classification-on-mnist\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nDecember 2, 2021 at 3:34 am\\n#\\n\\n\\n\\nThanks for sharing.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nDecember 4, 2021 at 4:05 am\\n#\\n\\n\\n\\nSo during training, the model accuracy against the training data goes over 99.9%, but the final accuracy on the test data is 99.26%. Are these results close enough that I can assume the model isn’t over trained? What’s a reasonable difference when both values are over 99%?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nDecember 8, 2021 at 7:17 am\\n#\\n\\n\\n\\nCan’t give you any general guidance on what is reasonable or not. But at >99% accuracy, I would assume it is good enough for this purpose.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nDecember 22, 2021 at 9:24 am\\n#\\n\\n\\n\\nHi Patrick…The following resource will provide you insight into how to avoid overfitting in deep neural networks.\\nhttps://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/\\nRegards,\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAndrew Odion\\nJanuary 1, 2022 at 11:52 pm\\n#\\n\\n\\n\\nThank you\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nJanuary 2, 2022 at 8:56 am\\n#\\n\\n\\n\\nYou are very welcome Andrew!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nJanuary 3, 2022 at 8:42 am\\n#\\n\\n\\n\\nYou are very welcome, Andrew!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGilad\\nJanuary 8, 2022 at 5:08 am\\n#\\n\\n\\n\\nHi,\\nI don’t know if you will ever see it but if you reply I will thank you, I wanted to try by myself this code because I was hoping to learn more about neural networks.\\nUnfortunately, I gave Python a picture I made in paint (the computer application) this image was resized to 28*28 and the picture is seen, I checked it.\\nIn the picture, I drew the number 2, and it said that it is four and I tried more unsuccessfully.\\nI’d like to know where is the problem.\\nAnyway if you can reply to me in E-mail I will thank you in order to check wether the problem is in the picture or the code.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nJanuary 8, 2022 at 10:58 am\\n#\\n\\n\\n\\nHi Gilad…Have you checked the overall accuracy of your model?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nGilad\\nJanuary 9, 2022 at 10:13 pm\\n#\\n\\n\\n\\nYes, the accuracy was 96 percent, this is the reason I find it awkward.\\nI am not sure whether the problem is in the picture but I’d like to know where is the problem.\\nCan I send you the picture that I used? maybe the problem is located there.\\nAnyway, thanks for the help.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nGilad\\nJanuary 9, 2022 at 10:29 pm\\n#\\n\\n\\n\\n99.140 is my right accuracy, sorry for the earlier mistake.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nGilad\\nJanuary 10, 2022 at 2:34 am\\n#\\n\\n\\n\\nJames thanks a lot it finally worked, my picture was not good.\\nI drew the digits in black and the background was white, and this is not the way the computer was trained.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nJanuary 10, 2022 at 11:12 am\\n#\\n\\n\\n\\nThank you for the feedback Gilad! Keep up the great work!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnbu\\nMarch 29, 2022 at 5:22 pm\\n#\\n\\n\\n\\nThis, according to me, is the best tutorial I have ever gone through. It helped me understand CNN in my very first attempt. Thank you, Dear James.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMarch 30, 2022 at 3:45 am\\n#\\n\\n\\n\\nThank you for the feedback and support Anbu!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nViswa\\nMay 1, 2022 at 2:16 am\\n#\\n\\n\\n\\nhello james,\\nGreat tutorial. I’ getting “name ‘train’ is not defined” as error while converting from integers to floats. can you please help me with that? Thank you.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMay 2, 2022 at 9:26 am\\n#\\n\\n\\n\\nHi Viswa…Thank you for the feedback! Did you copy and paste the code or type it in? There could be an issue related to copying and pasting the code.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nViswa\\nMay 3, 2022 at 1:06 pm\\n#\\n\\n\\n\\nOh! I got it. Thank you so much for tutorial, I’ve learned a lot from you.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nViswa\\nMay 4, 2022 at 6:25 am\\n#\\n\\n\\n\\nCan you please elaborate on why a dense layer with specifically 100 nodes is used to develop a baseline model?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nCarde\\nMay 9, 2022 at 6:47 pm\\n#\\n\\n\\n\\ntrain_norm = train.astype(‘float32’)\\nHi Jason, from which library this method come from?\\nCause train is not defined in your code and I want to see how the method works.\\ntrain_norm = train.astype(‘float32’)\\nNameError: name ‘train’ is not defined\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMay 10, 2022 at 12:13 pm\\n#\\n\\n\\n\\nHi Carde…Please see the complete code listing near the end of the tutorial.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuhas\\nMay 12, 2022 at 6:59 am\\n#\\n\\n\\n\\nIs it okay to add dropout() to the digit classification model, because I got the best accuracy when I use the dropout.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMay 13, 2022 at 12:56 am\\n#\\n\\n\\n\\nHi Suhas…Yes, that approach is a reasonable one and it is great to know you were able to improve your model accuracy! Dropout is definitely beneficial to avoid overtraining.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nabdool\\nOctober 28, 2022 at 4:57 am\\n#\\n\\n\\n\\nwhere is the final code and the code testing result\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nOctober 28, 2022 at 8:27 am\\n#\\n\\n\\n\\nHi abdool…The final code listing is provided in this post. Is it not visible?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAshbrocolli\\nNovember 18, 2022 at 4:15 am\\n#\\n\\n\\n\\nhi, for the improved depth, how many hidden layers are involved?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nNovember 18, 2022 at 6:10 am\\n#\\n\\n\\n\\nHi Ashbrocolli…The layers can be found in the in section following the comment below:\\n“The complete code listing with this change is provided below.”\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRabiaa CHARIJ\\nNovember 30, 2022 at 8:03 pm\\n#\\n\\n\\n\\nHello @James Carmichael, I wonder how the “to_categorical” works , I have seen documentation and it says if number of classes is not specified then this would be inferred as max(y) + 1 if y is a vector. So to my surprise ,I know that in the Mnist dataset the num classes is 10 but without specifiying this number as a parameter , the function returns a vector of shape (60 000,10) but how ? I would really like to know how this max(y)+1 would work on images and give the right num_classes that is 10.\\nThanks in advance for your answer.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nRabiaa CHARIJ\\nNovember 30, 2022 at 8:29 pm\\n#\\n\\n\\n\\nSorry I figured it out, As “y” is a vector of labels from 0 to 9 so max(y)+1 would return 10 (num_classses), which is obvious actually. I was Confused because I had an issue while printing “y” it didn’t show the expected values.\\nThanks!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nDecember 1, 2022 at 8:14 am\\n#\\n\\n\\n\\nThank you for the update Rabiaa! Great work!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCraneFrog\\nMarch 1, 2024 at 9:19 am\\n#\\n\\n\\n\\nOutdated tutorial. Would not recommend to beginners who are starting out. Over complicating things in modern age. Maybe at the time (5yrs ago!!!) this was fine but things can be done way more simpler and cleaner.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMarch 2, 2024 at 1:09 pm\\n#\\n\\n\\n\\nThank you for your feedback!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n \\nLeave a Reply Click here to cancel reply.Comment * Name (required) \\nEmail (will not be published) (required) \\n \\n\\nΔ \\n\\n\\n\\nWelcome!\\nI'm Jason Brownlee PhD \\nand I help developers get results with machine learning.\\nRead more\\n\\nNever miss a tutorial:\\n\\n\\n\\n\\xa0\\xa0\\xa0\\n\\n\\xa0\\xa0\\xa0\\n\\n\\xa0\\xa0\\xa0\\n\\n\\xa0\\xa0\\xa0\\n\\n\\nPicked for you:\\n\\n How to Train an Object Detection Model with Keras How to Develop a Face Recognition System Using FaceNet in Keras How to Classify Photos of Dogs and Cats (with 97% accuracy) How to Perform Object Detection With YOLOv3 in Keras How to Get Started With Deep Learning for Computer Vision (7-Day Mini-Course)\\nLoving the Tutorials?\\nThe Deep Learning for Computer Vision EBook is where you'll find the Really Good stuff.\\n\\n>> See What's Inside\\n\\n\\n\\n\\n\\n\\n© 2024 Guiding Tech Media. All Rights Reserved.\\nLinkedIn |\\nTwitter |\\nFacebook |\\nNewsletter |\\nRSS |\\nAdvertise \\n\\nPrivacy |\\nDisclaimer |\\nTerms |\\nContact |\\nSitemap \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
       " Document(metadata={'source': 'https://stackoverflow.com/questions/49089025/testing-a-single-image-on-the-mnist-tensorflow-cnn'}, page_content='\\n\\n\\n\\n\\n\\n \\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\nStack Overflow\\n\\n\\n\\nAbout\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tProducts\\n\\t\\t\\t\\t\\t\\n\\n\\nOverflowAI\\n\\n\\n\\n\\n\\n\\n\\nStack Overflow for Teams\\nWhere developers & technologists share private knowledge with coworkers\\n\\n\\n\\n\\nAdvertising & Talent\\nReach devs & technologists worldwide about your product, service or employer brand\\n\\n\\n\\n\\nOverflowAI\\nGenAI features for Teams\\n\\n\\n\\n\\nOverflowAPI\\nTrain & fine-tune LLMs\\n\\n\\n\\n\\nLabs\\nThe future of collective knowledge sharing\\n\\n\\n\\nAbout the company\\nVisit the blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading…\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncurrent community\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Stack Overflow\\n        \\n\\n\\n\\nhelp\\nchat\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Meta Stack Overflow\\n        \\n\\n\\n\\n\\n\\n\\nyour communities            \\n\\n\\n\\nSign up or log in to customize your list.                \\n\\n\\nmore stack exchange communities\\n\\ncompany blog\\n\\n\\n\\n\\n\\n\\n\\n\\nLog in\\n\\nSign up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    The 2024 Developer Survey results are live!\\n                \\nSee the results\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Home\\n\\n\\n\\n\\n\\n\\n Questions\\n\\n\\n\\n\\n\\n\\n Tags\\n\\n\\n\\n\\n\\n\\n\\n Users\\n\\n\\n\\n\\n\\n\\n Companies\\n\\n\\n\\n\\n\\nLabs\\n\\n\\n\\n\\n\\n\\n\\n\\n Jobs\\n\\n\\n\\n\\n\\n\\n Discussions\\n\\n\\n\\n\\n\\n\\nCollectives\\n\\n\\n\\n\\n\\n\\n\\n\\n                                        Communities for your favorite technologies.  Explore all Collectives\\n\\n\\n\\n\\n\\nTeams\\n\\n\\n\\n\\n\\nNow available on Stack Overflow for Teams! AI features where you work: search, IDE, and chat.\\n        \\nLearn more\\nExplore Teams\\n\\n\\n\\n\\nTeams\\n\\n\\n\\n\\n\\n\\n\\n            Ask questions, find answers and collaborate at work with Stack Overflow for Teams.\\n            Explore Teams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCollectives™ on Stack Overflow\\nFind centralized, trusted content and collaborate around the technologies you use most.\\n\\n                    Learn more about Collectives\\n                \\n\\n\\n\\n\\n\\nTeams\\nQ&A for work\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n                    Learn more about Teams\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\nGet early access and see previews of new features.\\n Learn more about Labs\\n\\n\\n\\n\\n\\n\\n\\nTesting a single image on the MNIST tensorflow CNN\\n\\n\\n\\n        Ask Question\\n    \\n\\n\\n\\n\\n\\nAsked\\n6 years, 5 months ago\\n\\n\\nModified\\n6 years, 5 months ago\\n\\n\\nViewed\\n                        1k times\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            0\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nI\\'ve already trained a CNN based on the classic MNIST dataset, and what i\\'m trying to do is build a program that loads the saved model, takes an image (a handwritten digit not part of the dataset) and can predict what digit is written and output it. I\\'ve found myself stuck trying to get the code to output the guess of what digit it is(0-9).\\nI\\'ve already worked out how to feed in a single image in, what exactly do i write to find out what single class the model has classified the image as?\\nThank you\\nnum_channels = 1\\nimage_size = 28\\npic_root = #insert file directory here\\n\\nimg=mpimg.imread(pic_root)\\nimage = img.reshape(-1,image_size,image_size, num_channels)\\nimg = tf.cast(image, tf.float32)\\n\\nwith tf.Session() as session:\\n    saver = tf.train.import_meta_graph(save_file) #loading the saved model\\n    image_predict = tf.nn.softmax(img)\\n    print(image_predict)\\n    soft_max = tf.nn.softmax(logits, name=\"softmax_tensor\")\\n    arg_max = tf.argmax(input=logits, axis=1)\\n    print(arg_max)\\n    print(soft_max)\\n\\nimage_predict, soft_max and arg_max all return something but i don\\'t know how to get the actual prediction from this. \\n\\n\\n\\n\\npythontensorflowconv-neural-network\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nedited Mar 3, 2018 at 21:56\\n\\n\\n\\n\\n\\nLauren\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            asked Mar 3, 2018 at 20:43\\n\\n\\n\\n\\n\\n\\nLaurenLauren\\n\\n122 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n2\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\nCan you post the code you have so far?\\n\\n–\\xa0Adnan S\\n\\n\\nCommented\\nMar 3, 2018 at 20:55\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosted :) sorry it\\'s a bit messy, would you like the code from the CNN itself as well? thank you\\n\\n–\\xa0Lauren\\n\\n\\nCommented\\nMar 3, 2018 at 21:57\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                        1 Answer\\n                                    1\\n\\n\\n\\n\\n\\n\\n            Sorted by:\\n        \\n\\n            Reset to default\\n        \\n\\n\\n\\n\\n                        Highest score (default)\\n                    \\n\\n                        Trending (recent votes count more)\\n                    \\n\\n                        Date modified (newest first)\\n                    \\n\\n                        Date created (oldest first)\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            0\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPer your code, soft_max and arg_max should be returned as arrays of length 10. The values in the array correspond to the 10 digits from 0 to 9. \\nEach value in soft_max array is the probability that the input image matches that particular digit. The array indexing starts at zero so the first value in array is the probability that the image is the digit 0 and the second value is the probability that the image is the digit 1 and so forth so that the tenth value is the probability that the image is 9. The predicted image is the value with the highest probability.\\narg_max saves you a processing step by returning a sorted list of predicted indices (which in this case match the predicted digit). So if arg_max has [4, 9, 5, ...], the predicted digit is 4.\\nprint(arg_max[0]) #should give you the predicted digit\\n\\nOnce you know that the return values are arrays as explained, the output can be decoded.\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n                        Follow\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nedited Mar 5, 2018 at 22:00\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            answered Mar 5, 2018 at 7:06\\n\\n\\n\\n\\n\\n\\nAdnan SAdnan S\\n\\n1,88211 gold badge1515 silver badges1919 bronze badges\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThank you so much for your help! When i print arg_max[0] it prints \\'Tensor(\"strided_slice:0\", shape=(), dtype=int64)\\' , any idea what this means?\\n\\n–\\xa0Lauren\\n\\n\\nCommented\\nMar 7, 2018 at 21:47\\n\\n\\n\\n\\n\\n\\n\\nAdd a comment\\n\\xa0|\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Your Answer\\n                                \\n\\n\\n\\n\\n\\n\\n\\n\\nReminder: Answers generated by artificial intelligence tools are not allowed on Stack Overflow. Learn more\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThanks for contributing an answer to Stack Overflow!Please be sure to answer the question. Provide details and share your research!But avoid …Asking for help, clarification, or responding to other answers.Making statements based on opinion; back them up with references or personal experience.To learn more, see our tips on writing great answers.\\n\\n\\n\\n\\n\\n\\nDraft saved\\nDraft discarded\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up or log in\\n\\n\\n Sign up using Google\\n                        \\n\\n Sign up using Email and Password\\n                        \\n\\n\\n\\nSubmit\\n\\nPost as a guest\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEmail\\nRequired, but never shown\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPost as a guest\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEmail\\nRequired, but never shown\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                            Post Your Answer\\n                                        \\n\\n                                            Discard\\n                                        \\n\\n                                                By clicking “Post Your Answer”, you agree to our terms of service and acknowledge you have read our privacy policy.\\n\\n\\n\\n\\n\\n\\nNot the answer you\\'re looking for? Browse other questions tagged pythontensorflowconv-neural-network or ask your own question.                                \\n\\n\\n\\n\\n\\n\\n\\n                            The Overflow Blog\\n                        \\n\\n\\n \\n\\nThis developer tool is 40 years old: can it be improved?\\n\\n\\n\\n\\n \\n\\nUnpacking the 2024 Developer Survey results\\n\\n\\n\\n                            Featured on Meta\\n                        \\n\\n\\n \\n\\nAnnouncing a change to the data-dump process\\n\\n\\n\\n\\n \\n\\nWe\\'ve made changes to our Terms of Service & Privacy Policy - July 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated\\n\\n\\n\\n2\\n\\nhow to test mnist on my own dataset images\\n\\n\\n\\n10\\n\\nTensorflow - Testing a mnist neural net with my own images\\n\\n\\n\\n3\\n\\nPython/Tensorflow - I have trained the convolutional neural network, how to test it?\\n\\n\\n\\n0\\n\\nTensorflow MNIST - accuracy of particular test image\\n\\n\\n\\n2\\n\\nHow to test multiple images at once with label_image.py in Tensorflow\\n\\n\\n\\n0\\n\\nCNN-Divide images into training/validation/testing\\n\\n\\n\\n1\\n\\nHow do i test my CNN model with an image?\\n\\n\\n\\n1\\n\\nIn Pytorch, how to test simple image with my loaded model?\\n\\n\\n\\n7\\n\\nHow to test one single image in pytorch\\n\\n\\n\\n2\\n\\nTesting my CNN on a small set of image but training has no effect\\n\\n\\n\\n\\n\\n\\n\\n            Hot Network Questions\\n        \\n\\n\\n\\n\\n                    How to measure out fresh herbs when the recipe calls for \\'a tablespoon of chopped herb\\'?\\n                \\n\\n\\n\\n                    Count number display: \"99+\" vs full number\\n                \\n\\n\\n\\n                    Why do many CVT cars appear to index gears during normal automatic operation?\\n                \\n\\n\\n\\n                    Always trust localhost certificates\\n                \\n\\n\\n\\n                    Masters Thesis Regression with dummy/control variables added leading to insignificant independent variable, how can I handle this? Please help :)\\n                \\n\\n\\n\\n                    What role can scrum master have/take when product owners differ from opinion?\\n                \\n\\n\\n\\n                    1 John 4:9, \"God sent His ONLY begotten Son into the world.\" Jesus is the Son in the exclusive sense. Would this mean the Son has His Father\\'s nature?\\n                \\n\\n\\n\\n                    What is the scriptural basis for the claim that Siva was a devotee of Vishnu?\\n                \\n\\n\\n\\n                    Can I replace the Sun with a non-nuclear equivalent?\\n                \\n\\n\\n\\n                    Hyphenation is switched off when text should fade away\\n                \\n\\n\\n\\n                    Fantasy book series about a lord (and maybe a lady) who rules over a world where it\\'s eternally spring, summer, fall, etc\\n                \\n\\n\\n\\n                    Neutron half-life outside a nucleus: can it be extended?\\n                \\n\\n\\n\\n                    Space UN – non human focalpoints\\n                \\n\\n\\n\\n                    systemd \"Environment\" variable containing %c fails\\n                \\n\\n\\n\\n                    Distribution of fall damage between the falling and the fallen upon. How does it apply when the damage is reduced by other means?\\n                \\n\\n\\n\\n                    Does roofing felt left exposed for several weeks need replacement?\\n                \\n\\n\\n\\n                    On a stopover, a space tourist who is in fact a gamesharp joins what looks like a casino game\\n                \\n\\n\\n\\n                    Terrain rising, controller not giving climb clearance... what to do?\\n                \\n\\n\\n\\n                    Are there official, standard, or conventional names for the screen RAM addresses on the ZX Spectrum?\\n                \\n\\n\\n\\n                    Reason why \"An advantage of playing video games is the excitement derived from it\" is incorrect\\n                \\n\\n\\n\\n                    Is ksh-syntax (Korn shell) compatible to bash?\\n                \\n\\n\\n\\n                    Is leveling this ground and removing plastic by the side of my house a bad idea?\\n                \\n\\n\\n\\n                    Is there a ring with zero divisors but no nilpotents?\\n                \\n\\n\\n\\n                    Forgot to Anonymize Paper for Double-Blind Review\\n                \\n\\n\\n\\n            more hot questions\\n        \\n\\n\\n\\n\\n            Question feed\\n        \\n\\n\\n\\n\\n                Subscribe to RSS\\n            \\n\\n\\n\\n                        Question feed\\n                        To subscribe to this RSS feed, copy and paste this URL into your RSS reader.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nlang-py\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStack Overflow\\n\\nQuestions\\nHelp\\nChat\\n\\n\\n\\nProducts\\n\\nTeams\\nAdvertising\\nCollectives\\nTalent\\n\\n\\n\\nCompany\\n\\nAbout\\nPress\\nWork Here\\nLegal\\nPrivacy Policy\\nTerms of Service\\nContact Us\\nCookie Settings\\nCookie Policy\\n\\n\\n\\n\\nStack Exchange Network\\n\\n\\n\\n                                    Technology\\n                                \\n\\n\\n\\n                                    Culture & recreation\\n                                \\n\\n\\n\\n                                    Life & arts\\n                                \\n\\n\\n\\n                                    Science\\n                                \\n\\n\\n\\n                                    Professional\\n                                \\n\\n\\n\\n                                    Business\\n                                \\n\\n\\n\\n                                    API\\n                                \\n\\n\\n\\n                                    Data\\n                                \\n\\n\\n\\n\\n\\n\\n\\nBlog\\nFacebook\\nTwitter\\nLinkedIn\\nInstagram\\n\\n\\nSite design / logo © 2024 Stack Exchange Inc; user contributions licensed under CC BY-SA.                    rev\\xa02024.8.6.13652\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/'}, page_content=\"\\n\\n\\n\\n [New Book] Click to get Mastering Digital Art with Stable Diffusion!\\n Use the offer code 20offearlybird to get 20% off. Hurry, sale ends soon!\\nNavigation\\n\\n\\n\\nMachineLearningMastery.com\\nMaking developers awesome at machine learning\\n\\n\\n\\n Click to Take the FREE Computer Vision Crash-Course\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nHome\\nMain MenuGet Started\\nBlog\\nTopics\\n\\nAttention\\nBetter Deep Learning\\nCalculus\\nChatGPT\\nCode Algorithms\\nComputer Vision\\nData Preparation\\nData Science\\nDeep Learning (keras)\\nDeep Learning with PyTorch\\nEnsemble Learning\\nGANs\\nNeural Net Time Series\\nNLP (Text)\\nImbalanced Learning\\nIntro to Time Series\\nIntro to Algorithms\\nLinear Algebra\\nLSTMs\\nOpenCV\\nOptimization\\nProbability\\nPython (scikit-learn)\\nPython for Machine Learning\\nR (caret)\\nStable Diffusion\\nStatistics\\nWeka (no code)\\nXGBoost\\n\\n\\neBooks\\nFAQ\\nAbout\\nContact\\n \\n\\n\\nReturn to Content\\n\\n\\n\\n\\n\\n\\nHow to Develop a CNN for MNIST Handwritten Digit Classification \\nBy Jason Brownlee on November 14, 2021 in Deep Learning for Computer Vision  188\\n\\n\\n\\n\\nShare  \\n\\nTweet \\n\\n        \\nShare \\n\\nHow to Develop a Convolutional Neural Network From Scratch for MNIST Handwritten Digit Classification.\\nThe MNIST handwritten digit classification problem is a standard dataset used in computer vision and deep learning.\\nAlthough the dataset is effectively solved, it can be used as the basis for learning and practicing how to develop, evaluate, and use convolutional deep learning neural networks for image classification from scratch. This includes how to develop a robust test harness for estimating the performance of the model, how to explore improvements to the model, and how to save the model and later load it to make predictions on new data.\\nIn this tutorial, you will discover how to develop a convolutional neural network for handwritten digit classification from scratch.\\nAfter completing this tutorial, you will know:\\n\\nHow to develop a test harness to develop a robust evaluation of a model and establish a baseline of performance for a classification task.\\nHow to explore extensions to a baseline model to improve learning and model capacity.\\nHow to develop a finalized model, evaluate the performance of the final model, and use it to make predictions on new images.\\n\\nKick-start your project with my new book Deep Learning for Computer Vision, including step-by-step tutorials and the Python source code files for all examples.\\nLet’s get started.\\n\\nUpdated Dec/2019: Updated examples for TensorFlow 2.0 and Keras 2.3.\\nUpdated Jan/2020: Fixed a bug where models were defined outside the cross-validation loop.\\nUpdated Nov/2021: Updated to use Tensorflow 2.6\\n\\nHow to Develop a Convolutional Neural Network From Scratch for MNIST Handwritten Digit ClassificationPhoto by Richard Allaway, some rights reserved.\\nTutorial Overview\\nThis tutorial is divided into five parts; they are:\\n\\nMNIST Handwritten Digit Classification Dataset\\nModel Evaluation Methodology\\nHow to Develop a Baseline Model\\nHow to Develop an Improved Model\\nHow to Finalize the Model and Make Predictions\\n\\n\\n\\nWant Results with Deep Learning for Computer Vision?\\nTake my free 7-day email crash course now (with sample code).\\nClick to sign-up and also get a free PDF Ebook version of the course.\\n Click here to subscribe \\n\\n\\nDevelopment Environment\\nThis tutorial assumes that you are using standalone Keras running on top of TensorFlow with Python 3. If you need help setting up your development environment see this tutorial:\\n\\nHow to Setup Your Python Environment for Machine Learning with Anaconda\\n\\nMNIST Handwritten Digit Classification Dataset\\nThe MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset.\\nIt is a dataset of 60,000 small square 28×28 pixel grayscale images of handwritten single digits between 0 and 9.\\nThe task is to classify a given image of a handwritten digit into one of 10 classes representing integer values from 0 to 9, inclusively.\\nIt is a widely used and deeply understood dataset and, for the most part, is “solved.” Top-performing models are deep learning convolutional neural networks that achieve a classification accuracy of above 99%, with an error rate between 0.4 %and 0.2% on the hold out test dataset.\\nThe example below loads the MNIST dataset using the Keras API and creates a plot of the first nine images in the training dataset.\\n\\n\\n\\n\\n\\n# example of loading the mnist dataset\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom matplotlib import pyplot as plt\\r\\n# load dataset\\r\\n(trainX, trainy), (testX, testy) = mnist.load_data()\\r\\n# summarize loaded dataset\\r\\nprint('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\\r\\nprint('Test: X=%s, y=%s' % (testX.shape, testy.shape))\\r\\n# plot first few images\\r\\nfor i in range(9):\\r\\n\\t# define subplot\\r\\n\\tplt.subplot(330 + 1 + i)\\r\\n\\t# plot raw pixel data\\r\\n\\tplt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\\r\\n# show the figure\\r\\nplt.show()\\n\\n\\n\\n\\n12345678910111213141516\\n\\n# example of loading the mnist datasetfrom tensorflow.keras.datasets import mnistfrom matplotlib import pyplot as plt# load dataset(trainX, trainy), (testX, testy) = mnist.load_data()# summarize loaded datasetprint('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))print('Test: X=%s, y=%s' % (testX.shape, testy.shape))# plot first few imagesfor i in range(9): # define subplot plt.subplot(330 + 1 + i) # plot raw pixel data plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))# show the figureplt.show()\\n\\n\\n\\nRunning the example loads the MNIST train and test dataset and prints their shape.\\nWe can see that there are 60,000 examples in the training dataset and 10,000 in the test dataset and that images are indeed square with 28×28 pixels.\\n\\n\\n\\n\\n\\nTrain: X=(60000, 28, 28), y=(60000,)\\r\\nTest: X=(10000, 28, 28), y=(10000,)\\n\\n\\n\\n\\n12\\n\\nTrain: X=(60000, 28, 28), y=(60000,)Test: X=(10000, 28, 28), y=(10000,)\\n\\n\\n\\nA plot of the first nine images in the dataset is also created showing the natural handwritten nature of the images to be classified.\\nPlot of a Subset of Images From the MNIST Dataset\\nModel Evaluation Methodology\\nAlthough the MNIST dataset is effectively solved, it can be a useful starting point for developing and practicing a methodology for solving image classification tasks using convolutional neural networks.\\nInstead of reviewing the literature on well-performing models on the dataset, we can develop a new model from scratch.\\nThe dataset already has a well-defined train and test dataset that we can use.\\nIn order to estimate the performance of a model for a given training run, we can further split the training set into a train and validation dataset. Performance on the train and validation dataset over each run can then be plotted to provide learning curves and insight into how well a model is learning the problem.\\nThe Keras API supports this by specifying the “validation_data” argument to the model.fit() function when training the model, that will, in turn, return an object that describes model performance for the chosen loss and metrics on each training epoch.\\n\\n\\n\\n\\n\\n# record model performance on a validation dataset during training\\r\\nhistory = model.fit(..., validation_data=(valX, valY))\\n\\n\\n\\n\\n12\\n\\n# record model performance on a validation dataset during traininghistory = model.fit(..., validation_data=(valX, valY))\\n\\n\\n\\nIn order to estimate the performance of a model on the problem in general, we can use k-fold cross-validation, perhaps five-fold cross-validation. This will give some account of the models variance with both respect to differences in the training and test datasets, and in terms of the stochastic nature of the learning algorithm. The performance of a model can be taken as the mean performance across k-folds, given the standard deviation, that could be used to estimate a confidence interval if desired.\\nWe can use the KFold class from the scikit-learn API to implement the k-fold cross-validation evaluation of a given neural network model. There are many ways to achieve this, although we can choose a flexible approach where the KFold class is only used to specify the row indexes used for each spit.\\n\\n\\n\\n\\n\\n# example of k-fold cv for a neural net\\r\\ndata = ...\\r\\n# prepare cross validation\\r\\nkfold = KFold(5, shuffle=True, random_state=1)\\r\\n# enumerate splits\\r\\nfor train_ix, test_ix in kfold.split(data):\\r\\n        model = ...\\r\\n\\t...\\n\\n\\n\\n\\n12345678\\n\\n# example of k-fold cv for a neural netdata = ...# prepare cross validationkfold = KFold(5, shuffle=True, random_state=1)# enumerate splitsfor train_ix, test_ix in kfold.split(data):\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0model = ... ...\\n\\n\\n\\nWe will hold back the actual test dataset and use it as an evaluation of our final model.\\nHow to Develop a Baseline Model\\nThe first step is to develop a baseline model.\\nThis is critical as it both involves developing the infrastructure for the test harness so that any model we design can be evaluated on the dataset, and it establishes a baseline in model performance on the problem, by which all improvements can be compared.\\nThe design of the test harness is modular, and we can develop a separate function for each piece. This allows a given aspect of the test harness to be modified or inter-changed, if we desire, separately from the rest.\\nWe can develop this test harness with five key elements. They are the loading of the dataset, the preparation of the dataset, the definition of the model, the evaluation of the model, and the presentation of results.\\nLoad Dataset\\nWe know some things about the dataset.\\nFor example, we know that the images are all pre-aligned (e.g. each image only contains a hand-drawn digit), that the images all have the same square size of 28×28 pixels, and that the images are grayscale.\\nTherefore, we can load the images and reshape the data arrays to have a single color channel.\\n\\n\\n\\n\\n\\n# load dataset\\r\\n(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n# reshape dataset to have a single channel\\r\\ntrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\ntestX = testX.reshape((testX.shape[0], 28, 28, 1))\\n\\n\\n\\n\\n12345\\n\\n# load dataset(trainX, trainY), (testX, testY) = mnist.load_data()# reshape dataset to have a single channeltrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))testX = testX.reshape((testX.shape[0], 28, 28, 1))\\n\\n\\n\\nWe also know that there are 10 classes and that classes are represented as unique integers.\\nWe can, therefore, use a one hot encoding for the class element of each sample, transforming the integer into a 10 element binary vector with a 1 for the index of the class value, and 0 values for all other classes. We can achieve this with the to_categorical() utility function.\\n\\n\\n\\n\\n\\n# one hot encode target values\\r\\ntrainY = to_categorical(trainY)\\r\\ntestY = to_categorical(testY)\\n\\n\\n\\n\\n123\\n\\n# one hot encode target valuestrainY = to_categorical(trainY)testY = to_categorical(testY)\\n\\n\\n\\nThe load_dataset() function implements these behaviors and can be used to load the dataset.\\n\\n\\n\\n\\n\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\n\\n\\n\\n\\n1234567891011\\n\\n# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\n\\n\\n\\n\\nPrepare Pixel Data\\nWe know that the pixel values for each image in the dataset are unsigned integers in the range between black and white, or 0 and 255.\\nWe do not know the best way to scale the pixel values for modeling, but we know that some scaling will be required.\\nA good starting point is to normalize the pixel values of grayscale images, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value.\\n\\n\\n\\n\\n\\n# convert from integers to floats\\r\\ntrain_norm = train.astype('float32')\\r\\ntest_norm = test.astype('float32')\\r\\n# normalize to range 0-1\\r\\ntrain_norm = train_norm / 255.0\\r\\ntest_norm = test_norm / 255.0\\n\\n\\n\\n\\n123456\\n\\n# convert from integers to floatstrain_norm = train.astype('float32')test_norm = test.astype('float32')# normalize to range 0-1train_norm = train_norm / 255.0test_norm = test_norm / 255.0\\n\\n\\n\\nThe prep_pixels() function below implements these behaviors and is provided with the pixel values for both the train and test datasets that will need to be scaled.\\n\\n\\n\\n\\n\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\n\\n\\n\\n\\n12345678910\\n\\n# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\n\\n\\n\\nThis function must be called to prepare the pixel values prior to any modeling.\\nDefine Model\\nNext, we need to define a baseline convolutional neural network model for the problem.\\nThe model has two main aspects: the feature extraction front end comprised of convolutional and pooling layers, and the classifier backend that will make a prediction.\\nFor the convolutional front-end, we can start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer. The filter maps can then be flattened to provide features to the classifier.\\nGiven that the problem is a multi-class classification task, we know that we will require an output layer with 10 nodes in order to predict the probability distribution of an image belonging to each of the 10 classes. This will also require the use of a softmax activation function. Between the feature extractor and the output layer, we can add a dense layer to interpret the features, in this case with 100 nodes.\\nAll layers will use the ReLU activation function and the He weight initialization scheme, both best practices.\\nWe will use a conservative configuration for the stochastic gradient descent optimizer with a learning rate of 0.01 and a momentum of 0.9. The categorical cross-entropy loss function will be optimized, suitable for multi-class classification, and we will monitor the classification accuracy metric, which is appropriate given we have the same number of examples in each of the 10 classes.\\nThe define_model() function below will define and return this model.\\n\\n\\n\\n\\n\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\n\\n\\n\\n\\n123456789101112\\n\\n# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\n\\n\\n\\n\\nEvaluate Model\\nAfter the model is defined, we need to evaluate it.\\nThe model will be evaluated using five-fold cross-validation. The value of k=5 was chosen to provide a baseline for both repeated evaluation and to not be so large as to require a long running time. Each test set will be 20% of the training dataset, or about 12,000 examples, close to the size of the actual test set for this problem.\\nThe training dataset is shuffled prior to being split, and the sample shuffling is performed each time, so that any model we evaluate will have the same train and test datasets in each fold, providing an apples-to-apples comparison between models.\\nWe will train the baseline model for a modest 10 training epochs with a default batch size of 32 examples. The test set for each fold will be used to evaluate the model both during each epoch of the training run, so that we can later create learning curves, and at the end of the run, so that we can estimate the performance of the model. As such, we will keep track of the resulting history from each run, as well as the classification accuracy of the fold.\\nThe evaluate_model() function below implements these behaviors, taking the training dataset as arguments and returning a list of accuracy scores and training histories that can be later summarized.\\n\\n\\n\\n\\n\\n# evaluate a model using k-fold cross-validation\\r\\ndef evaluate_model(dataX, dataY, n_folds=5):\\r\\n\\tscores, histories = list(), list()\\r\\n\\t# prepare cross validation\\r\\n\\tkfold = KFold(n_folds, shuffle=True, random_state=1)\\r\\n\\t# enumerate splits\\r\\n\\tfor train_ix, test_ix in kfold.split(dataX):\\r\\n\\t\\t# define model\\r\\n\\t\\tmodel = define_model()\\r\\n\\t\\t# select rows for train and test\\r\\n\\t\\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\\r\\n\\t\\t# fit model\\r\\n\\t\\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\r\\n\\t\\t# evaluate model\\r\\n\\t\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\t\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\t\\t# stores scores\\r\\n\\t\\tscores.append(acc)\\r\\n\\t\\thistories.append(history)\\r\\n\\treturn scores, histories\\n\\n\\n\\n\\n1234567891011121314151617181920\\n\\n# evaluate a model using k-fold cross-validationdef evaluate_model(dataX, dataY, n_folds=5): scores, histories = list(), list() # prepare cross validation kfold = KFold(n_folds, shuffle=True, random_state=1) # enumerate splits for train_ix, test_ix in kfold.split(dataX): # define model model = define_model() # select rows for train and test trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix] # fit model history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0) # evaluate model _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0)) # stores scores scores.append(acc) histories.append(history) return scores, histories\\n\\n\\n\\n\\nPresent Results\\nOnce the model has been evaluated, we can present the results.\\nThere are two key aspects to present: the diagnostics of the learning behavior of the model during training and the estimation of the model performance. These can be implemented using separate functions.\\nFirst, the diagnostics involve creating a line plot showing model performance on the train and test set during each fold of the k-fold cross-validation. These plots are valuable for getting an idea of whether a model is overfitting, underfitting, or has a good fit for the dataset.\\nWe will create a single figure with two subplots, one for loss and one for accuracy. Blue lines will indicate model performance on the training dataset and orange lines will indicate performance on the hold out test dataset. The summarize_diagnostics() function below creates and shows this plot given the collected training histories.\\n\\n\\n\\n\\n\\n# plot diagnostic learning curves\\r\\ndef summarize_diagnostics(histories):\\r\\n\\tfor i in range(len(histories)):\\r\\n\\t\\t# plot loss\\r\\n\\t\\tplt.subplot(2, 1, 1)\\r\\n\\t\\tplt.title('Cross Entropy Loss')\\r\\n\\t\\tplt.plot(histories[i].history['loss'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\\r\\n\\t\\t# plot accuracy\\r\\n\\t\\tplt.subplot(2, 1, 2)\\r\\n\\t\\tplt.title('Classification Accuracy')\\r\\n\\t\\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\\r\\n\\tplt.show()\\n\\n\\n\\n\\n1234567891011121314\\n\\n# plot diagnostic learning curvesdef summarize_diagnostics(histories): for i in range(len(histories)): # plot loss plt.subplot(2, 1, 1) plt.title('Cross Entropy Loss') plt.plot(histories[i].history['loss'], color='blue', label='train') plt.plot(histories[i].history['val_loss'], color='orange', label='test') # plot accuracy plt.subplot(2, 1, 2) plt.title('Classification Accuracy') plt.plot(histories[i].history['accuracy'], color='blue', label='train') plt.plot(histories[i].history['val_accuracy'], color='orange', label='test') plt.show()\\n\\n\\n\\nNext, the classification accuracy scores collected during each fold can be summarized by calculating the mean and standard deviation. This provides an estimate of the average expected performance of the model trained on this dataset, with an estimate of the average variance in the mean. We will also summarize the distribution of scores by creating and showing a box and whisker plot.\\nThe summarize_performance() function below implements this for a given list of scores collected during model evaluation.\\n\\n\\n\\n\\n\\n# summarize model performance\\r\\ndef summarize_performance(scores):\\r\\n\\t# print summary\\r\\n\\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\\r\\n\\t# box and whisker plots of results\\r\\n\\tplt.boxplot(scores)\\r\\n\\tplt.show()\\n\\n\\n\\n\\n1234567\\n\\n# summarize model performancedef summarize_performance(scores): # print summary print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores))) # box and whisker plots of results plt.boxplot(scores) plt.show()\\n\\n\\n\\n\\nComplete Example\\nWe need a function that will drive the test harness.\\nThis involves calling all of the define functions.\\n\\n\\n\\n\\n\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# evaluate model\\r\\n\\tscores, histories = evaluate_model(trainX, trainY)\\r\\n\\t# learning curves\\r\\n\\tsummarize_diagnostics(histories)\\r\\n\\t# summarize estimated performance\\r\\n\\tsummarize_performance(scores)\\n\\n\\n\\n\\n123456789101112\\n\\n# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # evaluate model scores, histories = evaluate_model(trainX, trainY) # learning curves summarize_diagnostics(histories) # summarize estimated performance summarize_performance(scores)\\n\\n\\n\\nWe now have everything we need; the complete code example for a baseline convolutional neural network model on the MNIST dataset is listed below.\\n\\n\\n\\n\\n\\n# baseline cnn model for mnist\\r\\nfrom numpy import mean\\r\\nfrom numpy import std\\r\\nfrom matplotlib import pyplot as plt\\r\\nfrom sklearn.model_selection import KFold\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\nfrom tensorflow.keras.models import Sequential\\r\\nfrom tensorflow.keras.layers import Conv2D\\r\\nfrom tensorflow.keras.layers import MaxPooling2D\\r\\nfrom tensorflow.keras.layers import Dense\\r\\nfrom tensorflow.keras.layers import Flatten\\r\\nfrom tensorflow.keras.optimizers import SGD\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\r\\n\\r\\n# evaluate a model using k-fold cross-validation\\r\\ndef evaluate_model(dataX, dataY, n_folds=5):\\r\\n\\tscores, histories = list(), list()\\r\\n\\t# prepare cross validation\\r\\n\\tkfold = KFold(n_folds, shuffle=True, random_state=1)\\r\\n\\t# enumerate splits\\r\\n\\tfor train_ix, test_ix in kfold.split(dataX):\\r\\n\\t\\t# define model\\r\\n\\t\\tmodel = define_model()\\r\\n\\t\\t# select rows for train and test\\r\\n\\t\\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\\r\\n\\t\\t# fit model\\r\\n\\t\\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\r\\n\\t\\t# evaluate model\\r\\n\\t\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\t\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\t\\t# stores scores\\r\\n\\t\\tscores.append(acc)\\r\\n\\t\\thistories.append(history)\\r\\n\\treturn scores, histories\\r\\n\\r\\n# plot diagnostic learning curves\\r\\ndef summarize_diagnostics(histories):\\r\\n\\tfor i in range(len(histories)):\\r\\n\\t\\t# plot loss\\r\\n\\t\\tplt.subplot(2, 1, 1)\\r\\n\\t\\tplt.title('Cross Entropy Loss')\\r\\n\\t\\tplt.plot(histories[i].history['loss'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\\r\\n\\t\\t# plot accuracy\\r\\n\\t\\tplt.subplot(2, 1, 2)\\r\\n\\t\\tplt.title('Classification Accuracy')\\r\\n\\t\\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\\r\\n\\tplt.show()\\r\\n\\r\\n# summarize model performance\\r\\ndef summarize_performance(scores):\\r\\n\\t# print summary\\r\\n\\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\\r\\n\\t# box and whisker plots of results\\r\\n\\tplt.boxplot(scores)\\r\\n\\tplt.show()\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# evaluate model\\r\\n\\tscores, histories = evaluate_model(trainX, trainY)\\r\\n\\t# learning curves\\r\\n\\tsummarize_diagnostics(histories)\\r\\n\\t# summarize estimated performance\\r\\n\\tsummarize_performance(scores)\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109\\n\\n# baseline cnn model for mnistfrom numpy import meanfrom numpy import stdfrom matplotlib import pyplot as pltfrom sklearn.model_selection import KFoldfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dfrom tensorflow.keras.layers import Densefrom tensorflow.keras.layers import Flattenfrom tensorflow.keras.optimizers import SGD\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\xa0# evaluate a model using k-fold cross-validationdef evaluate_model(dataX, dataY, n_folds=5): scores, histories = list(), list() # prepare cross validation kfold = KFold(n_folds, shuffle=True, random_state=1) # enumerate splits for train_ix, test_ix in kfold.split(dataX): # define model model = define_model() # select rows for train and test trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix] # fit model history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0) # evaluate model _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0)) # stores scores scores.append(acc) histories.append(history) return scores, histories\\xa0# plot diagnostic learning curvesdef summarize_diagnostics(histories): for i in range(len(histories)): # plot loss plt.subplot(2, 1, 1) plt.title('Cross Entropy Loss') plt.plot(histories[i].history['loss'], color='blue', label='train') plt.plot(histories[i].history['val_loss'], color='orange', label='test') # plot accuracy plt.subplot(2, 1, 2) plt.title('Classification Accuracy') plt.plot(histories[i].history['accuracy'], color='blue', label='train') plt.plot(histories[i].history['val_accuracy'], color='orange', label='test') plt.show()\\xa0# summarize model performancedef summarize_performance(scores): # print summary print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores))) # box and whisker plots of results plt.boxplot(scores) plt.show()\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # evaluate model scores, histories = evaluate_model(trainX, trainY) # learning curves summarize_diagnostics(histories) # summarize estimated performance summarize_performance(scores)\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nRunning the example prints the classification accuracy for each fold of the cross-validation process. This is helpful to get an idea that the model evaluation is progressing.\\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\\nWe can see two cases where the model achieves perfect skill and one case where it achieved lower than 98% accuracy. These are good results.\\n\\n\\n\\n\\n\\n> 98.550\\r\\n> 98.600\\r\\n> 98.642\\r\\n> 98.850\\r\\n> 98.742\\n\\n\\n\\n\\n12345\\n\\n> 98.550> 98.600> 98.642> 98.850> 98.742\\n\\n\\n\\nNext, a diagnostic plot is shown, giving insight into the learning behavior of the model across each fold.\\nIn this case, we can see that the model generally achieves a good fit, with train and test learning curves converging. There is no obvious sign of over- or underfitting.\\nLoss and Accuracy Learning Curves for the Baseline Model During k-Fold Cross-Validation\\nNext, a summary of the model performance is calculated.\\nWe can see in this case, the model has an estimated skill of about 98.6%, which is reasonable.\\n\\n\\n\\n\\n\\nAccuracy: mean=98.677 std=0.107, n=5\\n\\n\\n\\n\\n1\\n\\nAccuracy: mean=98.677 std=0.107, n=5\\n\\n\\n\\nFinally, a box and whisker plot is created to summarize the distribution of accuracy scores.\\nBox and Whisker Plot of Accuracy Scores for the Baseline Model Evaluated Using k-Fold Cross-Validation\\nWe now have a robust test harness and a well-performing baseline model.\\nHow to Develop an Improved Model\\nThere are many ways that we might explore improvements to the baseline model.\\nWe will look at areas of model configuration that often result in an improvement, so-called low-hanging fruit. The first is a change to the learning algorithm, and the second is an increase in the depth of the model.\\nImprovement to Learning\\nThere are many aspects of the learning algorithm that can be explored for improvement.\\nPerhaps the point of biggest leverage is the learning rate, such as evaluating the impact that smaller or larger values of the learning rate may have, as well as schedules that change the learning rate during training.\\nAnother approach that can rapidly accelerate the learning of a model and can result in large performance improvements is batch normalization. We will evaluate the effect that batch normalization has on our baseline model.\\nBatch normalization can be used after convolutional and fully connected layers. It has the effect of changing the distribution of the output of the layer, specifically by standardizing the outputs. This has the effect of stabilizing and accelerating the learning process.\\nWe can update the model definition to use batch normalization after the activation function for the convolutional and dense layers of our baseline model. The updated version of define_model() function with batch normalization is listed below.\\n\\n\\n\\n\\n\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(BatchNormalization())\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(BatchNormalization())\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\n\\n\\n\\n\\n1234567891011121314\\n\\n# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(BatchNormalization()) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(BatchNormalization()) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\n\\n\\n\\nThe complete code listing with this change is provided below.\\n\\n\\n\\n\\n\\n# cnn model with batch normalization for mnist\\r\\nfrom numpy import mean\\r\\nfrom numpy import std\\r\\nfrom matplotlib import pyplot as plt\\r\\nfrom sklearn.model_selection import KFold\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\nfrom tensorflow.keras.models import Sequential\\r\\nfrom tensorflow.keras.layers import Conv2D\\r\\nfrom tensorflow.keras.layers import MaxPooling2D\\r\\nfrom tensorflow.keras.layers import Dense\\r\\nfrom tensorflow.keras.layers import Flatten\\r\\nfrom tensorflow.keras.optimizers import SGD\\r\\nfrom tensorflow.keras.layers import BatchNormalization\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(BatchNormalization())\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(BatchNormalization())\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\r\\n\\r\\n# evaluate a model using k-fold cross-validation\\r\\ndef evaluate_model(dataX, dataY, n_folds=5):\\r\\n\\tscores, histories = list(), list()\\r\\n\\t# prepare cross validation\\r\\n\\tkfold = KFold(n_folds, shuffle=True, random_state=1)\\r\\n\\t# enumerate splits\\r\\n\\tfor train_ix, test_ix in kfold.split(dataX):\\r\\n\\t\\t# define model\\r\\n\\t\\tmodel = define_model()\\r\\n\\t\\t# select rows for train and test\\r\\n\\t\\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\\r\\n\\t\\t# fit model\\r\\n\\t\\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\r\\n\\t\\t# evaluate model\\r\\n\\t\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\t\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\t\\t# stores scores\\r\\n\\t\\tscores.append(acc)\\r\\n\\t\\thistories.append(history)\\r\\n\\treturn scores, histories\\r\\n\\r\\n# plot diagnostic learning curves\\r\\ndef summarize_diagnostics(histories):\\r\\n\\tfor i in range(len(histories)):\\r\\n\\t\\t# plot loss\\r\\n\\t\\tplt.subplot(2, 1, 1)\\r\\n\\t\\tplt.title('Cross Entropy Loss')\\r\\n\\t\\tplt.plot(histories[i].history['loss'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\\r\\n\\t\\t# plot accuracy\\r\\n\\t\\tplt.subplot(2, 1, 2)\\r\\n\\t\\tplt.title('Classification Accuracy')\\r\\n\\t\\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\\r\\n\\tplt.show()\\r\\n\\r\\n# summarize model performance\\r\\ndef summarize_performance(scores):\\r\\n\\t# print summary\\r\\n\\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\\r\\n\\t# box and whisker plots of results\\r\\n\\tplt.boxplot(scores)\\r\\n\\tplt.show()\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# evaluate model\\r\\n\\tscores, histories = evaluate_model(trainX, trainY)\\r\\n\\t# learning curves\\r\\n\\tsummarize_diagnostics(histories)\\r\\n\\t# summarize estimated performance\\r\\n\\tsummarize_performance(scores)\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112\\n\\n# cnn model with batch normalization for mnistfrom numpy import meanfrom numpy import stdfrom matplotlib import pyplot as pltfrom sklearn.model_selection import KFoldfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dfrom tensorflow.keras.layers import Densefrom tensorflow.keras.layers import Flattenfrom tensorflow.keras.optimizers import SGDfrom tensorflow.keras.layers import BatchNormalization\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(BatchNormalization()) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(BatchNormalization()) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\xa0# evaluate a model using k-fold cross-validationdef evaluate_model(dataX, dataY, n_folds=5): scores, histories = list(), list() # prepare cross validation kfold = KFold(n_folds, shuffle=True, random_state=1) # enumerate splits for train_ix, test_ix in kfold.split(dataX): # define model model = define_model() # select rows for train and test trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix] # fit model history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0) # evaluate model _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0)) # stores scores scores.append(acc) histories.append(history) return scores, histories\\xa0# plot diagnostic learning curvesdef summarize_diagnostics(histories): for i in range(len(histories)): # plot loss plt.subplot(2, 1, 1) plt.title('Cross Entropy Loss') plt.plot(histories[i].history['loss'], color='blue', label='train') plt.plot(histories[i].history['val_loss'], color='orange', label='test') # plot accuracy plt.subplot(2, 1, 2) plt.title('Classification Accuracy') plt.plot(histories[i].history['accuracy'], color='blue', label='train') plt.plot(histories[i].history['val_accuracy'], color='orange', label='test') plt.show()\\xa0# summarize model performancedef summarize_performance(scores): # print summary print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores))) # box and whisker plots of results plt.boxplot(scores) plt.show()\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # evaluate model scores, histories = evaluate_model(trainX, trainY) # learning curves summarize_diagnostics(histories) # summarize estimated performance summarize_performance(scores)\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nRunning the example again reports model performance for each fold of the cross-validation process.\\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\\nWe can see perhaps a small drop in model performance as compared to the baseline across the cross-validation folds.\\n\\n\\n\\n\\n\\n> 98.475\\r\\n> 98.608\\r\\n> 98.683\\r\\n> 98.783\\r\\n> 98.667\\n\\n\\n\\n\\n12345\\n\\n> 98.475> 98.608> 98.683> 98.783> 98.667\\n\\n\\n\\nA plot of the learning curves is created, in this case showing that the speed of learning (improvement over epochs) does not appear to be different from the baseline model.\\nThe plots suggest that batch normalization, at least as implemented in this case, does not offer any benefit.\\nLoss and Accuracy Learning Curves for the BatchNormalization Model During k-Fold Cross-Validation\\nNext, the estimated performance of the model is presented, showing performance with a slight decrease in the mean accuracy of the model: 98.643 as compared to 98.677 with the baseline model.\\n\\n\\n\\n\\n\\nAccuracy: mean=98.643 std=0.101, n=5\\n\\n\\n\\n\\n1\\n\\nAccuracy: mean=98.643 std=0.101, n=5\\n\\n\\n\\nBox and Whisker Plot of Accuracy Scores for the BatchNormalization Model Evaluated Using k-Fold Cross-Validation\\nIncrease in Model Depth\\nThere are many ways to change the model configuration in order to explore improvements over the baseline model.\\nTwo common approaches involve changing the capacity of the feature extraction part of the model or changing the capacity or function of the classifier part of the model. Perhaps the point of biggest influence is a change to the feature extractor.\\nWe can increase the depth of the feature extractor part of the model, following a VGG-like pattern of adding more convolutional and pooling layers with the same sized filter, while increasing the number of filters. In this case, we will add a double convolutional layer with 64 filters each, followed by another max pooling layer.\\nThe updated version of the define_model() function with this change is listed below.\\n\\n\\n\\n\\n\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\n\\n\\n\\n\\n123456789101112131415\\n\\n# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\n\\n\\n\\nFor completeness, the entire code listing, including this change, is provided below.\\n\\n\\n\\n\\n\\n# deeper cnn model for mnist\\r\\nfrom numpy import mean\\r\\nfrom numpy import std\\r\\nfrom matplotlib import pyplot as plt\\r\\nfrom sklearn.model_selection import KFold\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\nfrom tensorflow.keras.models import Sequential\\r\\nfrom tensorflow.keras.layers import Conv2D\\r\\nfrom tensorflow.keras.layers import MaxPooling2D\\r\\nfrom tensorflow.keras.layers import Dense\\r\\nfrom tensorflow.keras.layers import Flatten\\r\\nfrom tensorflow.keras.optimizers import SGD\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\r\\n\\r\\n# evaluate a model using k-fold cross-validation\\r\\ndef evaluate_model(dataX, dataY, n_folds=5):\\r\\n\\tscores, histories = list(), list()\\r\\n\\t# prepare cross validation\\r\\n\\tkfold = KFold(n_folds, shuffle=True, random_state=1)\\r\\n\\t# enumerate splits\\r\\n\\tfor train_ix, test_ix in kfold.split(dataX):\\r\\n\\t\\t# define model\\r\\n\\t\\tmodel = define_model()\\r\\n\\t\\t# select rows for train and test\\r\\n\\t\\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\\r\\n\\t\\t# fit model\\r\\n\\t\\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\r\\n\\t\\t# evaluate model\\r\\n\\t\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\t\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\t\\t# stores scores\\r\\n\\t\\tscores.append(acc)\\r\\n\\t\\thistories.append(history)\\r\\n\\treturn scores, histories\\r\\n\\r\\n# plot diagnostic learning curves\\r\\ndef summarize_diagnostics(histories):\\r\\n\\tfor i in range(len(histories)):\\r\\n\\t\\t# plot loss\\r\\n\\t\\tplt.subplot(2, 1, 1)\\r\\n\\t\\tplt.title('Cross Entropy Loss')\\r\\n\\t\\tplt.plot(histories[i].history['loss'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\\r\\n\\t\\t# plot accuracy\\r\\n\\t\\tplt.subplot(2, 1, 2)\\r\\n\\t\\tplt.title('Classification Accuracy')\\r\\n\\t\\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\\r\\n\\t\\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\\r\\n\\tplt.show()\\r\\n\\r\\n# summarize model performance\\r\\ndef summarize_performance(scores):\\r\\n\\t# print summary\\r\\n\\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\\r\\n\\t# box and whisker plots of results\\r\\n\\tplt.boxplot(scores)\\r\\n\\tplt.show()\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# evaluate model\\r\\n\\tscores, histories = evaluate_model(trainX, trainY)\\r\\n\\t# learning curves\\r\\n\\tsummarize_diagnostics(histories)\\r\\n\\t# summarize estimated performance\\r\\n\\tsummarize_performance(scores)\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112\\n\\n# deeper cnn model for mnistfrom numpy import meanfrom numpy import stdfrom matplotlib import pyplot as pltfrom sklearn.model_selection import KFoldfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dfrom tensorflow.keras.layers import Densefrom tensorflow.keras.layers import Flattenfrom tensorflow.keras.optimizers import SGD\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\xa0# evaluate a model using k-fold cross-validationdef evaluate_model(dataX, dataY, n_folds=5): scores, histories = list(), list() # prepare cross validation kfold = KFold(n_folds, shuffle=True, random_state=1) # enumerate splits for train_ix, test_ix in kfold.split(dataX): # define model model = define_model() # select rows for train and test trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix] # fit model history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0) # evaluate model _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0)) # stores scores scores.append(acc) histories.append(history) return scores, histories\\xa0# plot diagnostic learning curvesdef summarize_diagnostics(histories): for i in range(len(histories)): # plot loss plt.subplot(2, 1, 1) plt.title('Cross Entropy Loss') plt.plot(histories[i].history['loss'], color='blue', label='train') plt.plot(histories[i].history['val_loss'], color='orange', label='test') # plot accuracy plt.subplot(2, 1, 2) plt.title('Classification Accuracy') plt.plot(histories[i].history['accuracy'], color='blue', label='train') plt.plot(histories[i].history['val_accuracy'], color='orange', label='test') plt.show()\\xa0# summarize model performancedef summarize_performance(scores): # print summary print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores))) # box and whisker plots of results plt.boxplot(scores) plt.show()\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # evaluate model scores, histories = evaluate_model(trainX, trainY) # learning curves summarize_diagnostics(histories) # summarize estimated performance summarize_performance(scores)\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nRunning the example reports model performance for each fold of the cross-validation process.\\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\\nThe per-fold scores may suggest some improvement over the baseline.\\n\\n\\n\\n\\n\\n> 99.058\\r\\n> 99.042\\r\\n> 98.883\\r\\n> 99.192\\r\\n> 99.133\\n\\n\\n\\n\\n12345\\n\\n> 99.058> 99.042> 98.883> 99.192> 99.133\\n\\n\\n\\nA plot of the learning curves is created, in this case showing that the models still have a good fit on the problem, with no clear signs of overfitting. The plots may even suggest that further training epochs could be helpful.\\nLoss and Accuracy Learning Curves for the Deeper Model During k-Fold Cross-Validation\\nNext, the estimated performance of the model is presented, showing a small improvement in performance as compared to the baseline from 98.677 to 99.062, with a small drop in the standard deviation as well.\\n\\n\\n\\n\\n\\nAccuracy: mean=99.062 std=0.104, n=5\\n\\n\\n\\n\\n1\\n\\nAccuracy: mean=99.062 std=0.104, n=5\\n\\n\\n\\nBox and Whisker Plot of Accuracy Scores for the Deeper Model Evaluated Using k-Fold Cross-Validation\\nHow to Finalize the Model and Make Predictions\\nThe process of model improvement may continue for as long as we have ideas and the time and resources to test them out.\\nAt some point, a final model configuration must be chosen and adopted. In this case, we will choose the deeper model as our final model.\\nFirst, we will finalize our model, but fitting a model on the entire training dataset and saving the model to file for later use. We will then load the model and evaluate its performance on the hold out test dataset to get an idea of how well the chosen model actually performs in practice. Finally, we will use the saved model to make a prediction on a single image.\\nSave Final Model\\nA final model is typically fit on all available data, such as the combination of all train and test dataset.\\nIn this tutorial, we are intentionally holding back a test dataset so that we can estimate the performance of the final model, which can be a good idea in practice. As such, we will fit our model on the training dataset only.\\n\\n\\n\\n\\n\\n# fit model\\r\\nmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\\n\\n\\n\\n\\n12\\n\\n# fit modelmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\\n\\n\\n\\nOnce fit, we can save the final model to an H5 file by calling the save() function on the model and pass in the chosen filename.\\n\\n\\n\\n\\n\\n# save model\\r\\nmodel.save('final_model.h5')\\n\\n\\n\\n\\n12\\n\\n# save modelmodel.save('final_model.h5')\\n\\n\\n\\nNote, saving and loading a Keras model requires that the h5py library is installed on your workstation.\\nThe complete example of fitting the final deep model on the training dataset and saving it to file is listed below.\\n\\n\\n\\n\\n\\n# save the final model to file\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\nfrom tensorflow.keras.models import Sequential\\r\\nfrom tensorflow.keras.layers import Conv2D\\r\\nfrom tensorflow.keras.layers import MaxPooling2D\\r\\nfrom tensorflow.keras.layers import Dense\\r\\nfrom tensorflow.keras.layers import Flatten\\r\\nfrom tensorflow.keras.optimizers import SGD\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# define cnn model\\r\\ndef define_model():\\r\\n\\tmodel = Sequential()\\r\\n\\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(MaxPooling2D((2, 2)))\\r\\n\\tmodel.add(Flatten())\\r\\n\\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\\r\\n\\tmodel.add(Dense(10, activation='softmax'))\\r\\n\\t# compile model\\r\\n\\topt = SGD(learning_rate=0.01, momentum=0.9)\\r\\n\\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\\r\\n\\treturn model\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# define model\\r\\n\\tmodel = define_model()\\r\\n\\t# fit model\\r\\n\\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\\r\\n\\t# save model\\r\\n\\tmodel.save('final_model.h5')\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364\\n\\n# save the final model to filefrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dfrom tensorflow.keras.layers import Densefrom tensorflow.keras.layers import Flattenfrom tensorflow.keras.optimizers import SGD\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# define cnn modeldef define_model(): model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) model.add(MaxPooling2D((2, 2))) model.add(Flatten()) model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) model.add(Dense(10, activation='softmax')) # compile model opt = SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) return model\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # define model model = define_model() # fit model model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0) # save model model.save('final_model.h5')\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nAfter running this example, you will now have a 1.2-megabyte file with the name ‘final_model.h5‘ in your current working directory.\\nEvaluate Final Model\\nWe can now load the final model and evaluate it on the hold out test dataset.\\nThis is something we might do if we were interested in presenting the performance of the chosen model to project stakeholders.\\nThe model can be loaded via the load_model() function.\\nThe complete example of loading the saved model and evaluating it on the test dataset is listed below.\\n\\n\\n\\n\\n\\n# evaluate the deep model on the test dataset\\r\\nfrom tensorflow.keras.datasets import mnist\\r\\nfrom tensorflow.keras.models import load_model\\r\\nfrom tensorflow.keras.utils import to_categorical\\r\\n\\r\\n# load train and test dataset\\r\\ndef load_dataset():\\r\\n\\t# load dataset\\r\\n\\t(trainX, trainY), (testX, testY) = mnist.load_data()\\r\\n\\t# reshape dataset to have a single channel\\r\\n\\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\r\\n\\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\\r\\n\\t# one hot encode target values\\r\\n\\ttrainY = to_categorical(trainY)\\r\\n\\ttestY = to_categorical(testY)\\r\\n\\treturn trainX, trainY, testX, testY\\r\\n\\r\\n# scale pixels\\r\\ndef prep_pixels(train, test):\\r\\n\\t# convert from integers to floats\\r\\n\\ttrain_norm = train.astype('float32')\\r\\n\\ttest_norm = test.astype('float32')\\r\\n\\t# normalize to range 0-1\\r\\n\\ttrain_norm = train_norm / 255.0\\r\\n\\ttest_norm = test_norm / 255.0\\r\\n\\t# return normalized images\\r\\n\\treturn train_norm, test_norm\\r\\n\\r\\n# run the test harness for evaluating a model\\r\\ndef run_test_harness():\\r\\n\\t# load dataset\\r\\n\\ttrainX, trainY, testX, testY = load_dataset()\\r\\n\\t# prepare pixel data\\r\\n\\ttrainX, testX = prep_pixels(trainX, testX)\\r\\n\\t# load model\\r\\n\\tmodel = load_model('final_model.h5')\\r\\n\\t# evaluate model on test dataset\\r\\n\\t_, acc = model.evaluate(testX, testY, verbose=0)\\r\\n\\tprint('> %.3f' % (acc * 100.0))\\r\\n\\r\\n# entry point, run the test harness\\r\\nrun_test_harness()\\n\\n\\n\\n\\n123456789101112131415161718192021222324252627282930313233343536373839404142\\n\\n# evaluate the deep model on the test datasetfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.models import load_modelfrom tensorflow.keras.utils import to_categorical\\xa0# load train and test datasetdef load_dataset(): # load dataset (trainX, trainY), (testX, testY) = mnist.load_data() # reshape dataset to have a single channel trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1)) # one hot encode target values trainY = to_categorical(trainY) testY = to_categorical(testY) return trainX, trainY, testX, testY\\xa0# scale pixelsdef prep_pixels(train, test): # convert from integers to floats train_norm = train.astype('float32') test_norm = test.astype('float32') # normalize to range 0-1 train_norm = train_norm / 255.0 test_norm = test_norm / 255.0 # return normalized images return train_norm, test_norm\\xa0# run the test harness for evaluating a modeldef run_test_harness(): # load dataset trainX, trainY, testX, testY = load_dataset() # prepare pixel data trainX, testX = prep_pixels(trainX, testX) # load model model = load_model('final_model.h5') # evaluate model on test dataset _, acc = model.evaluate(testX, testY, verbose=0) print('> %.3f' % (acc * 100.0))\\xa0# entry point, run the test harnessrun_test_harness()\\n\\n\\n\\nRunning the example loads the saved model and evaluates the model on the hold out test dataset.\\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\\nThe classification accuracy for the model on the test dataset is calculated and printed. In this case, we can see that the model achieved an accuracy of 99.090%, or just less than 1%, which is not bad at all and reasonably close to the estimated 99.753% with a standard deviation of about half a percent (e.g. 99% of scores).\\n\\n\\n\\n\\n\\n> 99.090\\n\\n\\n\\n\\n1\\n\\n> 99.090\\n\\n\\n\\n\\nMake Prediction\\nWe can use our saved model to make a prediction on new images.\\nThe model assumes that new images are grayscale, that they have been aligned so that one image contains one centered handwritten digit, and that the size of the image is square with the size 28×28 pixels.\\nBelow is an image extracted from the MNIST test dataset. You can save it in your current working directory with the filename ‘sample_image.png‘.\\nSample Handwritten Digit\\n\\nDownload the sample image (sample_image.png)\\n\\nWe will pretend this is an entirely new and unseen image, prepared in the required way, and see how we might use our saved model to predict the integer that the image represents (e.g. we expect “7“).\\nFirst, we can load the image, force it to be in grayscale format, and force the size to be 28×28 pixels. The loaded image can then be resized to have a single channel and represent a single sample in a dataset. The load_image() function implements this and will return the loaded image ready for classification.\\nImportantly, the pixel values are prepared in the same way as the pixel values were prepared for the training dataset when fitting the final model, in this case, normalized.\\n\\n\\n\\n\\n\\n# load and prepare the image\\r\\ndef load_image(filename):\\r\\n\\t# load the image\\r\\n\\timg = load_img(filename, grayscale=True, target_size=(28, 28))\\r\\n\\t# convert to array\\r\\n\\timg = img_to_array(img)\\r\\n\\t# reshape into a single sample with 1 channel\\r\\n\\timg = img.reshape(1, 28, 28, 1)\\r\\n\\t# prepare pixel data\\r\\n\\timg = img.astype('float32')\\r\\n\\timg = img / 255.0\\r\\n\\treturn img\\n\\n\\n\\n\\n123456789101112\\n\\n# load and prepare the imagedef load_image(filename): # load the image img = load_img(filename, grayscale=True, target_size=(28, 28)) # convert to array img = img_to_array(img) # reshape into a single sample with 1 channel img = img.reshape(1, 28, 28, 1) # prepare pixel data img = img.astype('float32') img = img / 255.0 return img\\n\\n\\n\\nNext, we can load the model as in the previous section and call the predict() function to get the predicted score, and then use argmax() to obtain the digit that the image represents.\\n\\n\\n\\n\\n\\n# predict the class\\r\\npredict_value = model.predict(img)\\r\\ndigit = argmax(predict_value)\\n\\n\\n\\n\\n123\\n\\n# predict the classpredict_value = model.predict(img)digit = argmax(predict_value)\\n\\n\\n\\nThe complete example is listed below.\\n\\n\\n\\n\\n\\n# make a prediction for a new image.\\r\\nfrom numpy import argmax\\r\\nfrom keras.preprocessing.image import load_img\\r\\nfrom keras.preprocessing.image import img_to_array\\r\\nfrom keras.models import load_model\\r\\n\\r\\n# load and prepare the image\\r\\ndef load_image(filename):\\r\\n\\t# load the image\\r\\n\\timg = load_img(filename, grayscale=True, target_size=(28, 28))\\r\\n\\t# convert to array\\r\\n\\timg = img_to_array(img)\\r\\n\\t# reshape into a single sample with 1 channel\\r\\n\\timg = img.reshape(1, 28, 28, 1)\\r\\n\\t# prepare pixel data\\r\\n\\timg = img.astype('float32')\\r\\n\\timg = img / 255.0\\r\\n\\treturn img\\r\\n\\r\\n# load an image and predict the class\\r\\ndef run_example():\\r\\n\\t# load the image\\r\\n\\timg = load_image('sample_image.png')\\r\\n\\t# load model\\r\\n\\tmodel = load_model('final_model.h5')\\r\\n\\t# predict the class\\r\\n\\tpredict_value = model.predict(img)\\r\\n\\tdigit = argmax(predict_value)\\r\\n\\tprint(digit)\\r\\n\\r\\n# entry point, run the example\\r\\nrun_example()\\n\\n\\n\\n\\n1234567891011121314151617181920212223242526272829303132\\n\\n# make a prediction for a new image.from numpy import argmaxfrom keras.preprocessing.image import load_imgfrom keras.preprocessing.image import img_to_arrayfrom keras.models import load_model\\xa0# load and prepare the imagedef load_image(filename): # load the image img = load_img(filename, grayscale=True, target_size=(28, 28)) # convert to array img = img_to_array(img) # reshape into a single sample with 1 channel img = img.reshape(1, 28, 28, 1) # prepare pixel data img = img.astype('float32') img = img / 255.0 return img\\xa0# load an image and predict the classdef run_example(): # load the image img = load_image('sample_image.png') # load model model = load_model('final_model.h5') # predict the class predict_value = model.predict(img) digit = argmax(predict_value) print(digit)\\xa0# entry point, run the examplerun_example()\\n\\n\\n\\nRunning the example first loads and prepares the image, loads the model, and then correctly predicts that the loaded image represents the digit ‘7‘.\\n\\n\\n\\n\\n\\n7\\n\\n\\n\\n\\n1\\n\\n7\\n\\n\\n\\n\\nExtensions\\nThis section lists some ideas for extending the tutorial that you may wish to explore.\\n\\nTune Pixel Scaling. Explore how alternate pixel scaling methods impact model performance as compared to the baseline model, including centering and standardization.\\nTune the Learning Rate. Explore how different learning rates impact the model performance as compared to the baseline model, such as 0.001 and 0.0001.\\nTune Model Depth. Explore how adding more layers to the model impact the model performance as compared to the baseline model, such as another block of convolutional and pooling layers or another dense layer in the classifier part of the model.\\n\\nIf you explore any of these extensions, I’d love to know.\\nPost your findings in the comments below.\\nFurther Reading\\nThis section provides more resources on the topic if you are looking to go deeper.\\nAPIs\\n\\nKeras Datasets API\\nKeras Datasets Code\\nsklearn.model_selection.KFold API\\n\\nArticles\\n\\nMNIST database, Wikipedia.\\nClassification datasets results, What is the class of this image?\\n\\nSummary\\nIn this tutorial, you discovered how to develop a convolutional neural network for handwritten digit classification from scratch.\\nSpecifically, you learned:\\n\\nHow to develop a test harness to develop a robust evaluation of a model and establish a baseline of performance for a classification task.\\nHow to explore extensions to a baseline model to improve learning and model capacity.\\nHow to develop a finalized model, evaluate the performance of the final model, and use it to make predictions on new images.\\n\\nDo you have any questions?\\nAsk your questions in the comments below and I will do my best to answer.\\n\\n\\nDevelop Deep Learning Models for Vision Today!\\n\\nDevelop Your Own Vision Models in Minutes\\n...with just a few lines of python code\\nDiscover how in my new Ebook:\\nDeep Learning for Computer Vision\\nIt provides self-study tutorials on topics like:\\nclassification, object detection (yolo and rcnn), face recognition (vggface and facenet), data preparation and much more...\\nFinally Bring Deep Learning to your Vision Projects\\nSkip the Academics. Just Results.\\nSee What's Inside\\n\\n\\n\\n\\nShare  \\n\\nTweet \\n\\n        \\nShare \\n\\nMore On This TopicHow to Develop a GAN for Generating MNIST Handwritten DigitsHandwritten Digit Recognition Using Convolutional…Handwritten Digit Recognition with LeNet5 Model in PyTorchDeep Learning CNN for Fashion-MNIST Clothing ClassificationHow to Develop a Multichannel CNN Model for Text…How to Develop a CNN From Scratch for CIFAR-10 Photo… \\n\\n\\n\\n\\nAbout Jason Brownlee\\nJason Brownlee, PhD is a machine learning specialist who teaches developers how to get results with modern machine learning methods via hands-on tutorials. \\n\\nView all posts by Jason Brownlee → \\n\\n\\n\\n\\n\\n\\n\\n How to Visualize Filters and Feature Maps in Convolutional Neural Networks\\nDeep Learning CNN for Fashion-MNIST Clothing Classification \\n\\n\\n 188 Responses to How to Develop a CNN for MNIST Handwritten Digit Classification\\n\\n\\n\\n\\n\\nSHAHEEN ALHIRMIZY\\nMay 10, 2019 at 4:32 pm\\n#\\n\\n\\n\\nDear Jason Thank You Very Much For your wonderful Tutorial Please can you build for us A model for Edge detection from scratch using real images.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 11, 2019 at 6:05 am\\n#\\n\\n\\n\\nGreat suggestion, thanks.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSHAHEEN ALHIRMIZY\\nMay 10, 2019 at 4:47 pm\\n#\\n\\n\\n\\nI have two questions :\\nfirst suppose I have images sizes equal to 7611 x 7811 how to deal with this big size images in CNN models.\\nsecond question about if our images different sizes not same size.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 11, 2019 at 6:06 am\\n#\\n\\n\\n\\nI recommend reducing the size of your images first, before modeling, e.g. less than 1000 pixels, even less than 500 pixels if you can.\\nI then recommend normalizing images to the same size.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nvinay\\nSeptember 30, 2019 at 11:47 am\\n#\\n\\n\\n\\nto reduce the size of the images, which approach is better. Using machine learning or normal image compression methods.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nSeptember 30, 2019 at 2:26 pm\\n#\\n\\n\\n\\nUse image compression algorithms.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSHAHEEN ALHIRMIZY\\nMay 11, 2019 at 4:13 pm\\n#\\n\\n\\n\\nwhen we reducing the size of images that means losing many fine details from these images\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 12, 2019 at 6:38 am\\n#\\n\\n\\n\\nOften it does.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTaranpreetkaur\\nOctober 12, 2019 at 10:57 pm\\n#\\n\\n\\n\\nHow u make this project please help us … We can’t understand how we make this project … Taranpreetkaur\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 13, 2019 at 8:30 am\\n#\\n\\n\\n\\nWhat problem are you having exactly?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAjoy\\nOctober 20, 2019 at 4:08 am\\n#\\n\\n\\n\\nOriginal error was: No module named _multiarray_umath, keras .imageprocessing\\nImporting the numpy c-extensions failed.\\nAny ideas please\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 20, 2019 at 6:23 am\\n#\\n\\n\\n\\nSorry to hear that.\\nPerhaps try checking that your version of Keras and TensorFlow are up to date?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAjoy\\nOctober 20, 2019 at 7:18 pm\\n#\\n\\n\\n\\nSorry dont worry, I somehow got to resolve it. I think I reinstalled stuff.\\nI have another problem though. How do I add data for learning if in case the data predicted the wrong valiue pelase. I think I need the advise for both how to add as well as how to add the data in the mnist data format. Thanks\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 21, 2019 at 6:17 am\\n#\\n\\n\\n\\nHappy to hear that.\\nPerhaps you can refit your model as you get access to new data?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAjoy\\nOctober 20, 2019 at 7:51 pm\\n#\\n\\n\\n\\nJason you know what, for “17” it returned “7”. Thats actually good, but if you could please tip me as to how can I turn this into “Awesome.” Can I divide the pixel data into 2 dividions based on whitespace or what would be the best way please to recognize “17”. Thanks\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 21, 2019 at 6:17 am\\n#\\n\\n\\n\\nI believe the model supports one character at a time, try splitting multiple characters up into single character input.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJubayed\\nNovember 26, 2019 at 10:13 pm\\n#\\n\\n\\n\\nGreat!! I enjoyed very well.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nNovember 27, 2019 at 6:05 am\\n#\\n\\n\\n\\nThanks!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVictor Johns\\nNovember 27, 2019 at 3:43 am\\n#\\n\\n\\n\\nJason,\\nThanks much for this tutorial. I had a question on the structure of the CNN. In this (and other descriptions of this problem for the MNIST digit data set) a common structure seems to be that the number of CNN filters is 32. Where each filter is a 5×5 of stride 1. However (and I apologize if this is explained somewhere) I cannot seem to find why 32 filters are chosen. i.e. Why not 16 or 64 ( or 14 or 28). Is it possible to explain why this is so. \\nRegards\\nVictor\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nNovember 27, 2019 at 6:13 am\\n#\\n\\n\\n\\nIt is arbitrary.\\nTry different numbers of filters and compare the results.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSamuel\\nDecember 11, 2019 at 8:36 am\\n#\\n\\n\\n\\nJason,\\nThank you for the detailed explanation of this. I wanted to run your code and follow along to see how it worked. When I tried to run the complete example for the baseline cnn model for mnist, I get the following error:\\nKeyError Traceback (most recent call last)\\nin\\n107\\n108 # entry point, run the test harness\\n–> 109 run_test_harness()\\n in run_test_harness()\\n102 scores, histories = evaluate_model(model, trainX, trainY)\\n103 # learning curves\\n–> 104 summarize_diagnostics(histories)\\n105 # summarize estimated performance\\n106 summarize_performance(scores)\\n in summarize_diagnostics(histories)\\n79 pyplot.subplot(212)\\n80 pyplot.title(‘Classification Accuracy’)\\n—> 81 pyplot.plot(histories[i].history[‘acc’], color=’blue’, label=’train’)\\n82 pyplot.plot(histories[i].history[‘val_acc’], color=’orange’, label=’test’)\\n83 pyplot.show()\\nKeyError: ‘acc’\\nAny ideas what it means?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 11, 2019 at 1:41 pm\\n#\\n\\n\\n\\nYes, the API has changed. \\nI have updated the example. \\nThanks for letting me know!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nXenon\\nDecember 12, 2019 at 5:16 am\\n#\\n\\n\\n\\nplease how can i Train a simple convolutional network for number recognition (MNIST). Thanks. that’s what i want to see.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 12, 2019 at 6:33 am\\n#\\n\\n\\n\\nSee the above tutorial for an example.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVivek\\nDecember 23, 2019 at 10:30 pm\\n#\\n\\n\\n\\nI want to create a image exactly same as mnist using mspaint for example and test it using the mnist evaluation model using predict_classes API.\\nIs it possible without using python API.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 24, 2019 at 6:42 am\\n#\\n\\n\\n\\nI don’t see why not.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlexander Soare\\nDecember 27, 2019 at 8:00 am\\n#\\n\\n\\n\\nHi Jason,\\nThanks for the excellent tutorial! I have two questions about K-fold cross-validation. In your “gentle introduction” article you say that the model is discarded each time we switch the hold out set. So here are my questions\\n1) Here it looks like you don’t discard the model between iterations of the k-fold cross validation. Why?\\n2) The model’s accuracy gets better each time you do an iteration. Why is taking a simple average fair then? To take it to the extreme: What if you only trained on 1 epoch? Then you’d get 94% on your first fold, then 98.5% on your second fold. And so on, yielding a much poorer average and a huge standard deviation. On the back of this question, I’d also ask why the standard deviation is a fair representation of the model under these circumstances.\\nThanks again for the great material!\\nAlex\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 28, 2019 at 7:38 am\\n#\\n\\n\\n\\nYou’re welcome.\\nThat looks like an error. I will update the tutorial.\\nThanks for point it out!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlexander Soare\\nDecember 29, 2019 at 5:43 am\\n#\\n\\n\\n\\nThanks for picking up my previous question Jason. I have another. You say at some point that there are no clear signs of overfitting. But it looks like the orange lines for the validation accuracy are staying relatively low compared to the blue lines for the testing accuracy. Is this not an indicator of overfitting? Or am I misinterpreting the charts?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 29, 2019 at 6:09 am\\n#\\n\\n\\n\\nExcellent question Alexander.\\nThey are close enough that I would not classify it as overfitting, instead it is a good fit:\\nhttps://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnja\\nJanuary 3, 2020 at 3:02 pm\\n#\\n\\n\\n\\nHello Jason,\\nWhen I execute the final code I get following error: “AttributeError: module ‘tensorflow’ has no attribute ‘get_default_graph”. I have installed Tensorflow 2.0, will downgrading it to the previous version solve this problem?\\nThank you for your time and this amazing post!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJanuary 4, 2020 at 8:24 am\\n#\\n\\n\\n\\nConfirm you have Keras 2.3 and Tensorflow 2.0 installed.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAnja\\nJanuary 6, 2020 at 12:51 pm\\n#\\n\\n\\n\\nHello Jason,\\nI have Tensorflow 2.0 and Keras 2.2.4. I tried updating Keras to 2.3 but can not find the way on Windows 10. I tried also switching to Linux on VB but I have a hard time with permissions there. Do you have any advice for me, I would be really grateful?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJanuary 6, 2020 at 1:31 pm\\n#\\n\\n\\n\\nYou can try:\\n\\n\\n\\n\\n\\n\\npip install keras\\n\\n\\n\\n\\n1\\n\\npip install keras\\n\\n\\n\\n\\nOr, if you are on anaconda:\\n\\n\\n\\n\\n\\n\\nconda install -c conda-forge keras\\n\\n\\n\\n\\n1\\n\\nconda install -c conda-forge keras\\n\\n\\n\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDmytro\\nFebruary 4, 2020 at 7:44 am\\n#\\n\\n\\n\\nHello Jason,\\nThank you for the tutorial and all the answers!\\nI have my own set of images, each class in a separate folder. What should I do to upload the dataset instead of writing\\n# load dataset\\n(trainX, trainY), (testX, testY) = mnist.load_data()\\nIt would be great if you can give some advice!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 4, 2020 at 8:02 am\\n#\\n\\n\\n\\nHere is an example:\\nhttps://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDmytro\\nFebruary 5, 2020 at 4:00 pm\\n#\\n\\n\\n\\nThank you!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 6, 2020 at 8:18 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSARVANI CH\\nMarch 14, 2020 at 9:11 pm\\n#\\n\\n\\n\\nHi Jason,\\nThanks for the article!!!\\nDo you have any plans to implement “Information bottleneck theory” i.e, finding mainly the mutual information among various layers in an architecture?\\nDoes it seem simpler or a harder one for you??\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 15, 2020 at 6:13 am\\n#\\n\\n\\n\\nI have not heard of it sorry, do you have a link?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSWETHA\\nMarch 20, 2020 at 1:05 pm\\n#\\n\\n\\n\\ndef load_image(filename):\\n# load the image\\nimg = load_img(filename, grayscale=True, target_size=(28, 28))\\n# convert to array\\nimg = img_to_array(img)\\n# reshape into a single sample with 1 channel\\nimg = img.reshape(1, 28, 28, 1)\\n# prepare pixel data\\nimg = img.astype(‘float32’)\\nimg = img / 255.0\\nreturn img\\nwhat does the ‘filename’ mean in the above code?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 20, 2020 at 1:20 pm\\n#\\n\\n\\n\\nIt’s an argument to the function – the name of the file you want to load.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nSWETHA\\nMarch 20, 2020 at 2:17 pm\\n#\\n\\n\\n\\nDid you mean the saved model’s filename?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 21, 2020 at 8:17 am\\n#\\n\\n\\n\\nNo, the function loads an image as it’s name suggests.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSWETHA\\nMarch 20, 2020 at 1:48 pm\\n#\\n\\n\\n\\nThank you!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 21, 2020 at 8:16 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nElbhednam\\nMarch 26, 2020 at 6:52 am\\n#\\n\\n\\n\\nWhat is the purpose of reshaping the data to a single color channel? Is it necessary for the 2D convolution step in the model definition? I ask because other digit classification examples I’ve looked at go straight to flattening the train/test data but those didn’t have a 2D convolution layer.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 26, 2020 at 8:07 am\\n#\\n\\n\\n\\nThe CNN layer expects data to have a 3d shape including a channels dimension:\\nhttps://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEdward\\nApril 13, 2020 at 5:00 am\\n#\\n\\n\\n\\nIf one wanted to create a new MNIST how would they set the data up? In these examples we get to use curated datasets from a dispensary but that does not explain how to set up your data to run the model.\\nFor example what if I wanted to create my own MNIST to determine if the picture is a poker card, how would I go about setting the pictures and telling the machine what that picture is?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 13, 2020 at 6:22 am\\n#\\n\\n\\n\\nGood question, see this:\\nhttps://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmit Baghel\\nApril 15, 2020 at 3:53 pm\\n#\\n\\n\\n\\nhi Jason Brownlee,\\ni want to make model handwriting alphbet so please suggest which dataset is good\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 16, 2020 at 5:57 am\\n#\\n\\n\\n\\nPerhaps this will help:\\nhttps://machinelearningmastery.com/faq/single-faq/where-can-i-get-a-dataset-on-___\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNawal\\nApril 17, 2020 at 6:03 pm\\n#\\n\\n\\n\\nJason, Thank you so much for sharing your knowledge. I just started learning python, tensorflow and machine learning. I understood all the maths and processes but was having difficulty in coding. Your example worked first time. Brilliant.\\nDo you have a simpler example of CNN with just 4 hidden layers as follows:\\n1. Input layer of 784 nodes\\n2. First convolution later : 5x5x32\\n3. First max pooling layer\\n4. Second convolution layer 5x5x64\\n5. Second max pooling layer\\n6. Out put layer of 10 nodes\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 18, 2020 at 5:42 am\\n#\\n\\n\\n\\nThanks.\\nYou can adapt the above example to this directly if you like.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJoyce\\nMay 4, 2020 at 6:03 am\\n#\\n\\n\\n\\nHi Jason. Can I ask why did you reshape the data? The image from the MNIST are already grey scale which are 1 channel. I am not quite understand why you need to do this step. Also what does the trainx.shape[0]/testX.shape[0] do here?\\n# reshape dataset to have a single channel\\ntrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\\ntestX = testX.reshape((testX.shape[0], 28, 28, 1))\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 4, 2020 at 6:28 am\\n#\\n\\n\\n\\nInputs to CNNs must have the channel defined explicitly, which is not the case by default for grayscale images.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmy\\nMay 4, 2020 at 6:30 am\\n#\\n\\n\\n\\nCan I ask why the hot encode is 10 binary vectors? Why choose 10?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 4, 2020 at 6:33 am\\n#\\n\\n\\n\\nBecause there are 10 classes.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRuslaniv\\nMay 7, 2020 at 9:20 pm\\n#\\n\\n\\n\\nHi Jason! Thank you so much, this is a great tutorial!\\nJust one question, i’m somewhat confused.\\nAre training our model twice? Once with k-fold validation and then right before saving it, with model.fit?\\n====\\nmodel = define_model()\\nmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\\nmodel.save(‘final_model.h5’)\\n====\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 8, 2020 at 6:31 am\\n#\\n\\n\\n\\nCross-validation will train k models and is used to estimate the performance when making predictions on new data. These models are discarded.\\nOnce we choose a final model config, we fit a model on all data and use it to start making predictions.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nRuslaniv\\nMay 11, 2020 at 8:20 pm\\n#\\n\\n\\n\\nGreat, that’s what I thought! Thank you again for this amazing tutorial.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 12, 2020 at 6:43 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThenerd\\nFebruary 5, 2021 at 3:05 am\\n#\\n\\n\\n\\nIn the k fold cross validation a new model is defined for each k iteration. So does that mean a new model is trained each time? But then what is the use of training new models in each iteration? \\nBy model config you mean an optimal define_model? And once an optimal model is fixed we train on the entire training set? I am not able to relate how will K iterations in the K-fold reflect our understanding of what model configuration is the best.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 5, 2021 at 5:46 am\\n#\\n\\n\\n\\nYes, a new model is trained each iteration, evaluated, and discarded.\\nThe purpose is to estimate the performance of the model configuration when making predictions on unseen data for your prediction problem.\\nOnce we have this estimate, we can choose to use the configuration (compared to other configurations). A final model can be fit on all data and we can start making predictions for real on new data where we don’t know the label.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nThenerd\\nFebruary 10, 2021 at 7:21 am\\n#\\n\\n\\n\\nThankyou very much. I had another question. I was trying to run the final model on the unseen test data. however for each run the results vary ofcourse. therefore i decided to run this over 10 runs and average the test results, something like monte carlo simulation. but again in that case where would model = define_model() be places? would that be placed inside the for loop for average or just be defined once before running these 10 iterations, considering this average results is on the test data. since in kfold you discard it.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 10, 2021 at 8:13 am\\n#\\n\\n\\n\\nYou’re welcome.\\nYes, you can reduce variance in prediction by fitting multiple final models and averaging their predictions:\\nhttps://machinelearningmastery.com/how-to-reduce-model-variance/\\nThis has a code example:\\nhttps://machinelearningmastery.com/model-averaging-ensemble-for-deep-learning-neural-networks/\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGohel vivek\\nMay 11, 2020 at 6:02 pm\\n#\\n\\n\\n\\nIf i am writing this all by making a class name -mnist_classification then \\nAttributeError: ‘mnist_classification’ object has no attribute ‘astype’\\nthis .astype error is coming please sir can you help me to figure this out\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMay 12, 2020 at 6:40 am\\n#\\n\\n\\n\\nSorry to hear that, this will help:\\nhttps://machinelearningmastery.com/faq/single-faq/why-does-the-code-in-the-tutorial-not-work-for-me\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRamya\\nJune 2, 2020 at 7:01 am\\n#\\n\\n\\n\\nHi Jason,\\nThanks for this tutorial. It’s very helpful.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 2, 2020 at 7:55 am\\n#\\n\\n\\n\\nYou’re welcome, I’m happy to hear that.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMilind Naidu\\nJune 21, 2020 at 11:28 pm\\n#\\n\\n\\n\\nHi, i am trying to build a CNN fo the same problem. My output layer has 10 neurons. When i try to fit my model after One-Hot_encoding of y_train and y_test, i get an error that the labels and the logits don’t match. However, without the one-hot encoding the model fits perfectly. Can you please explain?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 22, 2020 at 6:14 am\\n#\\n\\n\\n\\nPerhaps you can use the above tutorial as a starting point and adapt it for your project?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWilliam\\nJuly 19, 2020 at 8:48 pm\\n#\\n\\n\\n\\nThis is the best article about MNIST, but I have a question “Is it necessary to use a GPU with high performance in order to running these codes?”\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJuly 20, 2020 at 6:12 am\\n#\\n\\n\\n\\nThanks!\\nNo, you can run on CPU, it might just take more minutes to run.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSandhya\\nJuly 31, 2020 at 3:58 pm\\n#\\n\\n\\n\\nHi Jason\\nThanks for this amazing tutorial. It will definitely help a lot of budding researchers.\\nI have a question\\nCan you please help if instead of single character i have to work on complete self taken handwritten word image (20 different classes,total around 20000 images). How to do it?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nAugust 1, 2020 at 6:07 am\\n#\\n\\n\\n\\nPerhaps the letters in each word images can first be segmented, then classified.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nSandhya\\nAugust 1, 2020 at 5:39 pm\\n#\\n\\n\\n\\nthanks for the reply but i want to do it using segmentation free approach\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nAugust 2, 2020 at 5:39 am\\n#\\n\\n\\n\\nPerhaps use a CNN to read the images and an LSTM to interpret the image features and output one letter at a time.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nPrasad Bapardekar\\nMarch 16, 2023 at 3:07 am\\n#\\n\\n\\n\\nPerhaps use a CNN to read the images and an LSTM to interpret the image features and output one letter at a time.\\nCan you please share more detail how to do it.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMarch 16, 2023 at 7:08 am\\n#\\n\\n\\n\\nHi Prasad…You may want to consider a CNN-LSTM model for your purpose:\\nhttps://machinelearningmastery.com/cnn-long-short-term-memory-networks/\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSandhya\\nJuly 31, 2020 at 4:14 pm\\n#\\n\\n\\n\\nhi Jason\\nThanks for this amazing tutorial.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nAugust 1, 2020 at 6:07 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nzulfiqar ali\\nOctober 18, 2020 at 9:46 am\\n#\\n\\n\\n\\nThanks, Jason Brownlee for this excellent tutorial. I am your huge fan and I regularly following your all machine learning and deep earning models.I got a lot of knowledge from this site but After completion of machine learning tutorials there always raise a question in my mind that how can we apply these models in Mobile APPs(Andriod, iOS, etc) so that we get more fun and knowledge by this models. Are you suggest to me any link to have such kind of projects such as weather prediction app . Thanks again.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 18, 2020 at 1:25 pm\\n#\\n\\n\\n\\nThanks.\\nSorry, I don’t know about using models on mobile.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nNovember 28, 2021 at 5:17 pm\\n#\\n\\n\\n\\nI know this is a year late, but see this for a mobile app based on tensorflow and keras: https://medium.com/@timanglade/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nZunaira Shafqat\\nOctober 23, 2020 at 4:49 am\\n#\\n\\n\\n\\nThanks for the tutorial Jason Brownlee.\\nCan I use same model but pass my own dataset (of humans) to it & use it for detecting fall or not fall by making small changes?\\nThanks.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nOctober 23, 2020 at 6:17 am\\n#\\n\\n\\n\\nSure.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPreethi\\nNovember 12, 2020 at 3:28 pm\\n#\\n\\n\\n\\nHi do you have any projects done based on Wireless and Mobile Network except human activity recognition using smart phone\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nNovember 13, 2020 at 6:32 am\\n#\\n\\n\\n\\nI don’t think so. Perhaps try the blog search.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArchna\\nNovember 13, 2020 at 7:01 pm\\n#\\n\\n\\n\\nThanks for the detailed explanation !!\\nCan you pls do a tutorial on colorization without using pretratined model\\nThanks in advance\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nNovember 14, 2020 at 6:30 am\\n#\\n\\n\\n\\nGreat suggestion, thanks!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nArchna\\nNovember 24, 2020 at 6:31 pm\\n#\\n\\n\\n\\nWaiting for the same 🙂\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEbdulmomen\\nDecember 7, 2020 at 8:53 am\\n#\\n\\n\\n\\nhey jason that was a very good tutorial, i did not understand how in the predict_classes we got 7? the model had a softmax activation function as the last layer which will be a probability distribution of 10 float numbers, what i can’t grasp is how did we get back 7?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nEbdulmomen\\nDecember 7, 2020 at 8:57 am\\n#\\n\\n\\n\\nwhat i mean is how this 10 probabilities turned into 1 predicted number?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nEbdulmomen\\nDecember 7, 2020 at 9:09 am\\n#\\n\\n\\n\\nand how does it know it is 7, didn’t we hot encode the Y values?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 7, 2020 at 1:35 pm\\n#\\n\\n\\n\\nVia argmax:\\nhttps://machinelearningmastery.com/argmax-in-machine-learning/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 7, 2020 at 1:35 pm\\n#\\n\\n\\n\\nThanks.\\nThe predict_classes() performs an argmax on the predicted probabilities for you.\\nIf you are new to argmax, see this:\\nhttps://machinelearningmastery.com/argmax-in-machine-learning/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nEbdulmomen\\nDecember 7, 2020 at 6:41 pm\\n#\\n\\n\\n\\nthank you jason, everything is clear, really appreciate it!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 8, 2020 at 7:40 am\\n#\\n\\n\\n\\nI’m happy to hear that.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNaveen\\nDecember 13, 2020 at 2:43 am\\n#\\n\\n\\n\\nHey is this code not compatible for Tensorflow 2? I am getting the following error.\\nE tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 13, 2020 at 6:06 am\\n#\\n\\n\\n\\nYes, you can learn more here:\\nhttps://machinelearningmastery.com/faq/single-faq/do-you-support-tensorflow-2\\nThat error looks like a problem with your development environment.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYash\\nDecember 23, 2020 at 9:40 am\\n#\\n\\n\\n\\nHello!\\nThanks for the wonderful article helped me a lot with my project!\\nI have a question though, I am trying to take an image from my phone and then use that image to predict the number but it doesn’t work with that. What should I do to that image?\\nI resized it to 28×28 using online tools and even tried the grayscale version of the image to predict.\\nAny suggestion or lead will be appreciated!\\nThanks in advance!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 23, 2020 at 1:27 pm\\n#\\n\\n\\n\\nYou will have to prepare the image in an identical manner to the images in the training set. e.g. white foreground, black background, grayscale and same image size.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJG\\nDecember 31, 2020 at 7:53 am\\n#\\n\\n\\n\\nHi Jason,\\nGreat tutorial as always!\\nI implemented your tutorial with two variants. \\nI load the images from digits dataset of sklearn library (it uses less images number only 1,797 and with much lower resolution 8 x 8 bits vs MNIST 70,000 and 28,28 pixels resolution. On the contrary it is much faster this dataset because it use less data features.\\nAnd also I apply for this multi-class problem other library classifier models from Sklearn such as SVC(), logisticRegression(), ExtraTreesClassifier(), XGBClassifier(), RandomForestClassifier(), etc.\\nMy main results are:\\n– I got 98.4% accuracy and 1.1 of sigma for the simple CNN baseline model (not other deep layers, not other BatchNormalization()) and I got 98.8% from SVC…but only suing the 8×8 pixels resolution which is a great new!.\\nBut when I reduce the final image to be predicted to 8 x 8 pixels, in order to apply my trained model, whereI got such a great score I poorly predict the 7 digit as 9 digit.\\nMy guess is when I load_image of 7 and I clip it to such smaller size of 8×8 pixels, I lost important images features in the process of cutting back the image….where the the MNIST 28×28 pixels still retain key digit features of the image, what do you think?\\nthank you Jason\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nDecember 31, 2020 at 9:26 am\\n#\\n\\n\\n\\nThanks.\\nVery nice experiments!\\nYes, the larger images perhaps provide more context on challenging cases in the dataset.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHannes\\nJanuary 26, 2021 at 1:15 am\\n#\\n\\n\\n\\nHi Jason,\\nYou have always very interesting articles.\\nI was able to train a CNN based on the Char74K-dataset. I’m happy of that because the model-file is only 42MB and the time to predict a number is fast.\\nI did use a kNN-model before (on the same dataset) that had a file size of 680MB!\\nThanks,\\nHannes\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJanuary 26, 2021 at 5:58 am\\n#\\n\\n\\n\\nThanks.\\nWell done!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMukesh\\nFebruary 5, 2021 at 8:42 pm\\n#\\n\\n\\n\\nHi Jason,\\nGreat article!!\\ni just have one doubt, in the evaluate method why are we creating a new model for every fold?\\nThanks,\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 6, 2021 at 5:49 am\\n#\\n\\n\\n\\nThis is how k-fold cross-validation works, we have a new training set and fit a new model for each fold, then average the performance of all models to get an estimate of model performance when used on unseen data.\\nYou can learn more here:\\nhttps://machinelearningmastery.com/k-fold-cross-validation/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDmitry\\nFebruary 6, 2021 at 6:20 pm\\n#\\n\\n\\n\\nThanks for this amazing tutorial!\\nI have some experience in MLP but not with CNN. Is there a reason try to use CNN if each sample of my data have shape 16×1 (row) with values between 0,01 to 0,99 and the model shoud perform classification for 15 classes. If I reshape samples from 16×1 to 4×4 then which filter size and a modest number of filters shoud I use? Or better dont reshape and try model with Conv1D layers? Thanks.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 7, 2021 at 5:17 am\\n#\\n\\n\\n\\nCNN can be effective if there is a spatial relationship between the inputs in an image or a sequence.\\nIf you have tabular data (e.g. not a images and not sequences), then a CNN does not make sense.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAhmed Shafeek\\nFebruary 18, 2021 at 2:19 pm\\n#\\n\\n\\n\\nHi Jason,\\nThank you very much for your amazing tutorial. I am running your code using pycharm and I have a GPU with the right CUDA but your code is only running on my CPU.\\nIs there something that I am missing here?\\nthank you. 🙂\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAhmed Shafeek\\nFebruary 18, 2021 at 4:52 pm\\n#\\n\\n\\n\\nSorry Jason, it turned out I had a problem in the CuDNN installation and i did a work around to fix it and it worked. 🙂\\nThanks again for this great tutorial. 🙂\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 19, 2021 at 5:55 am\\n#\\n\\n\\n\\nNo problem! \\nHappy to hear you fixed the issue.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 19, 2021 at 5:54 am\\n#\\n\\n\\n\\nThe code is agnostic to hardware – runs on both.\\nIf it is running on your CPU, then you need to change the configuration of your tensorflow library. I don’t have tutorials on this topic, sorry.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nKarl\\nFebruary 24, 2021 at 1:20 am\\n#\\n\\n\\n\\nHi Jason, \\nThank you very much for this tutorial, helped a lot! I developed my own CNN, which seems to perform pretty well according to the mean accuracy. However, the cross-entropy loss of the validation set is below the loss of the training set. Is this a sign of underfitting? And if so, should I change the model if I would like to apply the model to unseen data?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 24, 2021 at 5:34 am\\n#\\n\\n\\n\\nYou’re welcome.\\nWell done!\\nIf performance is poor, a learning curve can help diagnose issues, this can help you interpret the learning curve:\\nhttps://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNoah\\nFebruary 24, 2021 at 1:51 am\\n#\\n\\n\\n\\nHi Jason,\\nThank you very much for this tutorial, helped a lot! I developed my own CNN, which seems to perform pretty well according to the mean accuracy. However, the cross-entropy loss of the validation set is below the loss of the training set. Is this a sign of underfitting? And if so, should I change the model if I would like to apply the model to unseen data?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nFebruary 24, 2021 at 5:35 am\\n#\\n\\n\\n\\nYou’re welcome.\\nPerhaps focus on the out of sample performance of the model first and optimize that.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGeo\\nMarch 2, 2021 at 12:20 am\\n#\\n\\n\\n\\nHi Jason,\\nPreviously I was grateful for the tutorial you provided, I learned a lot from here. What if I want to display the probability value of the prediction result? (for example 50.67% something like that)\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 2, 2021 at 5:45 am\\n#\\n\\n\\n\\nThanks!\\nYou can call model.predict() then multiply the result by 100 to get a percentage.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWilliam\\nMarch 2, 2021 at 3:01 pm\\n#\\n\\n\\n\\nThank you for the tutorial!\\nI created an image with same characteristics as sample_image.png (1490×1480, black background, white foreground), opened it in Paint, typed a “6” (without the quotes, of course), increased the font size to 1000 (so it would occupy most of the canvas), then saved it. However, the code doesn’t seem to recognize it. It seems to think it’s a “1”, “8”, or other numbers.\\nAny suggestions on why?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nMarch 3, 2021 at 5:25 am\\n#\\n\\n\\n\\nPerhaps there was some important difference in the image itself or it’s preparation (e.g. pixel scaling) that differed from the training dataset?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVenkat\\nApril 1, 2021 at 10:07 pm\\n#\\n\\n\\n\\nHi Jason – fantastic article!! Just wondering why you had to do evaluate to get the accuracy, while it is already being returned by the fit call? I just checked the histories and they have exactly the same stuff returned by the evaluate call. Was there any other reason for the evaluate call?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 2, 2021 at 5:39 am\\n#\\n\\n\\n\\nThanks!\\nNo, accuracy on a hold out dataset is not calculated when calling fit. We must make predictions on new data manually or use the evaluate function.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nVenkat\\nApril 15, 2021 at 4:17 am\\n#\\n\\n\\n\\nThanks for the reply!! I was seeing the same data is passed (testX, testY) for both fit and evaluate calls for validation. As a result, the return object from fit call already has the data to be returned by the evaluate call. Am I making sense?\\n# fit model\\nhistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\\n# evaluate model\\n_, acc = model.evaluate(testX, testY, verbose=0)\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 15, 2021 at 5:30 am\\n#\\n\\n\\n\\nGenerally it is not a good idea to use test data as validation, I do to keep the examples simple.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBerke\\nApril 4, 2021 at 9:47 pm\\n#\\n\\n\\n\\nHi Jason, thanks for this great tutorial!\\nI don’t get why we don’t use the models that we created during the k-fold. I was expecting something like we combine this k models results into one single model and save it. If we don’t do that how’s that useful?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 5, 2021 at 6:11 am\\n#\\n\\n\\n\\nModels created during k-fold cross-validation are discarded. They are only used to estimate the performance of the model/pipeline on unseen examples.\\nOnce we choose a configuration, we can fit a final model on all data and use it to make predictions on new examples:\\nhttps://machinelearningmastery.com/train-final-machine-learning-model/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVishwa\\nApril 15, 2021 at 9:38 pm\\n#\\n\\n\\n\\nThanks a lot Jason !!! This tutorial was very very helpful and it solved half of my project problems !!! Thanks a lot again !..\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nApril 16, 2021 at 5:30 am\\n#\\n\\n\\n\\nYou’re welcome.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nismail\\nJune 9, 2021 at 8:47 am\\n#\\n\\n\\n\\nThank you for the great tutorial. Is it possible to use it with a webcam for recognition task?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 10, 2021 at 5:20 am\\n#\\n\\n\\n\\nPerhaps try it and see.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTaylor Rayne\\nJune 12, 2021 at 12:20 pm\\n#\\n\\n\\n\\nHello! Thank you Jason for this amazing resource. I am currently working on a rented computer from school – do you think I could do implement this code in CoLabs?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 13, 2021 at 5:46 am\\n#\\n\\n\\n\\nYou’re welcome.\\nGood question, see this:\\nhttps://machinelearningmastery.com/faq/single-faq/do-code-examples-run-on-google-colab\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nManal\\nJune 15, 2021 at 4:14 pm\\n#\\n\\n\\n\\nHi Jason,\\nThank you very much\\nIf possible, advise on the implementation HMM.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 16, 2021 at 6:17 am\\n#\\n\\n\\n\\nThanks for the suggestion, perhaps in the future.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\namberbir\\nJune 15, 2021 at 11:11 pm\\n#\\n\\n\\n\\ni am developing a model of handwritten character recognition but the accuracy is very low i think it is not only because i have a small datatset, there is something i am not understanding can u help me on the improvement\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJune 16, 2021 at 6:21 am\\n#\\n\\n\\n\\nPerhaps try some of these suggestions:\\nhttps://machinelearningmastery.com/improve-deep-learning-performance/\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShri\\nJuly 8, 2021 at 11:15 pm\\n#\\n\\n\\n\\nCan I use this code for any character dataset ?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nJuly 9, 2021 at 5:11 am\\n#\\n\\n\\n\\nPerhaps try it and see.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShireesh Apte\\nAugust 8, 2021 at 8:34 am\\n#\\n\\n\\n\\nCould you provide a peer review for a manuscript that has been submitted to the Journal of High School Science (http://jhss.scholasticahq.com) ? The title of the manuscript is : Implementing a Quantum Convolutional Neural Network for Efficient Image Recognition. Abstract: Machine learning has many real-world applications ranging from modeling the universe to computational chemistry. As probability is the bedrock for machine learning, it is essential to optimize both hardware and software to obtain the best results. Classical computers are generally used for machine learning programs. However, learning from high-dimensional data often demands excessive compute time and power, and it may not achieve the highest accuracy. The Quantum Computing environment can be utilized to create a more accurate model than that created via classical computing. To test this quantum advantage, we implemented a Quantum Convolutional Neural Network (QCNN), which parallels the structure of the classical Convolution Neural Network (CNN) in the quantum domain. Due to the lack of quantum computers with many qubits, physicists, namely John Preskill, have introduced the Noisy Intermediate Scale Quantum (NISQ) concept, which constitutes a hybrid interface between classical and quantum computers. In the context of QCNN, the data processing and the cost function optimization would be performed on the classical computer, while the probabilities generated by the Variational Quantum Circuits (VQC) would be evaluated on the quantum computer. The QCNN consists of a classical-to-quantum data encoder, a cluster state quantum circuit to entangle qubit states, a series of Variational Quantum Circuits using Quantum Convolutional and Pooling Layers for efficient feature extraction, a quantum-to-classical data decoder, which would lead to the output. Both the CNN and the QCNN extract features from data like 2D images, and performances can be compared using metrics like accuracy and time.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJason Brownlee\\nAugust 9, 2021 at 5:52 am\\n#\\n\\n\\n\\nSorry I cannot peer review your manuscript.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnbe\\nSeptember 11, 2021 at 6:48 pm\\n#\\n\\n\\n\\nwhat if we are asked to design a project to identify digit classification from MNIST using classification algorithm should we use the above oen\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nSeptember 14, 2021 at 1:08 pm\\n#\\n\\n\\n\\nYes\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbhi\\nNovember 12, 2021 at 11:26 pm\\n#\\n\\n\\n\\nWonderful tutorial!!\\nWhen i implemented the code i got this error ” AttributeError: ‘Sequential’ object has no attribute ‘predict_classes’ ”\\nAny suggestions to rectify this error please?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nNovember 14, 2021 at 2:27 pm\\n#\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nfrom numpy import argmax\\n\\npred_value = model.predict(img)\\ndigit = argmax(pred_value)\\n\\n\\n\\n\\n1234\\n\\nfrom numpy import argmax\\xa0pred_value = model.predict(img)digit = argmax(pred_value)\\n\\n\\n\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnnya Karn\\nNovember 17, 2021 at 12:06 am\\n#\\n\\n\\n\\nI used this model as an example and when I fed it a handwritten number, it continuously gave wrong predictions. Can you please tell me what could possibly be the problem?\\nIt reads accurately when I used printed numbers with black background.\\nI did however change the cnn model a little bit to make it Multiple Pooling model.\\nI can share the code as well, if you like.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nNovember 17, 2021 at 6:55 am\\n#\\n\\n\\n\\nCan’t tell because I didn’t see your handwriting. But this MNIST dataset is a 28×28 pixel grayscale with white on black. Try to mimick this set up and it should be much better. If your image is more complex (e.g., you scan it, then the background is not a single color, or the alphabet is more complicated with more strokes than digits) then you will need a larger network to recognize it.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLouca\\nNovember 23, 2021 at 12:01 pm\\n#\\n\\n\\n\\nYou mention in other answers that the inputs have to be reshaped because the convolutional layers expect an input with a dimension for channels. Do you know if this is unique to keras?\\nI am trying to classify 56×56 grayscale images (0->255), and so far I have normalized them to [-1,1]. However, they are still 2D as a 56×56 matrix. I am using pytorch. Do you know if I would also need to reshape them to add the single channel?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nNovember 23, 2021 at 1:40 pm\\n#\\n\\n\\n\\nDepends on the way you construct the model, it may or may not necessary.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nNovember 29, 2021 at 5:29 am\\n#\\n\\n\\n\\nWhy are there two copies of the 64-filter conv2D in the “Increase Model Depth” section:\\nmodel.add(Conv2D(64, (3, 3), activation=’relu’, kernel_initializer=’he_uniform’))\\nI tried this model with both one and two of these layers and got the same results.\\nAs a side note, I did increase the number of epochs to 15 and saw a slight improvement to both the accuracy mean and std deviation.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nNovember 29, 2021 at 8:56 am\\n#\\n\\n\\n\\nIf you see no difference for more layers, try to stay with the fewer layers one because it save time and memory.\\nIncreasing epochs can help train better, but you may also run into overfitting. So you need to check with validation set to confirm about the “improvement”.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nNovember 30, 2021 at 5:47 am\\n#\\n\\n\\n\\nI tried up to 25 epochs and looked at the loss with verbose=1 in the model.fit call. The loss bottoms out at around 20 epochs and then bounces around after that.\\nHere’s one run from epoch 10 through 25. The model got 99.260% on the test set:\\nEpoch 10/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0079 – accuracy: 0.9972\\nEpoch 11/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0061 – accuracy: 0.9980\\nEpoch 12/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0060 – accuracy: 0.9980\\nEpoch 13/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0058 – accuracy: 0.9978\\nEpoch 14/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0045 – accuracy: 0.9984\\nEpoch 15/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0042 – accuracy: 0.9987\\nEpoch 16/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0035 – accuracy: 0.9988\\nEpoch 17/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0031 – accuracy: 0.9991\\nEpoch 18/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0024 – accuracy: 0.9992\\nEpoch 19/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0026 – accuracy: 0.9993\\nEpoch 20/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0020 – accuracy: 0.9994\\nEpoch 21/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0020 – accuracy: 0.9994\\nEpoch 22/25\\n1875/1875 [==============================] – 7s 3ms/step – loss: 0.0027 – accuracy: 0.9991\\nEpoch 23/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0032 – accuracy: 0.9989\\nEpoch 24/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0022 – accuracy: 0.9993\\nEpoch 25/25\\n1875/1875 [==============================] – 6s 3ms/step – loss: 0.0020 – accuracy: 0.9993\\n> 99.260\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nDecember 2, 2021 at 1:59 am\\n#\\n\\n\\n\\nNot bad a result here!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nDecember 2, 2021 at 3:11 am\\n#\\n\\n\\n\\nThese guys: https://arxiv.org/pdf/2008.10400v2.pdf are getting 99.91% accuracy using a combination of fairly simple techniques: deeper model depth, increased convolution kernel size, data augmentation, batch normalization between all conv2D layers, disabling edge padding in the convolution output to reduce the map sizes between conv2D layers instead of max pooling (which I found quite elegant), and voting between multiple models. They do a good job of analyzing each technique and comparing the results to other common CNNs.\\nThey’re currently at the top of the rankings here: https://paperswithcode.com/sota/image-classification-on-mnist\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nDecember 2, 2021 at 3:34 am\\n#\\n\\n\\n\\nThanks for sharing.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPatrick Wood\\nDecember 4, 2021 at 4:05 am\\n#\\n\\n\\n\\nSo during training, the model accuracy against the training data goes over 99.9%, but the final accuracy on the test data is 99.26%. Are these results close enough that I can assume the model isn’t over trained? What’s a reasonable difference when both values are over 99%?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nAdrian Tam\\nDecember 8, 2021 at 7:17 am\\n#\\n\\n\\n\\nCan’t give you any general guidance on what is reasonable or not. But at >99% accuracy, I would assume it is good enough for this purpose.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nDecember 22, 2021 at 9:24 am\\n#\\n\\n\\n\\nHi Patrick…The following resource will provide you insight into how to avoid overfitting in deep neural networks.\\nhttps://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/\\nRegards,\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAndrew Odion\\nJanuary 1, 2022 at 11:52 pm\\n#\\n\\n\\n\\nThank you\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nJanuary 2, 2022 at 8:56 am\\n#\\n\\n\\n\\nYou are very welcome Andrew!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nJanuary 3, 2022 at 8:42 am\\n#\\n\\n\\n\\nYou are very welcome, Andrew!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGilad\\nJanuary 8, 2022 at 5:08 am\\n#\\n\\n\\n\\nHi,\\nI don’t know if you will ever see it but if you reply I will thank you, I wanted to try by myself this code because I was hoping to learn more about neural networks.\\nUnfortunately, I gave Python a picture I made in paint (the computer application) this image was resized to 28*28 and the picture is seen, I checked it.\\nIn the picture, I drew the number 2, and it said that it is four and I tried more unsuccessfully.\\nI’d like to know where is the problem.\\nAnyway if you can reply to me in E-mail I will thank you in order to check wether the problem is in the picture or the code.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nJanuary 8, 2022 at 10:58 am\\n#\\n\\n\\n\\nHi Gilad…Have you checked the overall accuracy of your model?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nGilad\\nJanuary 9, 2022 at 10:13 pm\\n#\\n\\n\\n\\nYes, the accuracy was 96 percent, this is the reason I find it awkward.\\nI am not sure whether the problem is in the picture but I’d like to know where is the problem.\\nCan I send you the picture that I used? maybe the problem is located there.\\nAnyway, thanks for the help.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nGilad\\nJanuary 9, 2022 at 10:29 pm\\n#\\n\\n\\n\\n99.140 is my right accuracy, sorry for the earlier mistake.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nGilad\\nJanuary 10, 2022 at 2:34 am\\n#\\n\\n\\n\\nJames thanks a lot it finally worked, my picture was not good.\\nI drew the digits in black and the background was white, and this is not the way the computer was trained.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nJanuary 10, 2022 at 11:12 am\\n#\\n\\n\\n\\nThank you for the feedback Gilad! Keep up the great work!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnbu\\nMarch 29, 2022 at 5:22 pm\\n#\\n\\n\\n\\nThis, according to me, is the best tutorial I have ever gone through. It helped me understand CNN in my very first attempt. Thank you, Dear James.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMarch 30, 2022 at 3:45 am\\n#\\n\\n\\n\\nThank you for the feedback and support Anbu!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nViswa\\nMay 1, 2022 at 2:16 am\\n#\\n\\n\\n\\nhello james,\\nGreat tutorial. I’ getting “name ‘train’ is not defined” as error while converting from integers to floats. can you please help me with that? Thank you.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMay 2, 2022 at 9:26 am\\n#\\n\\n\\n\\nHi Viswa…Thank you for the feedback! Did you copy and paste the code or type it in? There could be an issue related to copying and pasting the code.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nViswa\\nMay 3, 2022 at 1:06 pm\\n#\\n\\n\\n\\nOh! I got it. Thank you so much for tutorial, I’ve learned a lot from you.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nViswa\\nMay 4, 2022 at 6:25 am\\n#\\n\\n\\n\\nCan you please elaborate on why a dense layer with specifically 100 nodes is used to develop a baseline model?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nCarde\\nMay 9, 2022 at 6:47 pm\\n#\\n\\n\\n\\ntrain_norm = train.astype(‘float32’)\\nHi Jason, from which library this method come from?\\nCause train is not defined in your code and I want to see how the method works.\\ntrain_norm = train.astype(‘float32’)\\nNameError: name ‘train’ is not defined\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMay 10, 2022 at 12:13 pm\\n#\\n\\n\\n\\nHi Carde…Please see the complete code listing near the end of the tutorial.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuhas\\nMay 12, 2022 at 6:59 am\\n#\\n\\n\\n\\nIs it okay to add dropout() to the digit classification model, because I got the best accuracy when I use the dropout.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMay 13, 2022 at 12:56 am\\n#\\n\\n\\n\\nHi Suhas…Yes, that approach is a reasonable one and it is great to know you were able to improve your model accuracy! Dropout is definitely beneficial to avoid overtraining.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nabdool\\nOctober 28, 2022 at 4:57 am\\n#\\n\\n\\n\\nwhere is the final code and the code testing result\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nOctober 28, 2022 at 8:27 am\\n#\\n\\n\\n\\nHi abdool…The final code listing is provided in this post. Is it not visible?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAshbrocolli\\nNovember 18, 2022 at 4:15 am\\n#\\n\\n\\n\\nhi, for the improved depth, how many hidden layers are involved?\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nNovember 18, 2022 at 6:10 am\\n#\\n\\n\\n\\nHi Ashbrocolli…The layers can be found in the in section following the comment below:\\n“The complete code listing with this change is provided below.”\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRabiaa CHARIJ\\nNovember 30, 2022 at 8:03 pm\\n#\\n\\n\\n\\nHello @James Carmichael, I wonder how the “to_categorical” works , I have seen documentation and it says if number of classes is not specified then this would be inferred as max(y) + 1 if y is a vector. So to my surprise ,I know that in the Mnist dataset the num classes is 10 but without specifiying this number as a parameter , the function returns a vector of shape (60 000,10) but how ? I would really like to know how this max(y)+1 would work on images and give the right num_classes that is 10.\\nThanks in advance for your answer.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nRabiaa CHARIJ\\nNovember 30, 2022 at 8:29 pm\\n#\\n\\n\\n\\nSorry I figured it out, As “y” is a vector of labels from 0 to 9 so max(y)+1 would return 10 (num_classses), which is obvious actually. I was Confused because I had an issue while printing “y” it didn’t show the expected values.\\nThanks!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nDecember 1, 2022 at 8:14 am\\n#\\n\\n\\n\\nThank you for the update Rabiaa! Great work!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCraneFrog\\nMarch 1, 2024 at 9:19 am\\n#\\n\\n\\n\\nOutdated tutorial. Would not recommend to beginners who are starting out. Over complicating things in modern age. Maybe at the time (5yrs ago!!!) this was fine but things can be done way more simpler and cleaner.\\n\\nReply \\n\\n\\n\\n\\n\\n\\n\\nJames Carmichael\\nMarch 2, 2024 at 1:09 pm\\n#\\n\\n\\n\\nThank you for your feedback!\\n\\nReply \\n\\n\\n\\n\\n\\n\\n \\nLeave a Reply Click here to cancel reply.Comment * Name (required) \\nEmail (will not be published) (required) \\n \\n\\nΔ \\n\\n\\n\\nWelcome!\\nI'm Jason Brownlee PhD \\nand I help developers get results with machine learning.\\nRead more\\n\\nNever miss a tutorial:\\n\\n\\n\\n\\xa0\\xa0\\xa0\\n\\n\\xa0\\xa0\\xa0\\n\\n\\xa0\\xa0\\xa0\\n\\n\\xa0\\xa0\\xa0\\n\\n\\nPicked for you:\\n\\n How to Train an Object Detection Model with Keras How to Develop a Face Recognition System Using FaceNet in Keras How to Classify Photos of Dogs and Cats (with 97% accuracy) How to Perform Object Detection With YOLOv3 in Keras How to Get Started With Deep Learning for Computer Vision (7-Day Mini-Course)\\nLoving the Tutorials?\\nThe Deep Learning for Computer Vision EBook is where you'll find the Really Good stuff.\\n\\n>> See What's Inside\\n\\n\\n\\n\\n\\n\\n© 2024 Guiding Tech Media. All Rights Reserved.\\nLinkedIn |\\nTwitter |\\nFacebook |\\nNewsletter |\\nRSS |\\nAdvertise \\n\\nPrivacy |\\nDisclaimer |\\nTerms |\\nContact |\\nSitemap \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
       " Document(metadata={'source': 'https://www.reddit.com/r/LocalLLaMA/comments/14vnfh2/my_experience_on_starting_with_fine_tuning_llms/'}, page_content='\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Reddit and its partners use cookies and similar technologies to provide you with a better experience.\\n        \\n\\n          By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising.\\n        \\n\\n          By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of our platform.\\n        \\n\\n          For more information, please see our\\n              Cookie Notice\\n              and our\\n              Privacy Policy.\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen menu\\n\\nOpen navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nGo to Reddit Home\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n                \\n\\nA chip\\n\\n\\n\\n\\n\\n\\n\\n\\nA close button\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet app\\n\\n\\n\\nGet the Reddit app\\n\\n\\n\\nLog In\\n\\nLog in to Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExpand user menu\\nOpen settings menu\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLog In / Sign Up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdvertise on Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShop Collectible Avatars\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Get the Reddit app\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nScan this QR code to download the app now\\n\\n\\n\\n          Or check it out in the app stores \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Go to LocalLLaMA\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n\\n\\n\\n\\n\\n\\n\\n              Subreddit to discuss about Llama, the large language model created by Meta AI.\\n            \\n\\n\\n\\n\\n\\n\\nMembers\\n\\n\\n\\n\\n\\n\\n\\nOnline\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n•\\n\\n\\n\\n\\n\\n\\nIon_GPT\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      ADMIN\\n    \\n\\n      MOD\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n       My experience on starting with fine tuning LLMs with custom data\\n    \\n\\n\\n\\n\\n\\n    Discussion\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    I keep seeing questions about \"How I make a model to answer based on my data. I have [wiki, pdfs, whatever other documents]\"\\n  \\n    Currently I am making a living by helping companies built chatbots fine tuned on their custom data.\\n  \\n    Most of those are support or Q&A chatbots to answer questions from clients at any hour and day. There are also internal chatbots to be used to train new people joining the company and several other use cases.\\n  \\n    So, I was thinking to share my experience (it might be wrong and I might be doing everything wrong, but it is my experience and based on this I have a dozen chatbots running in production and talking with clients with few dozen more in different stages of testing).\\n  \\n    The actual training / fine-tuning, while it might initially seem like a daunting task due to the plethora of tools available (FastChat, Axolot, Deepspeed, transformers, LoRA, qLoRA, and more), I must tell you - this is actually the easiest part of the whole process! All you need to do is peek into their repositories, grab an example, and tweak it to fit your model and data.\\n  \\n    However, the real challenge lies in preparing the data. A massive wiki of product documentation, a thousand PDFs of your processes, or even a bustling support forum with countless topics - they all amount to nothing if you don\\'t have your data in the right format. Projects like Dolly and Orca have shown us how enriching data with context or system prompts can significantly improve the final model\\'s quality. Other projects, like Vicuna, use chains of multi-step Q&A with solid results. There are many other datasets formats, depending of the expected result. For example, a dataset for quotes is much simpler, because there will be no actual interaction, the quote is a quote.\\n  \\n    Personally, I mostly utilize the #instruction, #input, #output format for most of my fine-tuning tasks.\\n  \\n    So, shaping your data in the correct format is, without a doubt, the most difficult and time-consuming step when creating a Language Learning Model (LLM) for your company\\'s documentation, processes, support, sales, and so forth.\\n  \\n    Many methods can help you tackle this issue. Most choose to employ GPT4 for assistance. Privacy shouldn\\'t be a concern if you\\'re using Azure APIs, though they might be more costly, but offer privacy. However, if your data is incredibly sensitive, refrain from using them. And remember, any data used to train a public-facing chatbot should not contain any sensitive information.\\n  \\n    Automated tools can only do so much; manual work is indispensable and in many cases, difficult to outsource. Those who genuinely understand the product/process/business should scrutinize and cleanse the data. Even if the data is top-notch and GPT4 does a flawless job, the training could still fail. For instance, outdated information or contradictory responses can lead to poor results.\\n  \\n    In many of my projects, we involve a significant portion of the organization in the process. I develop a simple internal tool allowing individuals to review rows of training data and swiftly edit the output or flag the entire row as invalid.\\n  \\n    Once you\\'ve curated and correctly formatted your data, the fine-tuning can commence. If you have a vast amount of data, i.e., tens of thousands of instructions, it\\'s best to fine-tune the actual model. To do this, refer to the model repo and mimic their initial training process with your data.\\n  \\n    However, if you\\'re working with a smaller dataset, a LoRA or qLoRA fine-tuning would be more suitable. For this, start with examples from LoRA or qLoRA repositories, use booga UI, or experiment with different settings. Getting a good LoRA is a trial and error process, but with time, you\\'ll become good at it.\\n  \\n    Once you have your fine-tuned model, don\\'t expose it directly to clients. Instead, run client queries through the model, showcasing the responses internally and inviting internal users to correct the answers. Depending on the percentage of responses modified by users, you might need to execute another fine-tuning with this new data or completely redo the fine-tuning if results were really poor.\\n  \\n    On the hardware front, while it\\'s possible to train a qLoRA on a single 3090, I wouldn\\'t recommend it. There are too many limitations, and even browsing the web while training could lead to OOM. I personally use a cloud A6000 with 48GB VRAM, which costs about 80 cents per hour.\\n  \\n    For anything larger than a 13B model, whether it\\'s LoRA or full fine-tuning, I\\'d recommend using A100. Depending on the model and dataset size, and parameters, I run 1, 4, or 8 A100s. Most tools are tested and run smoothly on A100, so it\\'s a safe bet. I once got a good deal on H100, but the hassle of adapting the tools was too overwhelming, so I let it go.\\n  \\n    Lastly, if you\\'re looking for a quick start, try embeddings. This is a cheap, quick, and acceptable solution for internal needs. You just need to throw all internal documents into a vector db, put a model in front for searching, and voila! With no coding required, you can install booga with the superbooga extension to get started.\\n  \\n\\n    UPDATE:\\n  \\n    I saw some questions repeating, sorry that I am not able to answer to everyone, but I am updating here, hope that this helps. Here are some answers for the repeated questions:\\n  \\n\\n\\n    I do not know how to train a pre-trained model with \"raw\" data, like big documents. From what I know, any further training of a pre-trained model is done by feeding data tokenized and padded to maximum context size of the original model, no more.\\n  \\n\\n\\n    Before starting, make sure that the problem that needs to be solved and the expectations are fully defined. \"Teaching the model about xyz\" is not a problem, it is a wish. It is hard to solve \"wishes\", but we can solve problems. For example: \"I want to ask the model about xyz and get accurate answers based on abc data\". This is needed to offer non stop answering chat for customers. We expect customer to ask \"example1, 2, 3, .. 10\" and we expect the answers to be in this style \"example answers with example addressation, formal, informal, etc). We do not want the chat to engage in topics not related to xyz. If customer engage in such topics, politely explain that have no knowledge on that. (with example). This is a better description of the problem.\\n  \\n\\n\\n    It is important to define the target audience and how the model will be used. There is a big difference of using it internally inside an organisation or directly expose it to the clients. You can get a lot cheaper when it is just an internal helper and the output can be ignored if not good. For example, in this case, full documents can be ingested via vectordb and use the model to answer questions about the data from the vectordb. If you decide to go with the embeddings, this can be really helpful: https://github.com/HKUNLP/instructor-embedding\\n\\n\\n\\n    It is important to define what is the expected way to interact with the model. Do you want to chat with it? Should it follow instructions? Do you want to provide a context and get output in the provided context? Do you want to complete your writing (like Github Copilot or Starcoder)? Do you want to perform specific tasks (eg grammar checking, translation, classification of something etc)?\\n  \\n\\n\\n    After all the above are decided and clarified and you decided that embeddings are not what you want and want to proceed further with fine tuning, it is the time to decide on the data format.\\n  \\n\\n\\n    #instruction,#input,#output is a popular data format and can be used to train for both chat and instruction following. This is an example dataset in this format: https://huggingface.co/datasets/yahma/alpaca-cleaned . I am using this format the most because it is the easiest to format unstructured data into, having the optional #input it makes it very flexible\\n  \\n\\n\\n    It was proven that having better structured, with extra information training data will produce better results. Here is Dolly dataset that is using a context to enrich the data: https://huggingface.co/datasets/databricks/databricks-dolly-15k\\n\\n\\n\\n    A newer dataset that further proved that data format and quality is the most important in the output is Orca format. It is using a series of system prompts to categorize each data row (similar with a tagging system). https://huggingface.co/datasets/Open-Orca/OpenOrca\\n\\n\\n\\n    We don\\'t need complicated data structure always. For example, if the expecation is that we prompt the model \"Who wrote this quote: [famous quote content]?\" and we expect to only get name of the author, then a simple format is enough, like it is here: https://huggingface.co/datasets/Abirate/english_quotes\\n\\n\\n\\n    For a more fluid conversation, there is the Vicuna format, an Array of Q&A. Here is an example: https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered\\n\\n\\n\\n    There are other datasets formats, in some the output is partially masked (for completion suggestion models), but I have not worked and I am not familiar with those formats.\\n  \\n\\n\\n\\n\\n    From my experiments, things that can be totally wrong:\\n  \\n\\n\\n    directly train a pre-trained model with less than 50000 data row is more or less useless. I would think of directly train a model when I have more than 100k data rows, for a 13B model and at least 1 mil for a 65B model.\\n  \\n\\n\\n    with smaller datasets, it is efficient to train LoRA of qLoRA.\\n  \\n\\n\\n    I prefer to train a 4 bit qLora 30B model than a fp16 LoRA for a 13B model (about same hw requirements, but the results with the 4bit 30B model are superior to the 13B fp16 model)\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n      Read more\\n       \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Top 1%\\n            \\n\\n              Rank by size \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Top Posts\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Reddit \\n\\nreReddit: Top posts of July 10, 2023\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Reddit \\n\\nreReddit: Top posts of July 2023\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Reddit \\n\\nreReddit: Top posts of 2023\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n&nbsp;\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInternet Culture (Viral)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmazing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnimals & Pets\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCringe & Facepalm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFunny\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInteresting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMemes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOddly Satisfying\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReddit Meta\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWholesome & Heartwarming\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGames\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAction Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdventure Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEsports\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGaming Consoles & Gear\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGaming News & Discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMobile Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOther Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRole-Playing Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSimulation Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSports & Racing Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStrategy Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTabletop Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQ&As\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQ&As\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStories & Confessions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTechnology\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3D Printing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArtificial Intelligence & Machine Learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComputers & Hardware\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConsumer Electronics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDIY Electronics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProgramming\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSoftware & Apps\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStreaming Services\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTech News & Discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVirtual & Augmented Reality\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPop Culture\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCelebrities\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreators & Influencers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGenerations & Nostalgia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPodcasts\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStreamers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTarot & Astrology\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMovies & TV\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAction Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnimated Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComedy Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCrime, Mystery, & Thriller Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDocumentary Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDrama Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFantasy Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHorror Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMovie News & Discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReality TV\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRomance Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSci-Fi Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuperhero Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTV News & Discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdvertise\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHelp\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBlog\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCareers\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPress\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCommunities\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBest of Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTopics\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContent Policy\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPrivacy Policy\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nUser Agreement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nReddit, Inc. © 2024. All rights reserved.\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n     \\n \\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://medium.com/@watsonchua/finetuning-my-clone-training-an-llm-to-talk-like-me-2ee7b5ba2f88'}, page_content='Open in appSign upSign inWriteSign upSign inFinetuning My Clone — Training an LLM to Talk Like Me!Watson Chua·Follow9 min read·Jun 20, 2024--ListenShareBackgroundA large part of my past five weeks was spent attending the course Mastering LLMs: A Conference For Developers & Data Scientists, excellently conducted by Dan Becker and Hamel Husain, with many expert guest speakers sharing their experiences about working with LLM applications in production. There was a special focus on LLM finetuning, which can be used to overcome the limitations of prompt engineering and Retrieval Augmented Generation (RAG) in certain cases. The instructors shared that because it is resource and label intensive, finetuning should be used carefully and some of the reasons to perform finetuning are:The data is privateThe problem is extremely narrowPrompt engineering is impracticalAfter completing the course, I was dying to finetune my own LLM, but I didn’t have a use case. Then, an idea came to my mind: “Why not I finetune an LLM to talk like me and create a chatbot out of it?” I can then let it talk to my wife, my kids, and my friends, and I would have so much more free time!Fortunately, this use case fulfils the three conditions :The data is private => Yes, my personal chat data is privateThe problem is extremely narrow => Yes, I don’t think anyone else wants to finetune an LLM to talk like MEPrompt engineering is impractical => Yes, prompt engineering would require me to insert context about myself and the scenario at every conversation turn, which will become unwieldyAnd so, the project went underway!Data is King; It’s Everything (Almost)The most important thing in any Data Science or Machine Learning project is the data. How is my LLM going to learn to talk like me? Since my wife is going to be one of the main users of this chatbot, my data source has to contain many conversations between me and my wife, for the LLM to learn properly. WhatsApp is my main mode of communications, and most of my conversations with my wife take place there. Thus, I exported our WhatsApp chat to use as training data. I also exported the conversations with nine other friends so that the bot doesn’t only know how to talk to my wife.PreprocessingThe WhatsApp exports can’t be used directly. They need to be preprocessed into a format which the LLM can learn from. For WhatsApp data, this can be done in three steps:Combine consecutive messages from the same user into a single messageGroup the whole chat history into blocks of conversationsConcatenate the messages in each conversation and format them using a prompt templateFor Step 1, I combined consecutive messages from the same sender within five minutes of one another into a single message. For Step 2, I referred to Daniel Pleus’ blog post and notebook and adopted his method. I grouped the messages into conversation blocks where the messages in different blocks are at least one hour apart. If the conversation blocks are more than 3000 tokens, I split them into different blocks. The figure below shows an illustration.Preprocessing WhatsApp history into conversation blocksFinally, in Step 3, I concatenated all the messages in a conversation block into a single line using Llama3’s prompt template as follows:<|start_header_id|>system<|end_header_id|>my_message_1<|eot_id|><|start_header_id|>user<|end_header_id|>wife_message_1<|eot_id|><|start_header_id|>system<|end_header_id|>my_message_2<|eot_id|><|start_header_id|>user<|end_header_id|>wife_message_2<|eot_id|><|start_header_id|>system<|end_header_id|>my_message_3<|eot_id|><|start_header_id|>user<|end_header_id|>wife_message_3<|eot_id|>For example, Conversation Block 3 in the previous diagram will become:<|start_header_id|>system<|end_header_id|>Watch 5.40./nAdult price 15.50 per person omg/nMonday it will be 11.50 haha<|eot_id|><|start_header_id|>user<|end_header_id|>Walao ok<|eot_id|>Each line was then further formatted as a JSON string with key “input”, and concatenated with the processed output of the other conversation blocks to get a JSONL file as follows:{\"input\": <wife_formatted_convo_block_1>}{\"input\": <wife_formatted_convo_block_2>}{\"input\": <wife_formatted_convo_block_3>}...{\"input\": <wife_formatted_convo_block_1000>}{\"input\": <friend_1_formatted_convo_block_1>}{\"input\": <friend_1_formatted_convo_block_2>}{\"input\": <friend_1_formatted_convo_block_3>}...{\"input\": <friend_1_formatted_convo_block_100>}...{\"input\": <friend_1_formatted_convo_block_1>}{\"input\": <friend_1_formatted_convo_block_2>}{\"input\": <friend_1_formatted_convo_block_3>}...{\"input\": <friend_9_formatted_convo_block_1>}...{\"input\": <friend_9_formatted_convo_block_50>}After removing conversation blocks which are less than 100 tokens, I have a total of 4845 lines of conversations to train on. The breakdown is as follows:I’ve been talking to someone way too much[The code for this segment can be found in the preprocessing folder of my GitHub repo for this project.]Train Smarter, Not HarderWith the WhatsApp conversations properly formatted, I was ready to finetune! But before that, I had to make two decisions:Which model to finetune on?Which finetuning method to use?Base modelFor the base model, I chose Mistral-7B-v0.2 to finetune on. You might be asking “Wait a minute, didn’t you choose the Llama3 prompt template? Why are you finetuning the Mistral model?”The answer to this is that it doesn’t matter. Because I was finetuning the Mistral-7B-v0.2 base model which had not been instruction-tuned and so, I could use any prompt template I like, as long as I was consistent. This is based on advice from Hamel Husain who shared with us in the Mastering LLMs course that he would usually finetune on a base model instead of an instruction-tuned one to avoid conflicting prompt templates which could mess up the finetuning results.Finetuning techniqueThere are many techniques for finetuning and currently, the three most common ones are:Full FinetuningLow-Rank Adaptation (LoRa), andQuantised Lora (QLoRa)For a detailed explanation about the differences between the three different techniques, I refer you to this blog post by Benjamin Marie.Illustration by Benjamin MarieI have done a TL;DR version as a table below, with reference to the above-mentioned and Google Cloud’s comparisons:Full finetuning vs LoRa vs QLoRaIn my case, GPU memory usage was a critical factor since high memory GPU instances are expensive. This was exacerbated by the fact that my preprocessed conversations had large context lengths of 3000 tokens. Thus, I chose to use QLoRa with the following training parameters:max_length=3000lora_r=32lora_alpha=64lora_dropout=0.05epochs=5batch_size=1gradient_accumulation_steps=8 #(to get an effective batch size of 8)I used Hugging Face Spaces’ JupyterLab docker space with an A10G-Small GPU with 24GB VRAM to do the finetuning, at a cost of USD $1.00/hour. Finetuning used around 11GB of GPU RAM and after around 60 hours, model training was completed. This cost around USD 60 but thanks to the free USD 500 Hugging Face credits I got from signing up for the course, I didn’t have to pay anything from my own pocket.Finetuning was done on an A10 GPU[The code for this segment, adapted from Brev.dev’s Mistral finetuning notebook, can be found in the finetuning folder of my GitHub repo.]InferenceWe are now ready to test our new model!I hosted the model on an instance with a T4 GPU with 16GB GPU RAM. At a cost of $0.40 per hour, this was 60% cheaper than the A10G-Small instance. The lower GPU RAM wasn’t an issue as the finetuned model used only around 6GB of GPU RAM. I loaded the model and adapter using transfomers and bitsandbytes, then wrapped a FastAPI service around it to create an inference endpoint:Model hosted on an instance with T4 GPU for inferencingThe endpoint could be accessed using the FastAPI swagger page:Let’s see what we get for the prompt “How are you?”. As the inference code does not do any formatting, I had to format my prompt using the same template which I used for training:<|start_header_id|>user<|end_header_id|>How are you?<|eot_id|><|start_header_id|>system<|end_header_id|>The suffix <|start_header_id|>system<|end_header_id|> was appended to the last message to tell the model to always generate as the system (i.e. act like me). The model would generate tokens up till 100 tokens, or until it hit the first end-of-turn token <|eot_id|>. These are specified by parameters of the generate method which were as follows:{  \"prompt\": \"<|start_header_id|>user<|end_header_id|>How are you?<|eot_id|><|start_header_id|>system<|end_header_id|>\",  \"temperature\": 0.5,  \"max_new_tokens\": 100,  \"repetition_penalty\": 1.15,  \"custom_stop_tokens\": \"<|eot_id|>\"}I got the following response from the model:{  \"generated_text\": \"<|start_header_id|>user<|end_header_id|>How are you?<|eot_id|><|start_header_id|>system<|end_header_id|>I\\'m okay. You?\\\\nYou want to meet for lunch tomorrow?<|eot_id|><\"}Stripping off the prompt template formatting, it said:I’m okay. You? You want to meet for lunch tomorrow?Not bad. Friendly, like me.[The code for this segment can be found in the inference folder of my GitHub repo.]Bot, or Not?Finally, in the last step, I set up a Telegram bot to talk to the inference endpoint. The bot was built using the python-telegram-bot library. You first need to get a Telegram Bot token from @BotFather to be able to deploy a bot.Although I could easily build the bot using the library, I still needed to figure out the logic to get my bot to get messages from the user, talk to the LLM, and get a response.These are the steps to do so:Format and add user message to conversation listKeep prepending formatted historical messages between user and bot to the list, starting from the most recent, until the length of the conversation history hits the max tokens (3000)Join the list with the <|eot_id|> token and append <|start_header_id|>system<|end_header_id|> to the end of the prompt to make the LLM respond as the system.Once that was done, I deployed the bot by running the python script and my Telegram bot was up and running![Refer to the telegram_bot folder of my GitHub repo to see the code on how to build and deploy the bot.]Overall Set-UpPutting all the above information together, we get the following:User TestingThe first person I asked to test was, of course, my wife. This is their conversation, with my annotations on the bot’s responses.Conversation with my wifeLooks good. It talked to my wife in the same way I would, and shared the same concerns as me.Next, I asked a friend to talk to it….Conversation with my friendThis was generally still okay. The bot knew where I worked and what I did at work, but the comment about the directors seem to be over the top.Another friend spoke to it, and that was when things went haywire.Wait wut?I definitely can count better. And I don’t go around asking people to see my nipples. Now where did the LLM learn that from? 🤔 Nope, definitely not from me.Thoughts for ImprovementSpeaking to different peopleAfter playing with the bot for some time, I feel that it speaks too much like how I would speak to my wife. This is not unexpected, considering that more than 75% of the data it was trained on are our conversations. To make it a bot that can talk better to anyone, there are two things I can do:Down-sample the number of training examples between me and my wifeInstead of having a single user role for everyone, create separate roles such as wife, friend, and boss in the prompt template so that it can adopt different personasHallucination on unknownsThe bot tends to hallucinate when it faces questions or situations it is unfamiliar with, especially when the information has not been disclosed in my conversations in the training data. I can try explicitly adding background information on myself for completion finetuning before I do chat finetuning to make it learn this information.Better servingServing the model using FastAPI is functional but it’s not the best method. Merging the QLoRa adapters to the base model, and then serving them using model-serving containers like Text-Generation-Inference and vLLM would probably give a better throughput.Hosting is expensiveEven though the QLoRa model can be hosted on a relatively inexpensive T4 GPU instance for USD $0.40 per hour, the cost quickly adds up in the long run to $9.60 a day and $288 a month. No way I’m spending so much money on a toy project. I could try using llama.cpp to do CPU inference, or scheduling the instance to only turn on for certain hours.Access to BotUnfortunately, I can’t publicly share the bot’s URL as it was trained on private and sensitive information which it might disclose. However, if you know me personally, please ping me to try it out, just for the fun of it!If you would like to finetune your own chatbot, refer to my GitHub repo for the code: https://github.com/watsonchua/finetune-your-clone!LlmFinetuningDeep LearningArtificial IntelligenceGenerative Ai----FollowWritten by Watson Chua86 FollowersI\\'m a Lead Data Scientist at GovTech, specialising in NLP and Generative AIFollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://www.reddit.com/r/LocalLLaMA/comments/14vnfh2/my_experience_on_starting_with_fine_tuning_llms/'}, page_content='\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Reddit and its partners use cookies and similar technologies to provide you with a better experience.\\n        \\n\\n          By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising.\\n        \\n\\n          By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of our platform.\\n        \\n\\n          For more information, please see our\\n              Cookie Notice\\n              and our\\n              Privacy Policy.\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen menu\\n\\nOpen navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nGo to Reddit Home\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n                \\n\\nA chip\\n\\n\\n\\n\\n\\n\\n\\n\\nA close button\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet app\\n\\n\\n\\nGet the Reddit app\\n\\n\\n\\nLog In\\n\\nLog in to Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExpand user menu\\nOpen settings menu\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLog In / Sign Up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdvertise on Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShop Collectible Avatars\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Get the Reddit app\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nScan this QR code to download the app now\\n\\n\\n\\n          Or check it out in the app stores \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Go to LocalLLaMA\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n\\n\\n\\n\\n\\n\\n\\n              Subreddit to discuss about Llama, the large language model created by Meta AI.\\n            \\n\\n\\n\\n\\n\\n\\nMembers\\n\\n\\n\\n\\n\\n\\n\\nOnline\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n•\\n\\n\\n\\n\\n\\n\\nIon_GPT\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      ADMIN\\n    \\n\\n      MOD\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n       My experience on starting with fine tuning LLMs with custom data\\n    \\n\\n\\n\\n\\n\\n    Discussion\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    I keep seeing questions about \"How I make a model to answer based on my data. I have [wiki, pdfs, whatever other documents]\"\\n  \\n    Currently I am making a living by helping companies built chatbots fine tuned on their custom data.\\n  \\n    Most of those are support or Q&A chatbots to answer questions from clients at any hour and day. There are also internal chatbots to be used to train new people joining the company and several other use cases.\\n  \\n    So, I was thinking to share my experience (it might be wrong and I might be doing everything wrong, but it is my experience and based on this I have a dozen chatbots running in production and talking with clients with few dozen more in different stages of testing).\\n  \\n    The actual training / fine-tuning, while it might initially seem like a daunting task due to the plethora of tools available (FastChat, Axolot, Deepspeed, transformers, LoRA, qLoRA, and more), I must tell you - this is actually the easiest part of the whole process! All you need to do is peek into their repositories, grab an example, and tweak it to fit your model and data.\\n  \\n    However, the real challenge lies in preparing the data. A massive wiki of product documentation, a thousand PDFs of your processes, or even a bustling support forum with countless topics - they all amount to nothing if you don\\'t have your data in the right format. Projects like Dolly and Orca have shown us how enriching data with context or system prompts can significantly improve the final model\\'s quality. Other projects, like Vicuna, use chains of multi-step Q&A with solid results. There are many other datasets formats, depending of the expected result. For example, a dataset for quotes is much simpler, because there will be no actual interaction, the quote is a quote.\\n  \\n    Personally, I mostly utilize the #instruction, #input, #output format for most of my fine-tuning tasks.\\n  \\n    So, shaping your data in the correct format is, without a doubt, the most difficult and time-consuming step when creating a Language Learning Model (LLM) for your company\\'s documentation, processes, support, sales, and so forth.\\n  \\n    Many methods can help you tackle this issue. Most choose to employ GPT4 for assistance. Privacy shouldn\\'t be a concern if you\\'re using Azure APIs, though they might be more costly, but offer privacy. However, if your data is incredibly sensitive, refrain from using them. And remember, any data used to train a public-facing chatbot should not contain any sensitive information.\\n  \\n    Automated tools can only do so much; manual work is indispensable and in many cases, difficult to outsource. Those who genuinely understand the product/process/business should scrutinize and cleanse the data. Even if the data is top-notch and GPT4 does a flawless job, the training could still fail. For instance, outdated information or contradictory responses can lead to poor results.\\n  \\n    In many of my projects, we involve a significant portion of the organization in the process. I develop a simple internal tool allowing individuals to review rows of training data and swiftly edit the output or flag the entire row as invalid.\\n  \\n    Once you\\'ve curated and correctly formatted your data, the fine-tuning can commence. If you have a vast amount of data, i.e., tens of thousands of instructions, it\\'s best to fine-tune the actual model. To do this, refer to the model repo and mimic their initial training process with your data.\\n  \\n    However, if you\\'re working with a smaller dataset, a LoRA or qLoRA fine-tuning would be more suitable. For this, start with examples from LoRA or qLoRA repositories, use booga UI, or experiment with different settings. Getting a good LoRA is a trial and error process, but with time, you\\'ll become good at it.\\n  \\n    Once you have your fine-tuned model, don\\'t expose it directly to clients. Instead, run client queries through the model, showcasing the responses internally and inviting internal users to correct the answers. Depending on the percentage of responses modified by users, you might need to execute another fine-tuning with this new data or completely redo the fine-tuning if results were really poor.\\n  \\n    On the hardware front, while it\\'s possible to train a qLoRA on a single 3090, I wouldn\\'t recommend it. There are too many limitations, and even browsing the web while training could lead to OOM. I personally use a cloud A6000 with 48GB VRAM, which costs about 80 cents per hour.\\n  \\n    For anything larger than a 13B model, whether it\\'s LoRA or full fine-tuning, I\\'d recommend using A100. Depending on the model and dataset size, and parameters, I run 1, 4, or 8 A100s. Most tools are tested and run smoothly on A100, so it\\'s a safe bet. I once got a good deal on H100, but the hassle of adapting the tools was too overwhelming, so I let it go.\\n  \\n    Lastly, if you\\'re looking for a quick start, try embeddings. This is a cheap, quick, and acceptable solution for internal needs. You just need to throw all internal documents into a vector db, put a model in front for searching, and voila! With no coding required, you can install booga with the superbooga extension to get started.\\n  \\n\\n    UPDATE:\\n  \\n    I saw some questions repeating, sorry that I am not able to answer to everyone, but I am updating here, hope that this helps. Here are some answers for the repeated questions:\\n  \\n\\n\\n    I do not know how to train a pre-trained model with \"raw\" data, like big documents. From what I know, any further training of a pre-trained model is done by feeding data tokenized and padded to maximum context size of the original model, no more.\\n  \\n\\n\\n    Before starting, make sure that the problem that needs to be solved and the expectations are fully defined. \"Teaching the model about xyz\" is not a problem, it is a wish. It is hard to solve \"wishes\", but we can solve problems. For example: \"I want to ask the model about xyz and get accurate answers based on abc data\". This is needed to offer non stop answering chat for customers. We expect customer to ask \"example1, 2, 3, .. 10\" and we expect the answers to be in this style \"example answers with example addressation, formal, informal, etc). We do not want the chat to engage in topics not related to xyz. If customer engage in such topics, politely explain that have no knowledge on that. (with example). This is a better description of the problem.\\n  \\n\\n\\n    It is important to define the target audience and how the model will be used. There is a big difference of using it internally inside an organisation or directly expose it to the clients. You can get a lot cheaper when it is just an internal helper and the output can be ignored if not good. For example, in this case, full documents can be ingested via vectordb and use the model to answer questions about the data from the vectordb. If you decide to go with the embeddings, this can be really helpful: https://github.com/HKUNLP/instructor-embedding\\n\\n\\n\\n    It is important to define what is the expected way to interact with the model. Do you want to chat with it? Should it follow instructions? Do you want to provide a context and get output in the provided context? Do you want to complete your writing (like Github Copilot or Starcoder)? Do you want to perform specific tasks (eg grammar checking, translation, classification of something etc)?\\n  \\n\\n\\n    After all the above are decided and clarified and you decided that embeddings are not what you want and want to proceed further with fine tuning, it is the time to decide on the data format.\\n  \\n\\n\\n    #instruction,#input,#output is a popular data format and can be used to train for both chat and instruction following. This is an example dataset in this format: https://huggingface.co/datasets/yahma/alpaca-cleaned . I am using this format the most because it is the easiest to format unstructured data into, having the optional #input it makes it very flexible\\n  \\n\\n\\n    It was proven that having better structured, with extra information training data will produce better results. Here is Dolly dataset that is using a context to enrich the data: https://huggingface.co/datasets/databricks/databricks-dolly-15k\\n\\n\\n\\n    A newer dataset that further proved that data format and quality is the most important in the output is Orca format. It is using a series of system prompts to categorize each data row (similar with a tagging system). https://huggingface.co/datasets/Open-Orca/OpenOrca\\n\\n\\n\\n    We don\\'t need complicated data structure always. For example, if the expecation is that we prompt the model \"Who wrote this quote: [famous quote content]?\" and we expect to only get name of the author, then a simple format is enough, like it is here: https://huggingface.co/datasets/Abirate/english_quotes\\n\\n\\n\\n    For a more fluid conversation, there is the Vicuna format, an Array of Q&A. Here is an example: https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered\\n\\n\\n\\n    There are other datasets formats, in some the output is partially masked (for completion suggestion models), but I have not worked and I am not familiar with those formats.\\n  \\n\\n\\n\\n\\n    From my experiments, things that can be totally wrong:\\n  \\n\\n\\n    directly train a pre-trained model with less than 50000 data row is more or less useless. I would think of directly train a model when I have more than 100k data rows, for a 13B model and at least 1 mil for a 65B model.\\n  \\n\\n\\n    with smaller datasets, it is efficient to train LoRA of qLoRA.\\n  \\n\\n\\n    I prefer to train a 4 bit qLora 30B model than a fp16 LoRA for a 13B model (about same hw requirements, but the results with the 4bit 30B model are superior to the 13B fp16 model)\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n      Read more\\n       \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Top 1%\\n            \\n\\n              Rank by size \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Top Posts\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Reddit \\n\\nreReddit: Top posts of July 10, 2023\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Reddit \\n\\nreReddit: Top posts of July 2023\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Reddit \\n\\nreReddit: Top posts of 2023\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n&nbsp;\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInternet Culture (Viral)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmazing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnimals & Pets\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCringe & Facepalm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFunny\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInteresting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMemes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOddly Satisfying\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReddit Meta\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWholesome & Heartwarming\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGames\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAction Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdventure Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEsports\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGaming Consoles & Gear\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGaming News & Discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMobile Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOther Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRole-Playing Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSimulation Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSports & Racing Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStrategy Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTabletop Games\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQ&As\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQ&As\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStories & Confessions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTechnology\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3D Printing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArtificial Intelligence & Machine Learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComputers & Hardware\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConsumer Electronics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDIY Electronics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProgramming\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSoftware & Apps\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStreaming Services\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTech News & Discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVirtual & Augmented Reality\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPop Culture\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCelebrities\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreators & Influencers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGenerations & Nostalgia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPodcasts\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStreamers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTarot & Astrology\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMovies & TV\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAction Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnimated Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComedy Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCrime, Mystery, & Thriller Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDocumentary Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDrama Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFantasy Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHorror Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMovie News & Discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReality TV\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRomance Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSci-Fi Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuperhero Movies & Series\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTV News & Discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdvertise\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHelp\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBlog\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCareers\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPress\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCommunities\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBest of Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTopics\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContent Policy\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPrivacy Policy\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nUser Agreement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nReddit, Inc. © 2024. All rights reserved.\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n     \\n \\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://medium.com/@watsonchua/finetuning-my-clone-training-an-llm-to-talk-like-me-2ee7b5ba2f88'}, page_content='Open in appSign upSign inWriteSign upSign inFinetuning My Clone — Training an LLM to Talk Like Me!Watson Chua·Follow9 min read·Jun 20, 2024--ListenShareBackgroundA large part of my past five weeks was spent attending the course Mastering LLMs: A Conference For Developers & Data Scientists, excellently conducted by Dan Becker and Hamel Husain, with many expert guest speakers sharing their experiences about working with LLM applications in production. There was a special focus on LLM finetuning, which can be used to overcome the limitations of prompt engineering and Retrieval Augmented Generation (RAG) in certain cases. The instructors shared that because it is resource and label intensive, finetuning should be used carefully and some of the reasons to perform finetuning are:The data is privateThe problem is extremely narrowPrompt engineering is impracticalAfter completing the course, I was dying to finetune my own LLM, but I didn’t have a use case. Then, an idea came to my mind: “Why not I finetune an LLM to talk like me and create a chatbot out of it?” I can then let it talk to my wife, my kids, and my friends, and I would have so much more free time!Fortunately, this use case fulfils the three conditions :The data is private => Yes, my personal chat data is privateThe problem is extremely narrow => Yes, I don’t think anyone else wants to finetune an LLM to talk like MEPrompt engineering is impractical => Yes, prompt engineering would require me to insert context about myself and the scenario at every conversation turn, which will become unwieldyAnd so, the project went underway!Data is King; It’s Everything (Almost)The most important thing in any Data Science or Machine Learning project is the data. How is my LLM going to learn to talk like me? Since my wife is going to be one of the main users of this chatbot, my data source has to contain many conversations between me and my wife, for the LLM to learn properly. WhatsApp is my main mode of communications, and most of my conversations with my wife take place there. Thus, I exported our WhatsApp chat to use as training data. I also exported the conversations with nine other friends so that the bot doesn’t only know how to talk to my wife.PreprocessingThe WhatsApp exports can’t be used directly. They need to be preprocessed into a format which the LLM can learn from. For WhatsApp data, this can be done in three steps:Combine consecutive messages from the same user into a single messageGroup the whole chat history into blocks of conversationsConcatenate the messages in each conversation and format them using a prompt templateFor Step 1, I combined consecutive messages from the same sender within five minutes of one another into a single message. For Step 2, I referred to Daniel Pleus’ blog post and notebook and adopted his method. I grouped the messages into conversation blocks where the messages in different blocks are at least one hour apart. If the conversation blocks are more than 3000 tokens, I split them into different blocks. The figure below shows an illustration.Preprocessing WhatsApp history into conversation blocksFinally, in Step 3, I concatenated all the messages in a conversation block into a single line using Llama3’s prompt template as follows:<|start_header_id|>system<|end_header_id|>my_message_1<|eot_id|><|start_header_id|>user<|end_header_id|>wife_message_1<|eot_id|><|start_header_id|>system<|end_header_id|>my_message_2<|eot_id|><|start_header_id|>user<|end_header_id|>wife_message_2<|eot_id|><|start_header_id|>system<|end_header_id|>my_message_3<|eot_id|><|start_header_id|>user<|end_header_id|>wife_message_3<|eot_id|>For example, Conversation Block 3 in the previous diagram will become:<|start_header_id|>system<|end_header_id|>Watch 5.40./nAdult price 15.50 per person omg/nMonday it will be 11.50 haha<|eot_id|><|start_header_id|>user<|end_header_id|>Walao ok<|eot_id|>Each line was then further formatted as a JSON string with key “input”, and concatenated with the processed output of the other conversation blocks to get a JSONL file as follows:{\"input\": <wife_formatted_convo_block_1>}{\"input\": <wife_formatted_convo_block_2>}{\"input\": <wife_formatted_convo_block_3>}...{\"input\": <wife_formatted_convo_block_1000>}{\"input\": <friend_1_formatted_convo_block_1>}{\"input\": <friend_1_formatted_convo_block_2>}{\"input\": <friend_1_formatted_convo_block_3>}...{\"input\": <friend_1_formatted_convo_block_100>}...{\"input\": <friend_1_formatted_convo_block_1>}{\"input\": <friend_1_formatted_convo_block_2>}{\"input\": <friend_1_formatted_convo_block_3>}...{\"input\": <friend_9_formatted_convo_block_1>}...{\"input\": <friend_9_formatted_convo_block_50>}After removing conversation blocks which are less than 100 tokens, I have a total of 4845 lines of conversations to train on. The breakdown is as follows:I’ve been talking to someone way too much[The code for this segment can be found in the preprocessing folder of my GitHub repo for this project.]Train Smarter, Not HarderWith the WhatsApp conversations properly formatted, I was ready to finetune! But before that, I had to make two decisions:Which model to finetune on?Which finetuning method to use?Base modelFor the base model, I chose Mistral-7B-v0.2 to finetune on. You might be asking “Wait a minute, didn’t you choose the Llama3 prompt template? Why are you finetuning the Mistral model?”The answer to this is that it doesn’t matter. Because I was finetuning the Mistral-7B-v0.2 base model which had not been instruction-tuned and so, I could use any prompt template I like, as long as I was consistent. This is based on advice from Hamel Husain who shared with us in the Mastering LLMs course that he would usually finetune on a base model instead of an instruction-tuned one to avoid conflicting prompt templates which could mess up the finetuning results.Finetuning techniqueThere are many techniques for finetuning and currently, the three most common ones are:Full FinetuningLow-Rank Adaptation (LoRa), andQuantised Lora (QLoRa)For a detailed explanation about the differences between the three different techniques, I refer you to this blog post by Benjamin Marie.Illustration by Benjamin MarieI have done a TL;DR version as a table below, with reference to the above-mentioned and Google Cloud’s comparisons:Full finetuning vs LoRa vs QLoRaIn my case, GPU memory usage was a critical factor since high memory GPU instances are expensive. This was exacerbated by the fact that my preprocessed conversations had large context lengths of 3000 tokens. Thus, I chose to use QLoRa with the following training parameters:max_length=3000lora_r=32lora_alpha=64lora_dropout=0.05epochs=5batch_size=1gradient_accumulation_steps=8 #(to get an effective batch size of 8)I used Hugging Face Spaces’ JupyterLab docker space with an A10G-Small GPU with 24GB VRAM to do the finetuning, at a cost of USD $1.00/hour. Finetuning used around 11GB of GPU RAM and after around 60 hours, model training was completed. This cost around USD 60 but thanks to the free USD 500 Hugging Face credits I got from signing up for the course, I didn’t have to pay anything from my own pocket.Finetuning was done on an A10 GPU[The code for this segment, adapted from Brev.dev’s Mistral finetuning notebook, can be found in the finetuning folder of my GitHub repo.]InferenceWe are now ready to test our new model!I hosted the model on an instance with a T4 GPU with 16GB GPU RAM. At a cost of $0.40 per hour, this was 60% cheaper than the A10G-Small instance. The lower GPU RAM wasn’t an issue as the finetuned model used only around 6GB of GPU RAM. I loaded the model and adapter using transfomers and bitsandbytes, then wrapped a FastAPI service around it to create an inference endpoint:Model hosted on an instance with T4 GPU for inferencingThe endpoint could be accessed using the FastAPI swagger page:Let’s see what we get for the prompt “How are you?”. As the inference code does not do any formatting, I had to format my prompt using the same template which I used for training:<|start_header_id|>user<|end_header_id|>How are you?<|eot_id|><|start_header_id|>system<|end_header_id|>The suffix <|start_header_id|>system<|end_header_id|> was appended to the last message to tell the model to always generate as the system (i.e. act like me). The model would generate tokens up till 100 tokens, or until it hit the first end-of-turn token <|eot_id|>. These are specified by parameters of the generate method which were as follows:{  \"prompt\": \"<|start_header_id|>user<|end_header_id|>How are you?<|eot_id|><|start_header_id|>system<|end_header_id|>\",  \"temperature\": 0.5,  \"max_new_tokens\": 100,  \"repetition_penalty\": 1.15,  \"custom_stop_tokens\": \"<|eot_id|>\"}I got the following response from the model:{  \"generated_text\": \"<|start_header_id|>user<|end_header_id|>How are you?<|eot_id|><|start_header_id|>system<|end_header_id|>I\\'m okay. You?\\\\nYou want to meet for lunch tomorrow?<|eot_id|><\"}Stripping off the prompt template formatting, it said:I’m okay. You? You want to meet for lunch tomorrow?Not bad. Friendly, like me.[The code for this segment can be found in the inference folder of my GitHub repo.]Bot, or Not?Finally, in the last step, I set up a Telegram bot to talk to the inference endpoint. The bot was built using the python-telegram-bot library. You first need to get a Telegram Bot token from @BotFather to be able to deploy a bot.Although I could easily build the bot using the library, I still needed to figure out the logic to get my bot to get messages from the user, talk to the LLM, and get a response.These are the steps to do so:Format and add user message to conversation listKeep prepending formatted historical messages between user and bot to the list, starting from the most recent, until the length of the conversation history hits the max tokens (3000)Join the list with the <|eot_id|> token and append <|start_header_id|>system<|end_header_id|> to the end of the prompt to make the LLM respond as the system.Once that was done, I deployed the bot by running the python script and my Telegram bot was up and running![Refer to the telegram_bot folder of my GitHub repo to see the code on how to build and deploy the bot.]Overall Set-UpPutting all the above information together, we get the following:User TestingThe first person I asked to test was, of course, my wife. This is their conversation, with my annotations on the bot’s responses.Conversation with my wifeLooks good. It talked to my wife in the same way I would, and shared the same concerns as me.Next, I asked a friend to talk to it….Conversation with my friendThis was generally still okay. The bot knew where I worked and what I did at work, but the comment about the directors seem to be over the top.Another friend spoke to it, and that was when things went haywire.Wait wut?I definitely can count better. And I don’t go around asking people to see my nipples. Now where did the LLM learn that from? 🤔 Nope, definitely not from me.Thoughts for ImprovementSpeaking to different peopleAfter playing with the bot for some time, I feel that it speaks too much like how I would speak to my wife. This is not unexpected, considering that more than 75% of the data it was trained on are our conversations. To make it a bot that can talk better to anyone, there are two things I can do:Down-sample the number of training examples between me and my wifeInstead of having a single user role for everyone, create separate roles such as wife, friend, and boss in the prompt template so that it can adopt different personasHallucination on unknownsThe bot tends to hallucinate when it faces questions or situations it is unfamiliar with, especially when the information has not been disclosed in my conversations in the training data. I can try explicitly adding background information on myself for completion finetuning before I do chat finetuning to make it learn this information.Better servingServing the model using FastAPI is functional but it’s not the best method. Merging the QLoRa adapters to the base model, and then serving them using model-serving containers like Text-Generation-Inference and vLLM would probably give a better throughput.Hosting is expensiveEven though the QLoRa model can be hosted on a relatively inexpensive T4 GPU instance for USD $0.40 per hour, the cost quickly adds up in the long run to $9.60 a day and $288 a month. No way I’m spending so much money on a toy project. I could try using llama.cpp to do CPU inference, or scheduling the instance to only turn on for certain hours.Access to BotUnfortunately, I can’t publicly share the bot’s URL as it was trained on private and sensitive information which it might disclose. However, if you know me personally, please ping me to try it out, just for the fun of it!If you would like to finetune your own chatbot, refer to my GitHub repo for the code: https://github.com/watsonchua/finetune-your-clone!LlmFinetuningDeep LearningArtificial IntelligenceGenerative Ai----FollowWritten by Watson Chua86 FollowersI\\'m a Lead Data Scientist at GovTech, specialising in NLP and Generative AIFollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "documents = []\n",
    "# Chain\n",
    "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "# Run\n",
    "for question, answer in qa_dictionary.items():\n",
    "    queries = generate_queries_decomposition.invoke({\"question\":question,\"answer\":answer})\n",
    "    print(queries)\n",
    "    for query in queries:\n",
    "        scraper = WebScraper(answer,2)\n",
    "        # Call the method to get the file paths of the scraped data\n",
    "        documents.extend(scraper.get_scraped_data())\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the relevant documents in a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Index\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking accuracy with  background context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"\n",
    "Here is the question for the answer you need to check:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is the answer you need to check:\n",
    "\n",
    "\\n --- \\n {answer} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer + accuracy percentage + feedback:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context, your own knowledge and background question + answer + accuracy percentage + feedback\n",
    "on the subject matter to get the accuracy of the answer. A percentage accuracy score and also note down the \n",
    "places that the answer was inaccurate and give feedback for those places\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_qa_pair(question, answer, feedback):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\nFeedback: {feedback}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"answer\") | retriever, \n",
    "     \"answer\": itemgetter(\"answer\"),\n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "for question, answer in qa_dictionary.items():\n",
    "    feedback = rag_chain.invoke({\"answer\":answer,\"question\":question,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(question,answer,feedback)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n---\\nQuestion: Hello! Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. To start, could you tell me about your experience with machine learning, particularly any projects or coursework you've completed in this area?\\nAnswer: I'm sure I have a total of six months of experience with machine learning after I entered the University of Kent. Right now I'm mainly working on Numpy and Pandas. Numpy is to analyze image information and Pandas to extract data from CSVs.\\nFeedback: Accuracy: 70%\\n\\nThe answer correctly identifies the use of Numpy and Pandas for analyzing image information and extracting data from CSVs in the context of machine learning. However, the answer does not directly address the specific question about importing image data from a CSV file and saving it as a numpy array for processing. \\n\\nFeedback:\\n- The answer could be more accurate by providing a step-by-step guide or code snippet on how to achieve the task of importing image data from a CSV file and converting it into a numpy array for processing.\\n- Including examples or references to relevant libraries or functions in Numpy and Pandas would enhance the accuracy of the response.\\n---\\nQuestion: Thank you for sharing that information. Could you elaborate on a specific machine learning project you've worked on, perhaps one that involved Numpy or Pandas? What was the goal of the project, and what challenges did you face?\\nAnswer: I'm sure so one of the projects that I worked on was classifying the minst data set of images. Yeah basically it was done. I extracted the training set from the minst data, used a CNN algorithm to find out features from the images and then use the test set to predict the output of the model and it worked.\\nFeedback: Accuracy: 90%\\n\\nThe answer accurately describes the project of classifying the MNIST dataset of images using a CNN algorithm. It mentions extracting the training set, finding features from the images, and using the test set to predict the output of the model.\\n\\nInaccuracy:\\nThe answer could be more detailed by providing information on the specific CNN architecture used, any preprocessing steps applied to the images, and the evaluation metrics used to assess the model's performance.\\n\\nFeedback:\\n- Including details on the CNN architecture, preprocessing steps, and evaluation metrics would enhance the accuracy and completeness of the response.\\n- Providing insights into any challenges faced during the project or any improvements made to the model would add depth to the answer.\\n---\\nQuestion: I see. For your next project, have you considered working with any advanced optimization methods or modern ML techniques beyond CNNs? If so, which ones interest you and why?\\nAnswer: Yes, so LLM seem to be the rage these days. I am trying or will be interested in working on fine-tuning an LLM model to my specific needs as a chatbot. But I have not thought of what the chatbot will do.\\nFeedback: Accuracy: 95%\\n\\nThe answer accurately discusses the process of finetuning an LLM to talk like the author and creating a chatbot out of it. It correctly identifies the use case fulfilling the conditions of private data, a narrow problem, and the impracticality of prompt engineering. The answer also mentions the importance of data in the project, specifically using WhatsApp chat data for training the LLM.\\n\\nInaccuracy:\\nThe answer could be more detailed by providing insights into the specific techniques or methods used for finetuning the LLM, such as the choice of model architecture, hyperparameters, or training process.\\nIncluding examples of how the LLM was trained to mimic the author's conversational style or specific challenges faced during the project would enhance the completeness of the response.\\n\\nFeedback:\\n- Providing details on the techniques or methods used for finetuning the LLM, such as model architecture or training process, would add depth to the answer.\\n- Including examples or anecdotes of how the LLM was trained to mimic the author's conversational style or any challenges faced during the project would make the response more engaging and informative.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
