{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnthropicWrapper import ClaudeChat\n",
    "from AnthropicWrapper import Utilities\n",
    "from joblib import load\n",
    "import os\n",
    "import fitz\n",
    "import numpy as np\n",
    "from hume_analysis import HumeSentimentAnalyzer\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM-2 Configuration ---\n",
    "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
    "llm2_system_prompt = \"\"\"\n",
    "You are a seasoned hiring manager evaluating a candidate for a [Job Title] position at [Company Name]. The candidate has [Experience Level] experience in the field. You have access to the candidate's CV, the transcript of their interview, and sentiment analysis data from Hume.ai.\n",
    "You are to primarily use the transcript of the interview to make your decision on the candidate's performance. Further supportive information can be found in the sentiment analysis and CV to assist, but the primary analysis should lie with the transcript.\n",
    "Please take into account in order the accuracy of the candidates answer, sentimnet and then the others skills mentioned here.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. **Understand the Job Requirements:** Carefully analyze the [Job Description] provided and identify the key skills, experience, and qualifications required for success in this role.\n",
    "\n",
    "2. **Evaluate Candidate Alignment:** Assess how well the candidate's qualifications and experience align with the identified job requirements.\n",
    "    * **Accuracy** Based on your knowledge please analyze the accuracy of the candidates answer. Give an accuracy rating i percentage for the candidate.\n",
    "    * **Technical Skills:**  Does the candidate demonstrate the necessary technical skills, including specific software, tools, and frameworks mentioned in the job description? \n",
    "    * **Project Experience:**  Are the candidate's projects relevant to the role and demonstrate the required level of complexity and problem-solving abilities?\n",
    "    * **Soft Skills:**  Does the candidate possess the necessary communication, collaboration, and problem-solving skills?\n",
    "    * **Cultural Fit:**  Does the candidate seem to align with the company's values and work environment as described in the job description?\n",
    "\n",
    "3. **Analyze Sentiment Data:**  Use the sentiment analysis data from Hume.ai to understand the candidate's emotional state during the interview.  Does their emotional response indicate confidence, enthusiasm, or any potential issues?\n",
    "\n",
    "4. **Analyze Toxicity Scores:**  Does the candidate's communication exhibit any signs of toxicity, unprofessionalism, or potentially problematic behavior?\n",
    "\n",
    "5. **Provide a Recommendation:** \n",
    "    * **Strong Candidate:** The candidate demonstrates strong technical skills, relevant experience, and a positive attitude. Recommend moving them forward in the interview process.\n",
    "    * **Consider for Further Evaluation:** The candidate has potential, but their technical skills or project experience need further investigation. Recommend additional interviews or assessments. \n",
    "    * **Not a Fit:** The candidate lacks the necessary technical skills or experience, or their communication/attitude was not compelling. Recommend not moving forward with this candidate.\n",
    "\n",
    "**Explain your reasoning:** Provide specific evidence from the interview transcript, sentiment analysis of the interview, and CV to support your recommendation. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_description = \"\"\"\n",
    "Do you want to tackle the biggest questions in finance with near infinite compute power at your fingertips?\n",
    "\n",
    "G-Research is a leading quantitative research and technology firm, with offices in London and Dallas. We are proud to employ some of the best people in their field and to nurture their talent in a dynamic, flexible and highly stimulating culture where world-beating ideas are cultivated and rewarded.\n",
    "\n",
    "This is a role based in our new Soho Place office - opened in 2023 - in the heart of Central London and home to our Research Lab.\n",
    "\n",
    "The role\n",
    "\n",
    "We are looking for exceptional machine learning engineers to work alongside our quantitative researchers on cutting-edge machine learning problems.\n",
    "\n",
    "As a member of the Core Technical Machine Learning team, you will be engaged in a mixture of individual and collaborative work to tackle some of the toughest research questions.\n",
    "\n",
    "In this role, you will use a combination of off-the-shelf tools and custom solutions written from scratch to drive the latest advances in quantitative research.\n",
    "\n",
    "Past projects have included:\n",
    "\n",
    "Implementing ideas from a recently published research paper\n",
    "Writing custom libraries for efficiently training on petabytes of data\n",
    "Reducing model training times by hand optimising machine learning operations\n",
    "Profiling custom ML architectures to identify performance bottlenecks\n",
    "Evaluating the latest hardware and software in the machine learning ecosystem\n",
    "Who are we looking for?\n",
    "\n",
    "Candidates will be comfortable working both independently and in small teams on a variety of engineering challenges, with a particular focus on machine learning and scientific computing.\n",
    "\n",
    "The ideal candidate will have the following skills and experience:\n",
    "\n",
    "Either a post-graduate degree in machine learning or a related discipline, or commercial experience working on machine learning models at scale. We will also consider exceptional candidates with a proven record of success in online data science competitions, such as Kaggle\n",
    "Strong object-oriented programming skills and experience working with Python, PyTorch and NumPy are desirable\n",
    "Experience in one or more advanced optimisation methods, modern ML techniques, HPC, profiling, model inference; you dont need to have all of the above\n",
    "Excellent ML reasoning and communication skills are crucial: off-the-shelf methods dont always work on our data so you will need to understand how to develop your own models in a collaborative environment working in a team with complementary skills\n",
    "Finance experience is not necessary for this role and candidates from non-financial backgrounds are encouraged to apply.\n",
    "\n",
    "Why should you apply?\n",
    "\n",
    "Highly competitive compensation plus annual discretionary bonus\n",
    "Lunch provided (via Just Eat for Business) and dedicated barista bar\n",
    "35 days annual leave\n",
    "9 percent company pension contributions\n",
    "Informal dress code and excellent work/life balance\n",
    "Comprehensive healthcare and life assurance\n",
    "Cycle-to-work scheme\n",
    "Monthly company events\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function for LLM-2 analysis ---\n",
    "def analyze_candidate(job_title, experience_level, job_description, interview_transcript, cv, analyzer_output):\n",
    "    \"\"\"\n",
    "    Analyzes a candidate's suitability based on the provided data.\n",
    "\n",
    "    Args:\n",
    "        job_title (str): The title of the job.\n",
    "        experience_level (str): The candidate's experience level.\n",
    "        job_description (str): The text of the job description.\n",
    "        interview_transcript (str): The transcript of the interview.\n",
    "        cv (str): The candidate's CV.\n",
    "        sentiment_data (dict): Sentiment data from Hume.ai.\n",
    "        toxicity_data (dict): Toxicity data from Hume.ai.\n",
    "\n",
    "    Returns:\n",
    "        str: The recommendation and reasoning from LLM-2.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a prompt with placeholders for dynamic values\n",
    "    llm2_prompt = llm2_system_prompt.replace(\"[Job Title]\", job_title)\n",
    "    llm2_prompt = llm2_prompt.replace(\"[Experience Level]\", experience_level)\n",
    "    llm2_prompt = llm2_prompt.replace(\"[Job Description]\", job_description)\n",
    "    \n",
    "     # --- Preprocess Sentiment Data ---\n",
    "    positive_emotions = [\"Joy\", \"Enthusiasm\", \"Excitement\", \"Pride\", \"Satisfaction\", \"Triumph\", \"Surprise (positive)\", \"Contentment\", \"Ecstasy\", \"Gratitude\", \"Love\", \"Relief\"]\n",
    "    negative_emotions = [\"Anger\", \"Annoyance\", \"Anxiety\", \"Boredom\", \"Contempt\", \"Disappointment\", \"Disapproval\", \"Disgust\", \"Distress\", \"Fear\", \"Guilt\", \"Horror\", \"Pain\", \"Sadness\", \"Shame\", \"Surprise (negative)\", \"Sympathy\", \"Tiredness\"]\n",
    "\n",
    "    positive_sentiment_score = np.mean([analyzer_output[\"emotions\"].get(emotion, 0) for emotion in positive_emotions])\n",
    "    negative_sentiment_score = np.mean([analyzer_output[\"emotions\"].get(emotion, 0) for emotion in negative_emotions])\n",
    "\n",
    "    # --- Preprocess Toxicity Data ---\n",
    "    toxicity_weights = {\"severe_toxic\": 0.3, \"threat\": 0.2, \"toxic\": 0.15, \"identity_hate\": 0.1, \"insult\": 0.1, \"obscene\": 0.1}\n",
    "    overall_toxicity_score = np.sum([analyzer_output[\"toxicity\"].get(category, 0) * toxicity_weights[category] for category in toxicity_weights])\n",
    "    toxicity_level = \"Low\" if overall_toxicity_score < 0.01 else \"Moderate\" if overall_toxicity_score < 0.05 else \"High\"\n",
    "\n",
    "    # ---  Preprocess Sentiment Scores (1-9) ---\n",
    "    sentiment_scores = analyzer_output[\"sentiments\"] \n",
    "    sentiment_scores = analyzer_output[\"sentiments\"]\n",
    "    overall_sentiment_score = sum(float(key) * float(value) for key, value in sentiment_scores.items())\n",
    "    overall_sentiment_level = \"Highly Negative\" if overall_sentiment_score < 3 else \"Negative\" if overall_sentiment_score < 6 else \"Neutral\" if overall_sentiment_score < 7 else \"Positive\" if overall_sentiment_score < 8 else \"Highly Positive\"\n",
    "    \n",
    "    # --- Add Preprocessed Data to the Analyzer Output ---\n",
    "    analyzer_output[\"Preprocessed Sentiment\"] = {\n",
    "        \"Positive Sentiment\": positive_sentiment_score,\n",
    "        \"Negative Sentiment\": negative_sentiment_score,\n",
    "        \"Overall Sentiment Score (1-9)\": overall_sentiment_score,\n",
    "        \"Overall Sentiment Level\": overall_sentiment_level\n",
    "    }\n",
    "\n",
    "    analyzer_output[\"Preprocessed Toxicity\"] = {\n",
    "        \"Overall Toxicity Score\": overall_toxicity_score,\n",
    "        \"Toxicity Level\": toxicity_level\n",
    "    }\n",
    "\n",
    "    # --- Prepare the data for LLM-2 ---\n",
    "    analysis_data = {\n",
    "        \"Interview Transcript\": interview_transcript,\n",
    "        \"CV\": cv,\n",
    "        \"Analyzer Output\": analyzer_output  # Pass the entire dictionary\n",
    "    }\n",
    "\n",
    "    llm2_prompt += \"\\n\\nHere is the data for your analysis:\\n\"\n",
    "    llm2_prompt += \"\\n\".join(f\"{key}: {value}\" for key, value in analysis_data.items())\n",
    "    global claude\n",
    "    claude = ClaudeChat(chat_model_name, llm2_prompt)\n",
    "    return claude.chat(\"Please Execute the system prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-3-5-sonnet-20240620\"\n",
    "job_role = \"Machine Learning Engineer\"\n",
    "candidate_skill = \"Entry-Level\"\n",
    "utilities = Utilities()\n",
    "transcript_path = \"conversation.pdf\"\n",
    "transcript = utilities.process_pdf(transcript_path)\n",
    "pdf_path = r\"D:\\Hidden Desktop\\OneDrive\\Cross Device\\Jobs Applications\\Graduating\\CV.pdf\"\n",
    "cv = utilities.process_pdf(transcript_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef extract_transcript_from_pdf(pdf_path):\\n\\n    doc = fitz.open(pdf_path)\\n    extracted_transcript = \"\"\\n\\n    for page_num in range(doc.page_count):\\n        page = doc[page_num]\\n        blocks = page.get_text(\"blocks\")\\n\\n        for block in blocks:\\n            text = block[4].strip()\\n            if text:\\n                if block[0] < 200 and block[3] > 12:  # Check for headings or dialogue lines\\n                    extracted_transcript += f\"\\n\\n{text}\\n\"\\n                else:\\n                    extracted_transcript += f\"{text} \"\\n\\n    return extracted_transcript\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def extract_transcript_from_pdf(pdf_path):\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_transcript = \"\"\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "\n",
    "        for block in blocks:\n",
    "            text = block[4].strip()\n",
    "            if text:\n",
    "                if block[0] < 200 and block[3] > 12:  # Check for headings or dialogue lines\n",
    "                    extracted_transcript += f\"\\n\\n{text}\\n\"\n",
    "                else:\n",
    "                    extracted_transcript += f\"{text} \"\n",
    "\n",
    "    return extracted_transcript\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Directory : d:\\Kent\\University Of Kent UK\\Projects\\Disso\\Screening-LLM\\LLM2-Prompting\n",
      "Analyzing audio...\n"
     ]
    }
   ],
   "source": [
    "# Get the directory containing the script\n",
    "script_directory = os.getcwd()\n",
    "print(\"Script Directory : \"+script_directory)\n",
    "# Navigate one folder up\n",
    "one_folder_up = os.path.dirname(script_directory)\n",
    "# Construct the path to the .env file in the parent folder\n",
    "parent_folder_path = os.path.dirname(os.getcwd())\n",
    "dotenv_path = os.path.join(parent_folder_path, \".env\")\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path)\n",
    "analyzer = HumeSentimentAnalyzer(os.getenv(\"HUME_API_KEY\"))\n",
    "result = analyzer.analyze_audio(os.path.join(script_directory, \"interview_audio.wav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotions': {'Admiration': 0.026119697839021683, 'Adoration': 0.003861038014292717, 'Aesthetic Appreciation': 0.035107363015413284, 'Amusement': 0.03813358396291733, 'Anger': 0.00038087990833446383, 'Annoyance': 0.010568605735898018, 'Anxiety': 0.01789218746125698, 'Awe': 0.012385101988911629, 'Awkwardness': 0.010339461266994476, 'Boredom': 0.022676732391119003, 'Calmness': 0.059521790593862534, 'Concentration': 0.3941130042076111, 'Confusion': 0.041417255997657776, 'Contemplation': 0.3485284149646759, 'Contempt': 0.010550647974014282, 'Contentment': 0.02668710984289646, 'Craving': 0.008198815397918224, 'Desire': 0.00071975082391873, 'Determination': 0.44453132152557373, 'Disappointment': 0.008252736181020737, 'Disapproval': 0.003823148086667061, 'Disgust': 0.000525407784152776, 'Distress': 0.004626619163900614, 'Doubt': 0.08696653693914413, 'Ecstasy': 0.0022196820937097073, 'Embarrassment': 0.0017864009132608771, 'Empathic Pain': 0.0033241109922528267, 'Enthusiasm': 0.4430784285068512, 'Entrancement': 0.023503456264734268, 'Envy': 0.0026425861287862062, 'Excitement': 0.13492001593112946, 'Fear': 0.004691607318818569, 'Gratitude': 0.006802787072956562, 'Guilt': 0.0008118593250401318, 'Horror': 0.00019832693214993924, 'Interest': 0.5725105404853821, 'Joy': 0.012980169616639614, 'Love': 0.001052350620739162, 'Nostalgia': 0.002565887523815036, 'Pain': 0.00069716403959319, 'Pride': 0.029314959421753883, 'Realization': 0.05947358161211014, 'Relief': 0.0030791121535003185, 'Romance': 0.0004746409540530294, 'Sadness': 0.0015676087932661176, 'Sarcasm': 0.019213156774640083, 'Satisfaction': 0.0527133010327816, 'Shame': 0.001531878369860351, 'Surprise (negative)': 0.005111930426210165, 'Surprise (positive)': 0.02895338647067547, 'Sympathy': 0.0037859452422708273, 'Tiredness': 0.009146211668848991, 'Triumph': 0.03132116422057152}, 'sentiments': {'1': 0.0022532460279762745, '2': 0.005031921900808811, '3': 0.007615720387548208, '4': 0.020007017999887466, '5': 0.21344728767871857, '6': 0.24443399906158447, '7': 0.2450898289680481, '8': 0.19101573526859283, '9': 0.07798416912555695}, 'toxicity': {'identity_hate': 0.0034884349443018436, 'insult': 0.00170091912150383, 'obscene': 0.001942797563970089, 'severe_toxic': 0.00243135797791183, 'threat': 0.003274350194260478, 'toxic': 0.004167427308857441}, 'transcription': \"Hello? I'm sure. I have total of six months of experience with machine learning opera in the University of Ken. Right now mainly working on nam and ponder, nam numpy to analyze image information and partners us to extract data from Csv. Sure. So one of the projects that I worked on was classifying the mint dataset. Of images. Yeah. Basically, it was done. I extracted the training set from the main data used Cnn algorithm to find out features from the images, and then use the test set to edit predict the output of the model, and it worked. Yes. Seem to be the reach this days. I am. Trying or will be interested in working on, fine tuning L model to my specific needs, as a chatbot bot, but I have not thought of what the chatbot will do.\"}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing candidate...\n",
      "LLM-2 Recommendation: Based on the interview transcript, sentiment analysis, and job requirements, here's my evaluation of the candidate for the Entry-Level Machine Learning Engineer position at G-Research:\n",
      "\n",
      "1. Accuracy of Candidate's Answers: 65%\n",
      "The candidate's responses show a basic understanding of machine learning concepts, but lack depth and specificity expected for this role.\n",
      "\n",
      "2. Evaluation of Candidate Alignment:\n",
      "\n",
      "Technical Skills: \n",
      "The candidate demonstrates basic knowledge of Python libraries like NumPy and Pandas, which is a good starting point. However, they don't mention experience with PyTorch, which is specifically desired for this role. Their project experience is limited to basic CNN implementation on the MNIST dataset, which is a standard beginner project.\n",
      "\n",
      "Project Experience:\n",
      "The candidate's project experience is limited and basic. While they have worked on image classification using CNNs, they don't demonstrate experience with more advanced techniques or large-scale data processing, which are key requirements for this role.\n",
      "\n",
      "Soft Skills:\n",
      "The candidate's communication skills appear to be adequate, but not exceptional. They provide brief answers without elaborating much on technical details or challenges faced.\n",
      "\n",
      "Cultural Fit:\n",
      "There's not enough information to make a strong judgment on cultural fit. The candidate shows some interest in current trends (mentioning LLMs), which aligns with the company's focus on cutting-edge research.\n",
      "\n",
      "3. Sentiment Analysis:\n",
      "The sentiment analysis shows high levels of Interest (0.57), Enthusiasm (0.44), and Determination (0.44), which are positive indicators. However, there's also a notable level of Doubt (0.09), which might indicate lack of confidence in some areas.\n",
      "\n",
      "4. Toxicity Scores:\n",
      "The toxicity scores are very low across all categories, indicating professional and appropriate communication.\n",
      "\n",
      "5. Recommendation: Consider for Further Evaluation\n",
      "\n",
      "Reasoning:\n",
      "While the candidate shows some promise and enthusiasm for machine learning, their current skill level and project experience fall short of the requirements for this position at G-Research. \n",
      "\n",
      "Positives:\n",
      "- Shows interest and enthusiasm for the field\n",
      "- Has basic knowledge of Python libraries like NumPy and Pandas\n",
      "- Has completed a basic machine learning project (MNIST classification)\n",
      "- Demonstrates awareness of current trends (mentioning LLMs)\n",
      "\n",
      "Areas of Concern:\n",
      "- Lacks experience with PyTorch, which is specifically\n"
     ]
    }
   ],
   "source": [
    "# --- Call LLM-2 for Candidate Analysis ---\n",
    "print(\"Analyzing candidate...\")\n",
    "llm2_recommendation = analyze_candidate(\n",
    "    job_title=job_role,\n",
    "    experience_level=candidate_skill,\n",
    "    job_description=role_description,\n",
    "    interview_transcript=transcript,\n",
    "    cv=cv,\n",
    "    analyzer_output=result\n",
    ")\n",
    "\n",
    "print(f\"LLM-2 Recommendation: {llm2_recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(claude.chat_with_history_doc(input()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
