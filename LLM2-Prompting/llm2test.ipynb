{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnthropicWrapper import ClaudeChat\n",
    "from AnthropicWrapper import Utilities\n",
    "from joblib import load\n",
    "import os\n",
    "import fitz\n",
    "import numpy as np\n",
    "from hume_analysis import HumeSentimentAnalyzer\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM-2 Configuration ---\n",
    "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
    "llm2_system_prompt = \"\"\"\n",
    "You are a seasoned hiring manager evaluating a candidate for a [Job Title] position at [Company Name]. The candidate has [Experience Level] experience in the field. You have access to the candidate's CV, the transcript of their interview, and sentiment analysis data from Hume.ai.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. **Understand the Job Requirements:** Carefully analyze the [Job Description] provided and identify the key skills, experience, and qualifications required for success in this role.\n",
    "\n",
    "2. **Evaluate Candidate Alignment:** Assess how well the candidate's qualifications and experience align with the identified job requirements. \n",
    "    * **Technical Skills:**  Does the candidate demonstrate the necessary technical skills, including specific software, tools, and frameworks mentioned in the job description? \n",
    "    * **Project Experience:**  Are the candidate's projects relevant to the role and demonstrate the required level of complexity and problem-solving abilities?\n",
    "    * **Soft Skills:**  Does the candidate possess the necessary communication, collaboration, and problem-solving skills?\n",
    "    * **Cultural Fit:**  Does the candidate seem to align with the company's values and work environment as described in the job description?\n",
    "\n",
    "3. **Analyze Sentiment Data:**  Use the sentiment analysis data from Hume.ai to understand the candidate's emotional state during the interview.  Does their emotional response indicate confidence, enthusiasm, or any potential issues?\n",
    "\n",
    "4. **Analyze Toxicity Scores:**  Does the candidate's communication exhibit any signs of toxicity, unprofessionalism, or potentially problematic behavior?\n",
    "\n",
    "5. **Provide a Recommendation:** \n",
    "    * **Strong Candidate:** The candidate demonstrates strong technical skills, relevant experience, and a positive attitude. Recommend moving them forward in the interview process.\n",
    "    * **Consider for Further Evaluation:** The candidate has potential, but their technical skills or project experience need further investigation. Recommend additional interviews or assessments. \n",
    "    * **Not a Fit:** The candidate lacks the necessary technical skills or experience, or their communication/attitude was not compelling. Recommend not moving forward with this candidate.\n",
    "\n",
    "**Explain your reasoning:** Provide specific evidence from the CV, transcript, and sentiment analysis data to support your recommendation. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_description = \"\"\"\n",
    "Do you want to tackle the biggest questions in finance with near infinite compute power at your fingertips?\n",
    "\n",
    "G-Research is a leading quantitative research and technology firm, with offices in London and Dallas. We are proud to employ some of the best people in their field and to nurture their talent in a dynamic, flexible and highly stimulating culture where world-beating ideas are cultivated and rewarded.\n",
    "\n",
    "This is a role based in our new Soho Place office - opened in 2023 - in the heart of Central London and home to our Research Lab.\n",
    "\n",
    "The role\n",
    "\n",
    "We are looking for exceptional machine learning engineers to work alongside our quantitative researchers on cutting-edge machine learning problems.\n",
    "\n",
    "As a member of the Core Technical Machine Learning team, you will be engaged in a mixture of individual and collaborative work to tackle some of the toughest research questions.\n",
    "\n",
    "In this role, you will use a combination of off-the-shelf tools and custom solutions written from scratch to drive the latest advances in quantitative research.\n",
    "\n",
    "Past projects have included:\n",
    "\n",
    "Implementing ideas from a recently published research paper\n",
    "Writing custom libraries for efficiently training on petabytes of data\n",
    "Reducing model training times by hand optimising machine learning operations\n",
    "Profiling custom ML architectures to identify performance bottlenecks\n",
    "Evaluating the latest hardware and software in the machine learning ecosystem\n",
    "Who are we looking for?\n",
    "\n",
    "Candidates will be comfortable working both independently and in small teams on a variety of engineering challenges, with a particular focus on machine learning and scientific computing.\n",
    "\n",
    "The ideal candidate will have the following skills and experience:\n",
    "\n",
    "Either a post-graduate degree in machine learning or a related discipline, or commercial experience working on machine learning models at scale. We will also consider exceptional candidates with a proven record of success in online data science competitions, such as Kaggle\n",
    "Strong object-oriented programming skills and experience working with Python, PyTorch and NumPy are desirable\n",
    "Experience in one or more advanced optimisation methods, modern ML techniques, HPC, profiling, model inference; you dont need to have all of the above\n",
    "Excellent ML reasoning and communication skills are crucial: off-the-shelf methods dont always work on our data so you will need to understand how to develop your own models in a collaborative environment working in a team with complementary skills\n",
    "Finance experience is not necessary for this role and candidates from non-financial backgrounds are encouraged to apply.\n",
    "\n",
    "Why should you apply?\n",
    "\n",
    "Highly competitive compensation plus annual discretionary bonus\n",
    "Lunch provided (via Just Eat for Business) and dedicated barista bar\n",
    "35 days annual leave\n",
    "9 percent company pension contributions\n",
    "Informal dress code and excellent work/life balance\n",
    "Comprehensive healthcare and life assurance\n",
    "Cycle-to-work scheme\n",
    "Monthly company events\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function for LLM-2 analysis ---\n",
    "def analyze_candidate(job_title, experience_level, job_description, interview_transcript, cv, analyzer_output):\n",
    "    \"\"\"\n",
    "    Analyzes a candidate's suitability based on the provided data.\n",
    "\n",
    "    Args:\n",
    "        job_title (str): The title of the job.\n",
    "        experience_level (str): The candidate's experience level.\n",
    "        job_description (str): The text of the job description.\n",
    "        interview_transcript (str): The transcript of the interview.\n",
    "        cv (str): The candidate's CV.\n",
    "        sentiment_data (dict): Sentiment data from Hume.ai.\n",
    "        toxicity_data (dict): Toxicity data from Hume.ai.\n",
    "\n",
    "    Returns:\n",
    "        str: The recommendation and reasoning from LLM-2.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a prompt with placeholders for dynamic values\n",
    "    llm2_prompt = llm2_system_prompt.replace(\"[Job Title]\", job_title)\n",
    "    llm2_prompt = llm2_prompt.replace(\"[Experience Level]\", experience_level)\n",
    "    llm2_prompt = llm2_prompt.replace(\"[Job Description]\", job_description)\n",
    "    \n",
    "     # --- Preprocess Sentiment Data ---\n",
    "    positive_emotions = [\"Joy\", \"Enthusiasm\", \"Excitement\", \"Pride\", \"Satisfaction\", \"Triumph\", \"Surprise (positive)\", \"Contentment\", \"Ecstasy\", \"Gratitude\", \"Love\", \"Relief\"]\n",
    "    negative_emotions = [\"Anger\", \"Annoyance\", \"Anxiety\", \"Boredom\", \"Contempt\", \"Disappointment\", \"Disapproval\", \"Disgust\", \"Distress\", \"Fear\", \"Guilt\", \"Horror\", \"Pain\", \"Sadness\", \"Shame\", \"Surprise (negative)\", \"Sympathy\", \"Tiredness\"]\n",
    "\n",
    "    positive_sentiment_score = np.mean([analyzer_output[\"emotions\"].get(emotion, 0) for emotion in positive_emotions])\n",
    "    negative_sentiment_score = np.mean([analyzer_output[\"emotions\"].get(emotion, 0) for emotion in negative_emotions])\n",
    "\n",
    "    # --- Preprocess Toxicity Data ---\n",
    "    toxicity_weights = {\"severe_toxic\": 0.3, \"threat\": 0.2, \"toxic\": 0.15, \"identity_hate\": 0.1, \"insult\": 0.1, \"obscene\": 0.1}\n",
    "    overall_toxicity_score = np.sum([analyzer_output[\"toxicity\"].get(category, 0) * toxicity_weights[category] for category in toxicity_weights])\n",
    "    toxicity_level = \"Low\" if overall_toxicity_score < 0.01 else \"Moderate\" if overall_toxicity_score < 0.05 else \"High\"\n",
    "\n",
    "    # ---  Preprocess Sentiment Scores (1-9) ---\n",
    "    sentiment_scores = analyzer_output[\"sentiments\"] \n",
    "    sentiment_scores = analyzer_output[\"sentiments\"]\n",
    "    overall_sentiment_score = sum(float(key) * float(value) for key, value in sentiment_scores.items())\n",
    "    overall_sentiment_level = \"Highly Negative\" if overall_sentiment_score < 3 else \"Negative\" if overall_sentiment_score < 6 else \"Neutral\" if overall_sentiment_score < 7 else \"Positive\" if overall_sentiment_score < 8 else \"Highly Positive\"\n",
    "    \n",
    "    # --- Add Preprocessed Data to the Analyzer Output ---\n",
    "    analyzer_output[\"Preprocessed Sentiment\"] = {\n",
    "        \"Positive Sentiment\": positive_sentiment_score,\n",
    "        \"Negative Sentiment\": negative_sentiment_score,\n",
    "        \"Overall Sentiment Score (1-9)\": overall_sentiment_score,\n",
    "        \"Overall Sentiment Level\": overall_sentiment_level\n",
    "    }\n",
    "\n",
    "    analyzer_output[\"Preprocessed Toxicity\"] = {\n",
    "        \"Overall Toxicity Score\": overall_toxicity_score,\n",
    "        \"Toxicity Level\": toxicity_level\n",
    "    }\n",
    "\n",
    "    # --- Prepare the data for LLM-2 ---\n",
    "    analysis_data = {\n",
    "        \"Interview Transcript\": interview_transcript,\n",
    "        \"CV\": cv,\n",
    "        \"Analyzer Output\": analyzer_output  # Pass the entire dictionary\n",
    "    }\n",
    "\n",
    "    llm2_prompt += \"\\n\\nHere is the data for your analysis:\\n\"\n",
    "    llm2_prompt += \"\\n\".join(f\"{key}: {value}\" for key, value in analysis_data.items())\n",
    "    global claude\n",
    "    claude = ClaudeChat(chat_model_name, llm2_prompt)\n",
    "    return claude.chat(\"Please Execute the system prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-3-5-sonnet-20240620\"\n",
    "job_role = \"Machine Learning Engineer\"\n",
    "candidate_skill = \"Entry-Level\"\n",
    "utilities = Utilities()\n",
    "transcript_path = \"conversation.pdf\"\n",
    "transcript = utilities.process_pdf(transcript_path)\n",
    "pdf_path = r\"D:\\Hidden Desktop\\OneDrive\\Cross Device\\Jobs Applications\\Graduating\\CV.pdf\"\n",
    "cv = utilities.process_pdf(transcript_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef extract_transcript_from_pdf(pdf_path):\\n\\n    doc = fitz.open(pdf_path)\\n    extracted_transcript = \"\"\\n\\n    for page_num in range(doc.page_count):\\n        page = doc[page_num]\\n        blocks = page.get_text(\"blocks\")\\n\\n        for block in blocks:\\n            text = block[4].strip()\\n            if text:\\n                if block[0] < 200 and block[3] > 12:  # Check for headings or dialogue lines\\n                    extracted_transcript += f\"\\n\\n{text}\\n\"\\n                else:\\n                    extracted_transcript += f\"{text} \"\\n\\n    return extracted_transcript\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def extract_transcript_from_pdf(pdf_path):\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_transcript = \"\"\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "\n",
    "        for block in blocks:\n",
    "            text = block[4].strip()\n",
    "            if text:\n",
    "                if block[0] < 200 and block[3] > 12:  # Check for headings or dialogue lines\n",
    "                    extracted_transcript += f\"\\n\\n{text}\\n\"\n",
    "                else:\n",
    "                    extracted_transcript += f\"{text} \"\n",
    "\n",
    "    return extracted_transcript\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Directory : d:\\Kent\\University Of Kent UK\\Projects\\Disso\\Screening-LLM\\LLM2-Prompting\n",
      "Analyzing audio...\n"
     ]
    }
   ],
   "source": [
    "# Get the directory containing the script\n",
    "script_directory = os.getcwd()\n",
    "print(\"Script Directory : \"+script_directory)\n",
    "# Navigate one folder up\n",
    "one_folder_up = os.path.dirname(script_directory)\n",
    "# Construct the path to the .env file in the parent folder\n",
    "parent_folder_path = os.path.dirname(os.getcwd())\n",
    "dotenv_path = os.path.join(parent_folder_path, \".env\")\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path)\n",
    "analyzer = HumeSentimentAnalyzer(os.getenv(\"HUME_API_KEY\"))\n",
    "result = analyzer.analyze_audio(os.path.join(script_directory, \"interview_audio.wav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotions': {'Admiration': 0.013154713436961174, 'Adoration': 0.005036264657974243, 'Aesthetic Appreciation': 0.02096581645309925, 'Amusement': 0.038279544562101364, 'Anger': 0.00032193015795201063, 'Annoyance': 0.00515311723574996, 'Anxiety': 0.015116434544324875, 'Awe': 0.004606128670275211, 'Awkwardness': 0.0266299806535244, 'Boredom': 0.032327186316251755, 'Calmness': 0.3473110795021057, 'Concentration': 0.2725161612033844, 'Confusion': 0.02289200946688652, 'Contemplation': 0.1169968917965889, 'Contempt': 0.01220963429659605, 'Contentment': 0.09862833470106125, 'Craving': 0.005860886070877314, 'Desire': 0.002857029438018799, 'Determination': 0.13869863748550415, 'Disappointment': 0.001249863300472498, 'Disapproval': 0.00198471755720675, 'Disgust': 0.0005089972401037812, 'Distress': 0.0017954296199604869, 'Doubt': 0.02944629080593586, 'Ecstasy': 0.003593969624489546, 'Embarrassment': 0.0014260212192311883, 'Empathic Pain': 0.004238705150783062, 'Enthusiasm': 0.3247373402118683, 'Entrancement': 0.01422841101884842, 'Envy': 0.0008931924821808934, 'Excitement': 0.12892471253871918, 'Fear': 0.004100775811821222, 'Gratitude': 0.011588839814066887, 'Guilt': 0.00044759982847608626, 'Horror': 0.00022001679462846369, 'Interest': 0.6780880689620972, 'Joy': 0.03051365166902542, 'Love': 0.0037222332321107388, 'Nostalgia': 0.0015311534516513348, 'Pain': 0.0003198323829565197, 'Pride': 0.012678961269557476, 'Realization': 0.02276882529258728, 'Relief': 0.01432751677930355, 'Romance': 0.0022724654991179705, 'Sadness': 0.00023499377130065113, 'Sarcasm': 0.007394158281385899, 'Satisfaction': 0.12197037786245346, 'Shame': 0.0006897133425809443, 'Surprise (negative)': 0.002988350810483098, 'Surprise (positive)': 0.03629360347986221, 'Sympathy': 0.008132639341056347, 'Tiredness': 0.0022081199567764997, 'Triumph': 0.019593924283981323}, 'sentiments': {'1': 0.0007990009617060423, '2': 0.0012647139374166727, '3': 0.0021771506872028112, '4': 0.007528484333306551, '5': 0.22259631752967834, '6': 0.28936120867729187, '7': 0.21417443454265594, '8': 0.15961700677871704, '9': 0.08622882515192032}, 'toxicity': {'identity_hate': 0.0028074539732187986, 'insult': 0.0018535471754148602, 'obscene': 0.002118476666510105, 'severe_toxic': 0.0020371179562062025, 'threat': 0.0031466283835470676, 'toxic': 0.006835162173956633}, 'transcription': 'Hello. Sure. This is a quick test to see if the audio file is pending or not. Yeah. See you it. Back.'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing candidate...\n",
      "LLM-2 Recommendation: Based on the provided information, here's my evaluation of the candidate for the Entry-Level Machine Learning Engineer position at G-Research:\n",
      "\n",
      "1. Understanding the Job Requirements:\n",
      "The role requires strong machine learning skills, experience with Python, PyTorch, and NumPy, and the ability to work on complex ML problems. The ideal candidate should have a post-graduate degree in ML or related field, or commercial experience with ML at scale. Strong object-oriented programming skills and experience with advanced optimization methods are desirable.\n",
      "\n",
      "2. Evaluating Candidate Alignment:\n",
      "\n",
      "Technical Skills: \n",
      "The candidate demonstrates strong experience with NumPy (3 years) and has worked on complex ML projects, including developing a fine-tuned LLM BERT model at NVIDIA. This aligns well with the required technical skills.\n",
      "\n",
      "Project Experience: \n",
      "The candidate's work on the BERT model at NVIDIA, including handling challenges like image-to-text conversion, shows relevant and complex project experience. Their approach to financial data modeling using LSTM for the FTSE 100 index demonstrates an understanding of ML applications in finance.\n",
      "\n",
      "Soft Skills: \n",
      "The candidate communicates their experiences clearly and shows problem-solving abilities in describing how they overcame challenges.\n",
      "\n",
      "Cultural Fit: \n",
      "The candidate's experience with cutting-edge ML problems and their approach to tackling complex issues align well with G-Research's focus on innovative quantitative research.\n",
      "\n",
      "3. Sentiment Analysis:\n",
      "The sentiment analysis shows high levels of Interest (0.678), Calmness (0.347), and Concentration (0.273). This suggests the candidate was engaged and composed during the interview, which is positive.\n",
      "\n",
      "4. Toxicity Scores:\n",
      "The toxicity scores are very low across all categories, with an overall toxicity score of 0.00294 (Low). This indicates professional and appropriate communication.\n",
      "\n",
      "5. Recommendation: Strong Candidate\n",
      "\n",
      "I recommend moving forward with this candidate in the interview process. The candidate demonstrates strong technical skills and relevant experience that align well with the job requirements. Their work at NVIDIA on complex ML problems, particularly with BERT models and image processing, is directly relevant to the role. \n",
      "\n",
      "The candidate's ability to articulate their approach to financial data modeling shows an understanding of ML applications in finance, which is crucial for G-Research. Their experience with NumPy and their understanding of advanced ML concepts\n"
     ]
    }
   ],
   "source": [
    "# --- Call LLM-2 for Candidate Analysis ---\n",
    "print(\"Analyzing candidate...\")\n",
    "llm2_recommendation = analyze_candidate(\n",
    "    job_title=job_role,\n",
    "    experience_level=candidate_skill,\n",
    "    job_description=role_description,\n",
    "    interview_transcript=transcript,\n",
    "    cv=cv,\n",
    "    analyzer_output=result\n",
    ")\n",
    "\n",
    "print(f\"LLM-2 Recommendation: {llm2_recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(claude.chat_with_history_doc(input()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
