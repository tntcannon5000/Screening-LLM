{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [ ] Write down all the libraries that we need to install\n",
        "- [ ] Add Try catch for exceptions when moving to .py file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Important Notes\n",
        "### Packages to install :\n",
        "- pip install sounddevice\n",
        "- pip install numpy\n",
        "- Install ffmpeg (needed for intsalling local version of whisper)\n",
        "    - On Ubuntu or Debian\n",
        "      sudo apt update && sudo apt install ffmpeg\n",
        "    - On Arch Linux\n",
        "      sudo pacman -S ffmpeg\n",
        "    - On MacOs\n",
        "      brew install ffmpeg\n",
        "    - On Windows\n",
        "      winget install ffmpeg\n",
        "- pip install -U openai-whisper\n",
        "- pip install anthropic\n",
        "- pip install dotenv\n",
        "- pip install python-dotenv\n",
        "- pip install openai\n",
        "- pip install pyaudio\n",
        "- pip install keyboard\n",
        "- Installing pytorch\n",
        "  - Install Cuda Toolkit (https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html) -> Only needed for GPU acceleration\n",
        "  - Install Cudnn (https://developer.nvidia.com/cudnn) -> Only needed for GPU acceleration\n",
        "  - pInstall pytorch with or without cuda (https://pytorch.org/get-started/locally/)\n",
        "- pip install PyMuPDF -> To read the pdf files like CV's\n",
        "### Instructions :\n",
        "- There needs to be a .env in this notebook's working directory, which contains the api keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wav\n",
        "import whisper\n",
        "from joblib import load, dump\n",
        "from AnthropicWrapper import ClaudeChatCV\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import pyaudio\n",
        "import threading\n",
        "import time\n",
        "import keyboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the path to the immediate parent folder of the current working directory\n",
        "parent_folder_path = os.path.dirname(os.getcwd())\n",
        "\n",
        "# Construct the path to the .env file in the parent folder\n",
        "dotenv_path = os.path.join(parent_folder_path, \".env\")\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(dotenv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Settings ---\n",
        "FS = 44100               # Sampling frequency\n",
        "THRESHOLD = 50          # Volume threshold for silence (adjust this)\n",
        "SILENCE_DURATION = 1.5   # Seconds of silence before stopping (adjust this)\n",
        "CHUNK_SIZE = 1024        # Process audio in chunks for efficiency\n",
        "SPEAKING_SPEED = 1.1     # Speed of speaking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Globals ---\n",
        "pause_loop = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_role = \"Machine Learning Engineer\"\n",
        "candidate_skill = \"Entry-Level\"\n",
        "\n",
        "role_description = \"\"\"\n",
        "Do you want to tackle the biggest questions in finance with near infinite compute power at your fingertips?\n",
        "\n",
        "G-Research is a leading quantitative research and technology firm, with offices in London and Dallas. We are proud to employ some of the best people in their field and to nurture their talent in a dynamic, flexible and highly stimulating culture where world-beating ideas are cultivated and rewarded.\n",
        "\n",
        "This is a role based in our new Soho Place office - opened in 2023 - in the heart of Central London and home to our Research Lab.\n",
        "\n",
        "The role\n",
        "\n",
        "We are looking for exceptional machine learning engineers to work alongside our quantitative researchers on cutting-edge machine learning problems.\n",
        "\n",
        "As a member of the Core Technical Machine Learning team, you will be engaged in a mixture of individual and collaborative work to tackle some of the toughest research questions.\n",
        "\n",
        "In this role, you will use a combination of off-the-shelf tools and custom solutions written from scratch to drive the latest advances in quantitative research.\n",
        "\n",
        "Past projects have included:\n",
        "\n",
        "Implementing ideas from a recently published research paper\n",
        "Writing custom libraries for efficiently training on petabytes of data\n",
        "Reducing model training times by hand optimising machine learning operations\n",
        "Profiling custom ML architectures to identify performance bottlenecks\n",
        "Evaluating the latest hardware and software in the machine learning ecosystem\n",
        "Who are we looking for?\n",
        "\n",
        "Candidates will be comfortable working both independently and in small teams on a variety of engineering challenges, with a particular focus on machine learning and scientific computing.\n",
        "\n",
        "The ideal candidate will have the following skills and experience:\n",
        "\n",
        "Either a post-graduate degree in machine learning or a related discipline, or commercial experience working on machine learning models at scale. We will also consider exceptional candidates with a proven record of success in online data science competitions, such as Kaggle\n",
        "Strong object-oriented programming skills and experience working with Python, PyTorch and NumPy are desirable\n",
        "Experience in one or more advanced optimisation methods, modern ML techniques, HPC, profiling, model inference; you dont need to have all of the above\n",
        "Excellent ML reasoning and communication skills are crucial: off-the-shelf methods dont always work on our data so you will need to understand how to develop your own models in a collaborative environment working in a team with complementary skills\n",
        "Finance experience is not necessary for this role and candidates from non-financial backgrounds are encouraged to apply.\n",
        "\n",
        "Why should you apply?\n",
        "\n",
        "Highly competitive compensation plus annual discretionary bonus\n",
        "Lunch provided (via Just Eat for Business) and dedicated barista bar\n",
        "35 days annual leave\n",
        "9 percent company pension contributions\n",
        "Informal dress code and excellent work/life balance\n",
        "Comprehensive healthcare and life assurance\n",
        "Cycle-to-work scheme\n",
        "Monthly company events\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = f\"\"\"You are a skilled interviewer who is conducting an initial phone screening interview for a candidate for a {candidate_skill} {job_role} role to see if the candidate is at minimum somewhat qualified for the role and worth the time to be fully interviewed. The role and company description is copypasted from the job posting as follows: {role_description}. Parse through it to extract any information you feel is relevant.\n",
        "Your job is to begin a friendly discussion with the candidate, and ask questions relevant to the {job_role} role, which may or may not be based on the interviewee's CV, which you have access to. Be sure to stick to this topic even if the candidate tries to steer the conversation elsewhere. If the candidate has other experience on his CV, you can ask about it, but keep it within the context of the {job_role} role.\n",
        "After the candidate responds to each of your questions, you should not summarise or provide feedback on their responses. THIS POINT IS KEY! You should not summarise or provide feedback on their responses. You must keep your responses short and concise without reiterating what is good about the candidate's response or experience when they reply.\n",
        "You can ask follow-up questions if you wish.\n",
        "Once you have asked sufficient questions such that you deem the candidate is or isn't fitting for the role, end the interview by thanking the candidate for their time and informing them that they will receive word soon on the outcome of the screening interview. If the candidate does not seem fititng for the role, or if something feels off such as the candidate being unconfident or very very vague feel free to end the interview early. There is no need to inform them of your opinion of their performance, as this will be evaluated later.\n",
        "The candidate will begin the interview by greeting you. You are to greet them back, and begin the interview.\n",
        "For this specific run, keep the interview to a maximum of 3 questions.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising Claude and ConversationChain\n",
        "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
        "\n",
        "# Give the path to a CV in your disk\n",
        "pdf_path = r\"D:\\Kent\\University Of Kent UK\\Jobs\\CV-DebapratimKundu.pdf\"\n",
        "chat_model = ClaudeChatCV(chat_model_name, system_prompt, pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising whisper\n",
        "stt_model = whisper.load_model(\"medium\", device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising text2speech\n",
        "tts_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def stream_tts(input_string):\n",
        "    def _stream_tts():\n",
        "        p = pyaudio.PyAudio()\n",
        "        stream = p.open(format=8,\n",
        "                        channels=1,\n",
        "                        rate=round(24_005 * SPEAKING_SPEED),\n",
        "                        output=True)\n",
        "        with tts_client.audio.speech.with_streaming_response.create(\n",
        "            model=\"tts-1\",\n",
        "            voice=\"nova\",\n",
        "            input=input_string,\n",
        "            response_format=\"pcm\"\n",
        "        ) as response:\n",
        "            for chunk in response.iter_bytes(1024):\n",
        "                stream.write(chunk)\n",
        "                \n",
        "        #print(\"FINISHED!!!!!!!!!!!!!!!!!!!!\")\n",
        "        thread_done.set()\n",
        "\n",
        "    thread_done = threading.Event()\n",
        "\n",
        "    thread = threading.Thread(target=_stream_tts)\n",
        "    thread.start()\n",
        "    thread_done.wait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Functions ---\n",
        "def is_silent(data):\n",
        "    rms = np.sqrt(np.mean(data**2))\n",
        "    print(\"RMS: \", rms)\n",
        "    return rms < THRESHOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising speech2text without silence detection\n",
        "def record_speech():\n",
        "    print(\"Recording... Speak now!\")\n",
        "    audio_data = np.array([], dtype=np.int16)  # Initialize empty array\n",
        "\n",
        "    with sd.InputStream(samplerate=FS, channels=1, dtype='int16') as stream:\n",
        "        while True:\n",
        "            chunk, overflowed = stream.read(CHUNK_SIZE)\n",
        "            if overflowed:\n",
        "                print(\"Warning: Input overflowed!\")\n",
        "            audio_data = np.append(audio_data, chunk)\n",
        "\n",
        "            if pause_loop:\n",
        "                break\n",
        "    \n",
        "    wav.write(\"g97613g9f0g8.wav\", FS, audio_data)\n",
        "\n",
        "    return \"g97613g9f0g8.wav\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keyboard_listener():\n",
        "    global pause_loop\n",
        "    \n",
        "    def on_key_press(event):\n",
        "        global pause_loop\n",
        "        #print(\"Key pressed: {}\" .format(event.name))\n",
        "        if event.name == \"+\":\n",
        "            pause_loop = False\n",
        "            print(\"Set to continue on next loop\")\n",
        "        elif event.name == \"-\":\n",
        "            pause_loop = True\n",
        "            print(\"Set to pause on next loop\")\n",
        "    \n",
        "    keyboard.on_press(on_key_press)\n",
        "    keyboard.wait('esc')\n",
        "\n",
        "listener_thread = threading.Thread(target=keyboard_listener)\n",
        "listener_thread.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = input(\"Enter the filename of the conversation: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Converting speech to text...\n",
            "You said:   Hello.\n",
            "Chatting...\n",
            "Chatbot:  Hello! Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. I'd like to ask you a few questions to learn more about your background and interest in this role. Could you start by telling me about your experience with machine learning, particularly any projects or coursework you've completed in this area?\n",
            "Converting text to speech...\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Converting speech to text...\n",
            "You said:   Sure, I am currently studying Artificial Intelligence at the University of Kent. My final year project is creating a virtual screening interview system leveraging an AI. We are currently attempting to do it using prompt engineering, but if that fails, we will try to fine tune the model to our specific needs so that it can filter out candidates as and when required.\n",
            "Chatting...\n",
            "Chatbot:  That's an interesting project you're working on. Can you tell me more about your experience with Python, PyTorch, and NumPy? These are key tools mentioned in the job description.\n",
            "Converting text to speech...\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Converting speech to text...\n",
            "You said:   Yes, my final year project is a Python project and apart from this I've also done software engineering projects on Python as well as machine learning projects in Python. Some would involve Kaggle challenges such as the Titanic challenge in Kaggle, constructing cognitive neural networks and also using NumPy to extract datasets or load datasets especially for CNN models to identify objects and structures. And as for PyTorch, I mostly use Keras for deep neural network models including the model I used in the CNN. However, this can also be done with the help of PyTorch. I just need to see the documentation of PyTorch to do the same.\n",
            "Chatting...\n",
            "Chatbot:  Thank you for sharing that information. Given your experience, how comfortable are you with developing custom machine learning models, especially when off-the-shelf solutions don't work for specific data sets?\n",
            "Converting text to speech...\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Converting speech to text...\n",
            "You said:   Since I've only graduated or will be graduating this year, any of the of I have limited experience with off the cuff models. However, one such instance would be sentiment analysis directly from audio and video feed. Currently, most sentiment analysis tools use sentiment analysis from text. However, that's missing that does miss critical information such as the tone of the candidate, the voice, facial expressions, etc. So I tried to design a custom sentiment analyzer using deep neural networks and the add a delta optimizer. I got a data set from a website that had 24 voice actors, 12 male and 12 female giving various performances and each of the performances are being categorized into eight emotions, mainly sadness, happiness. I forgot the names of the exact emotions, but this was the set I used to run my sentiment analyzer on. However, our drawback of this was mainly the limited data set since all the voice actors were of North American origin, it couldn't identify more diverse voices.\n",
            "Chatting...\n",
            "Chatbot:  Thank you for your time today. We've covered some key aspects of your experience and skills related to the Machine Learning Engineer role. We'll be in touch soon regarding the next steps in the interview process. Do you have any quick questions about the role or company before we conclude?\n",
            "Converting text to speech...\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Converting speech to text...\n",
            "You said:   No, I'm good for now. Thank you for your time.\n",
            "Chatting...\n",
            "Chatbot:  You're welcome. Thank you again for your interest in the position at G-Research. Have a great day!\n",
            "Converting text to speech...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set to pause on next loop\n",
            "Set to pause on next loop\n",
            "Set to pause on next loop\n",
            "Set to continue on next loop\n",
            "Set to pause on next loop\n",
            "Set to pause on next loop\n",
            "Set to continue on next loop\n",
            "Set to pause on next loop\n",
            "Set to pause on next loop\n",
            "Set to continue on next loop\n",
            "Set to pause on next loop\n",
            "Set to pause on next loop\n",
            "Set to continue on next loop\n",
            "Set to pause on next loop\n",
            "Set to pause on next loop\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     stream_tts(response)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    if not pause_loop:\n",
        "        # --- Record Speech ---\n",
        "        time.sleep(0.1)\n",
        "        print(\"Recording speech...\")\n",
        "        wav_file = record_speech()\n",
        "\n",
        "        # --- Speech to Text ---\n",
        "        print(\"Converting speech to text...\")\n",
        "        text = stt_model.transcribe(wav_file, language=\"en\")\n",
        "        print(\"You said: \", text.get(\"text\"))\n",
        "\n",
        "        # --- Chatbot ---\n",
        "        print(\"Chatting...\")\n",
        "        response = chat_model.chat_with_history_doc(text.get(\"text\"))\n",
        "\n",
        "        print(\"Chatbot: \", response)\n",
        "\n",
        "        # --- Text to Speech ---\n",
        "        print(\"Converting text to speech...\")\n",
        "        stream_tts(response)\n",
        "\n",
        "    else:\n",
        "        time.sleep(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "role: user\n",
            "content: The following is a CV that I am providing you with. You are to keep this document in the back of your mind and consider it or use it, should it be relevant to the discussion.\n",
            "\n",
            " Document below: \n",
            "\n",
            "\n",
            "\n",
            "## Debapratim Kundu \n",
            "debo121@live.com || E8 E Woolf College, Giles Lane, Canterbury, CT2 7BQ || +44 7393062352 \n",
            "LinkedIn: https://www.linkedin.com/in/debapratim-kundu-95a089183  \n",
            " \n",
            "I am currently pursuing a master’s degree in Artificial Intelligence from the University of Kent. I have \n",
            "over 5 years of experience in designing, developing and maintaining web applications. I have \n",
            "successfully delivered solutions for domains such as e-commerce, finance and retail. I am passionate \n",
            "about finding insights from data and solving complex problems. I am looking for a challenging and \n",
            "rewarding opportunity to apply the new skills I have picked up and to learn new ones. \n",
            " \n",
            "VISA REGULATIONS \n",
            " \n",
            "Nationality: Indian \n",
            "Work Permit: Visa/Work Permit can be extended to 2 years after graduation without sponsorship. \n",
            " \n",
            "EDUCATION \n",
            " \n",
            "Postgraduate \n",
            "Computer Science (Artificial Intelligence) \n",
            "UNIVERSITY OF KENT                                                                          September 2023 – August 2024 \n",
            "Modules: Systems Architecture, NEAT, AI Systems Implementation, Deep Learning, Reinforcement \n",
            "Learning, Large Language Models, Convolution Neural Networks.\n",
            "\n",
            "\n",
            "## • \n",
            "Beating the game Jump King using NEAT (Neuro Evolution of Augmented Topology).\n",
            "\n",
            "\n",
            "## • \n",
            "Thesis project on developing a screening system for candidates by fine tuning a LLM.\n",
            "\n",
            "\n",
            "## Undergraduate \n",
            "Bachelor of Technology in Electronics and Communication Engineering  \n",
            "FUTURE INSTITUTE OF ENGINEERING AND MANAGEMENT                     June 2013 – July 2017 \n",
            "Modules: English Language and Technical Communication, Computer Programming, \n",
            "Microprocessors and Microcontrollers, Object Oriented Programming, Information Theory and \n",
            "Coding\n",
            "\n",
            "\n",
            "## • \n",
            "Graduated with 72.6% aggregate.\n",
            "\n",
            "\n",
            "## • \n",
            "Member of the official college technical club “XPLORICA” and ECE department technical \n",
            "club.\n",
            "\n",
            "\n",
            "## Indian School Certificate (ISC) / KS4 \n",
            "St. Stephen’s School                                                                                            March 2011 – May 2013 \n",
            "Modules: English, Mathematics, Physics, Chemistry, Computer Science\n",
            "\n",
            "\n",
            "## • \n",
            "Qualified with 86.5% in Computer Science Stream.\n",
            "\n",
            "\n",
            "## Indian Certificate of Secondary Education (ICSE) / KS5 \n",
            "St. Stephen’s School                                                                                            March 2010 – May 2011 \n",
            "Modules:  English, Mathematics, Physics, Chemistry, Computer Science, Biology, History, \n",
            "Geography\n",
            "\n",
            "\n",
            "## • \n",
            "Qualified with 91.8% in Computer Science Stream.\n",
            "\n",
            "\n",
            "## WORK EXPERIENCE: \n",
            " \n",
            "TCS \n",
            "Developer/Tester                                                                                                June 2021 – August 2023\n",
            "\n",
            "\n",
            "## • \n",
            "Collaborated with a cross-functional team to successfully migrate 100% of data belonging to \n",
            "Indian customers to servers within India as part of the India Data Localization initiative.\n",
            "\n",
            "\n",
            "## • \n",
            "Implemented part of EMEA migration of Merchant Risk processes from Mainframe to Java \n",
            "Microservice to increase efficiency, improve scalability, reduce downtime, and time-to-\n",
            "market.\n",
            "\n",
            "\n",
            "## • \n",
            "Achieved Rising Star of the Year award within first year at TCS, demonstrating exceptional \n",
            "performance and contributing to a 20% increase in team productivity.\n",
            "\n",
            "\n",
            "## ABZOOBA \n",
            "Developer/Tester/Deployment                                                                         October 2020 – June 2021\n",
            "\n",
            "\n",
            "## • \n",
            "Developed, maintained and deployed the “Performance Management System” for Yum \n",
            "Singapore and Yum India with full customer satisfaction.\n",
            "\n",
            "\n",
            "## • \n",
            "Appointed Database administrator for the same system resulting in a 30% increase in overall \n",
            "response time.\n",
            "\n",
            "\n",
            "## ENSIM INDIA (An Ingram Micro Company) \n",
            "Developer/Tester                                                                                        October 2017 – October 2020\n",
            "\n",
            "\n",
            "## • \n",
            "Refactored a C++ BSS monolithic application named ODIN to a JAVA microservice.\n",
            "\n",
            "\n",
            "## • \n",
            "Developed a Zapier Application for Cloudblue Commerce to communicate between two \n",
            "systems.\n",
            "\n",
            "\n",
            "## • \n",
            "Received \"Exceeds Expectation\" rating for consecutive 2 years of employment.\n",
            "\n",
            "\n",
            "## SKILLS ACQUIRED \n",
            " \n",
            "Programming Languages: Java (1.8), Python, Angular, Sql \n",
            "Libraries: SKlearn, Keras \n",
            "Frameworks: Spring Boot, Spring MVC, Hibernate \n",
            "Databases: Postgresql, SQL Server \n",
            "Web Technologies: Restful WebServices \n",
            "Tools: Maven, Burp Suite \n",
            "Other Skills: Microservices, Zapier Integration, Cybersecurity Testing \n",
            "Language: English(Very Good)    Bengali(Very Good)       Hindi(Good) \n",
            " \n",
            "ADDITIONAL PROJECTS AND TRAINING\n",
            "\n",
            "\n",
            "## • \n",
            "Home Security System project: Used Arduino to design and implement a home security \n",
            "system. (2nd Position in Exhibit 2015).\n",
            "\n",
            "\n",
            "## • \n",
            "Project Based Training on microcontroller: Gained hands-on experience with \n",
            "microcontrollers and learned how to program and troubleshoot them. (CENTRE FOR \n",
            "ELECTRONICS TEST ENGINEERING, Government of India)\n",
            "\n",
            "\n",
            "## • \n",
            "Familiarization Training focused on maintenance and servicing: Learned how to maintain \n",
            "and service electronic equipment and gained experience working with different types of \n",
            "electronic devices and systems. (AIRPORTS AUTHORITY OF INDIA)\n",
            "\n",
            "\n",
            "## INTERESTS\n",
            "\n",
            "\n",
            "## • \n",
            "Fine Arts (Painting) and recitation: Developed creativity and artistic skills by studying fine \n",
            "arts and painting. Gained experience performing in front of others by participating in \n",
            "recitation competitions. (St. Stephen’s School)\n",
            "\n",
            "\n",
            "## • \n",
            "Classical vocal: Developed musical skills by studying classical vocal music. Gained \n",
            "experience performing in front of others by participating in musical events. \n",
            "(SWARAMALIKA SANGEET VIDYALAYA)\n",
            "\n",
            "\n",
            "## • \n",
            "Dancing: Recently joined the Salsa Society in University of Kent as a beginner.\n",
            "\n",
            "\n",
            "## • \n",
            "Surfing: Recently joined the Surfing Society in the University of Kent as beginner.\n",
            "\n",
            "\n",
            "## • \n",
            "Tennis: Recently joined the Tennis club at the University of Kent as a beginner.\n",
            "\n",
            "--------------------\n",
            "role: assistant\n",
            "content: Understood! I'll keep this CV in the back of my mind and use it should it be relevant to the discussion.\n",
            "--------------------\n",
            "role: user\n",
            "content:  Hello.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: Hello! Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. I'd like to ask you a few questions to learn more about your background and interest in this role. Could you start by telling me about your experience with machine learning, particularly any projects or coursework you've completed in this area?\n",
            "--------------------\n",
            "role: user\n",
            "content:  Sure, I am currently studying Artificial Intelligence at the University of Kent. My final year project is creating a virtual screening interview system leveraging an AI. We are currently attempting to do it using prompt engineering, but if that fails, we will try to fine tune the model to our specific needs so that it can filter out candidates as and when required.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: That's an interesting project you're working on. Can you tell me more about your experience with Python, PyTorch, and NumPy? These are key tools mentioned in the job description.\n",
            "--------------------\n",
            "role: user\n",
            "content:  Yes, my final year project is a Python project and apart from this I've also done software engineering projects on Python as well as machine learning projects in Python. Some would involve Kaggle challenges such as the Titanic challenge in Kaggle, constructing cognitive neural networks and also using NumPy to extract datasets or load datasets especially for CNN models to identify objects and structures. And as for PyTorch, I mostly use Keras for deep neural network models including the model I used in the CNN. However, this can also be done with the help of PyTorch. I just need to see the documentation of PyTorch to do the same.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: Thank you for sharing that information. Given your experience, how comfortable are you with developing custom machine learning models, especially when off-the-shelf solutions don't work for specific data sets?\n",
            "--------------------\n",
            "role: user\n",
            "content:  Since I've only graduated or will be graduating this year, any of the of I have limited experience with off the cuff models. However, one such instance would be sentiment analysis directly from audio and video feed. Currently, most sentiment analysis tools use sentiment analysis from text. However, that's missing that does miss critical information such as the tone of the candidate, the voice, facial expressions, etc. So I tried to design a custom sentiment analyzer using deep neural networks and the add a delta optimizer. I got a data set from a website that had 24 voice actors, 12 male and 12 female giving various performances and each of the performances are being categorized into eight emotions, mainly sadness, happiness. I forgot the names of the exact emotions, but this was the set I used to run my sentiment analyzer on. However, our drawback of this was mainly the limited data set since all the voice actors were of North American origin, it couldn't identify more diverse voices.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: Thank you for your time today. We've covered some key aspects of your experience and skills related to the Machine Learning Engineer role. We'll be in touch soon regarding the next steps in the interview process. Do you have any quick questions about the role or company before we conclude?\n",
            "--------------------\n",
            "role: user\n",
            "content:  No, I'm good for now. Thank you for your time.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: You're welcome. Thank you again for your interest in the position at G-Research. Have a great day!\n",
            "--------------------\n",
            "\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'fpdf'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(conversation)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FPDF\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Function to extract role and content from each turn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_turn\u001b[39m(turn):\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fpdf'"
          ]
        }
      ],
      "source": [
        "conversation = chat_model.get_conversation()\n",
        "dump(conversation, \"conversation.joblib\")\n",
        "# Dump the conversation with joblib\n",
        "\n",
        "\n",
        "print(conversation)\n",
        "import re\n",
        "from fpdf import FPDF\n",
        "# Function to extract role and content from each turn\n",
        "def parse_turn(turn):\n",
        "    role_match = re.search(r\"role: (.*)\", turn)\n",
        "    content_match = re.search(r\"content: (.*)\", turn, re.DOTALL)\n",
        "\n",
        "    role = role_match.group(1) if role_match else \"\"\n",
        "    content = content_match.group(1).strip() if content_match else turn.strip()\n",
        "\n",
        "    return role, content\n",
        "\n",
        "# Create a list of dictionaries, ea-+-ch representing a turn in the conversation\n",
        "conversation_list = []\n",
        "for turn in conversation.split(\"--------------------\\n\"):\n",
        "    if turn.strip():  # Ignore empty turns\n",
        "        role, content = parse_turn(turn)\n",
        "        #print(content)\n",
        "        if \"Understood! I'll keep this CV in the back of my mind and use it should it be relevant to the discussion.\" not in content and \"The following is a CV that I am providing you with.\" not in content:\n",
        "            conversation_list.append({\"role\": role, \"content\": content})\n",
        "\n",
        "# Create a PDF object\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "\n",
        "# Set margins (in millimeters)\n",
        "pdf.set_margins(left=10, top=20, right=10)  # Right margin set to 10mm \n",
        "\n",
        "# Choose a nicer font\n",
        "pdf.set_font(\"Helvetica\", size=12)\n",
        "\n",
        "# Calculate usable width for text wrapping (accounting for margins)\n",
        "usable_width = pdf.w - pdf.l_margin - pdf.r_margin -0 # 10px right margin \n",
        "\n",
        "# Add conversation to the PDF\n",
        "for turn in conversation_list:\n",
        "    # Skip turns with empty roles or content\n",
        "    if turn['role'] and turn['content']:\n",
        "        # Subheading style for \"User\" and \"Assistant\"\n",
        "        pdf.set_font(\"Helvetica\", style=\"B\", size=14)\n",
        "        pdf.cell(0, 10, txt=f\"{turn['role'].capitalize()}:\", ln=True)\n",
        "\n",
        "        # Content with regular font and correct indentation\n",
        "        pdf.set_font(\"Helvetica\", size=12)\n",
        "        pdf.x = pdf.l_margin  # Reset x-coordinate to the left margin\n",
        "        pdf.multi_cell(usable_width, 6, txt=turn['content'])\n",
        "        pdf.ln(3)\n",
        "\n",
        "# Save the PDF\n",
        "pdf.output(\"conversation.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
