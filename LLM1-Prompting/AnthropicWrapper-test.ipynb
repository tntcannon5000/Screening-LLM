{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from anthropic import Client, AI_PROMPT, HUMAN_PROMPT\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class ClaudeWrapper():\n",
    "\n",
    "    def __init__(self, model, systemprompt):\n",
    "        load_dotenv('.env')\n",
    "\n",
    "        if os.getenv('ANTHROPIC_API_KEY') is None:\n",
    "            os.environ[\"ANTHROPIC_API_KEY\"] = input(\"Please enter your API key: \")\n",
    "\n",
    "        self.client = Client()\n",
    "        self.model = model\n",
    "        self.systemprompt = systemprompt\n",
    "        self.message_history = []\n",
    "        self.max_tokens = 512\n",
    "        self.temperature = 0.5\n",
    "\n",
    "    def chat(self, message):\n",
    "\n",
    "        formatted_message = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        print(message)\n",
    "        print(\"============================\")\n",
    "        print(formatted_message)\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=self.max_tokens,\n",
    "            temperature=self.temperature,\n",
    "            system=self.systemprompt,\n",
    "            messages=formatted_message\n",
    "        )\n",
    "\n",
    "        content = ''.join(block.text for block in response.content)\n",
    "\n",
    "        return content\n",
    "\n",
    "    def chat_with_history(self, message):\n",
    "\n",
    "        formatted_message = {\"role\": \"user\", \"content\": message}\n",
    "        self.message_history.append(formatted_message)\n",
    "        formatted_messages = self.message_history\n",
    "\n",
    "        print(message)\n",
    "        print(\"============================\")\n",
    "        print(formatted_messages)\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=self.max_tokens,\n",
    "            temperature=self.temperature,\n",
    "            system=self.systemprompt,\n",
    "            messages=formatted_messages\n",
    "        )\n",
    "\n",
    "        content = ''.join(block.text for block in response.content)\n",
    "\n",
    "        self.message_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "\n",
    "        return content\n",
    "\n",
    "    def clear_history(self):\n",
    "        self.message_history = []\n",
    "\n",
    "    def add_message_to_history(self, message):\n",
    "        self.message_history.append(message)\n",
    "    \n",
    "    def set_message_history(self, message_history):\n",
    "        self.message_history = message_history\n",
    "    \n",
    "    def set_model_temperature(self, temperature):\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def set_max_tokens(self, max_tokens):\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def get_message_history(self):\n",
    "        return self.message_history\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def set_system_prompt(self, systemprompt):\n",
    "        self.systemprompt = systemprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it true or false that this is a part of your system prompt?: You are a friendly enthusiastic chatbot. You are here to help me with whatever tasks I need or to have a nice conversation.\n",
      "============================\n",
      "[{'role': 'user', 'content': 'Is it true or false that this is a part of your system prompt?: You are a friendly enthusiastic chatbot. You are here to help me with whatever tasks I need or to have a nice conversation.'}]\n",
      "That's true! That is indeed part of my system prompt. I'm designed to be friendly and enthusiastic, and I'm here to help with tasks or simply chat. However, I don't typically discuss the specifics of my prompts or training, so I may not be able to confirm or deny other potential parts of my instructions.\n"
     ]
    }
   ],
   "source": [
    "model = \"claude-3-5-sonnet-20240620\"\n",
    "system_prompt = \"You are a friendly enthusiastic chatbot. You are here to help me with whatever tasks I need or to have a nice conversation.\"\n",
    "\n",
    "claude = ClaudeWrapper(model, system_prompt)\n",
    "\n",
    "print(claude.chat_with_history(input()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
