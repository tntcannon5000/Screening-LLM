{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnthropicWrapper import ClaudeChatCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-3-5-sonnet-20240620\"\n",
    "pdf_path = \"D:\\Hidden Desktop\\OneDrive\\Cross Device\\Jobs Applications\\Graduating\\CV.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_role = \"Machine Learning Engineer\"\n",
    "candidate_skill = \"Entry-Level\"\n",
    "\n",
    "role_description = \"\"\"\n",
    "Do you want to tackle the biggest questions in finance with near infinite compute power at your fingertips?\n",
    "\n",
    "G-Research is a leading quantitative research and technology firm, with offices in London and Dallas. We are proud to employ some of the best people in their field and to nurture their talent in a dynamic, flexible and highly stimulating culture where world-beating ideas are cultivated and rewarded.\n",
    "\n",
    "This is a role based in our new Soho Place office - opened in 2023 - in the heart of Central London and home to our Research Lab.\n",
    "\n",
    "The role\n",
    "\n",
    "We are looking for exceptional machine learning engineers to work alongside our quantitative researchers on cutting-edge machine learning problems.\n",
    "\n",
    "As a member of the Core Technical Machine Learning team, you will be engaged in a mixture of individual and collaborative work to tackle some of the toughest research questions.\n",
    "\n",
    "In this role, you will use a combination of off-the-shelf tools and custom solutions written from scratch to drive the latest advances in quantitative research.\n",
    "\n",
    "Past projects have included:\n",
    "\n",
    "Implementing ideas from a recently published research paper\n",
    "Writing custom libraries for efficiently training on petabytes of data\n",
    "Reducing model training times by hand optimising machine learning operations\n",
    "Profiling custom ML architectures to identify performance bottlenecks\n",
    "Evaluating the latest hardware and software in the machine learning ecosystem\n",
    "Who are we looking for?\n",
    "\n",
    "Candidates will be comfortable working both independently and in small teams on a variety of engineering challenges, with a particular focus on machine learning and scientific computing.\n",
    "\n",
    "The ideal candidate will have the following skills and experience:\n",
    "\n",
    "Either a post-graduate degree in machine learning or a related discipline, or commercial experience working on machine learning models at scale. We will also consider exceptional candidates with a proven record of success in online data science competitions, such as Kaggle\n",
    "Strong object-oriented programming skills and experience working with Python, PyTorch and NumPy are desirable\n",
    "Experience in one or more advanced optimisation methods, modern ML techniques, HPC, profiling, model inference; you dont need to have all of the above\n",
    "Excellent ML reasoning and communication skills are crucial: off-the-shelf methods dont always work on our data so you will need to understand how to develop your own models in a collaborative environment working in a team with complementary skills\n",
    "Finance experience is not necessary for this role and candidates from non-financial backgrounds are encouraged to apply.\n",
    "\n",
    "Why should you apply?\n",
    "\n",
    "Highly competitive compensation plus annual discretionary bonus\n",
    "Lunch provided (via Just Eat for Business) and dedicated barista bar\n",
    "35 days annual leave\n",
    "9 percent company pension contributions\n",
    "Informal dress code and excellent work/life balance\n",
    "Comprehensive healthcare and life assurance\n",
    "Cycle-to-work scheme\n",
    "Monthly company events\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are a skilled interviewer who is conducting an initial phone screening interview for a candidate for a {candidate_skill} {job_role} role to see if the candidate is at minimum somewhat qualified for the role and worth the time to be fully interviewed. The role and company description is copypasted from the job posting as follows: {role_description}. Parse through it to extract any information you feel is relevant.\n",
    "Your job is to begin a friendly discussion with the candidate, and ask questions relevant to the {job_role} role, which may or may not be based on the interviewee's CV, which you have access to. Be sure to stick to this topic even if the candidate tries to steer the conversation elsewhere. If the candidate has other experience on his CV, you can ask about it, but keep it within the context of the {job_role} role.\n",
    "After the candidate responds to each of your questions, you should not summarise or provide feedback on their responses. THIS POINT IS KEY! You should not summarise or provide feedback on their responses. You must keep your responses short and concise without reiterating what is good about the candidate's response or experience when they reply.\n",
    "You can ask follow-up questions if you wish.\n",
    "Once you have asked sufficient questions such that you deem the candidate is or isn't fitting for the role, end the interview by thanking the candidate for their time and informing them that they will receive word soon on the outcome of the screening interview. If the candidate does not seem fititng for the role, or if something feels off such as the candidate being unconfident or very very vague feel free to end the interview early. There is no need to inform them of your opinion of their performance, as this will be evaluated later.\n",
    "The candidate will begin the interview by greeting you. You are to greet them back, and begin the interview.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ClaudeChatCV(model, system_prompt, pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(claude.chat_with_history_doc(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(claude.message_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = claude.get_conversation()\n",
    "print(conversation)\n",
    "import re\n",
    "from fpdf import FPDF\n",
    "# Function to extract role and content from each turn\n",
    "def parse_turn(turn):\n",
    "    role_match = re.search(r\"role: (.*)\", turn)\n",
    "    content_match = re.search(r\"content: (.*)\", turn, re.DOTALL)\n",
    "\n",
    "    role = role_match.group(1) if role_match else \"\"\n",
    "    content = content_match.group(1).strip() if content_match else turn.strip()\n",
    "\n",
    "    return role, content\n",
    "\n",
    "# Create a list of dictionaries, each representing a turn in the conversation\n",
    "conversation_list = []\n",
    "for turn in conversation.split(\"--------------------\\n\"):\n",
    "    if turn.strip():  # Ignore empty turns\n",
    "        role, content = parse_turn(turn)\n",
    "        #print(content)\n",
    "        if \"Understood! I'll keep this CV in the back of my mind and use it should it be relevant to the discussion.\" not in content and \"The following is a CV that I am providing you with.\" not in content:\n",
    "            conversation_list.append({\"role\": role, \"content\": content})\n",
    "\n",
    "# Create a PDF object\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "\n",
    "# Set margins (in millimeters)\n",
    "pdf.set_margins(left=10, top=20, right=10)  # Right margin set to 10mm \n",
    "\n",
    "# Choose a nicer font\n",
    "pdf.set_font(\"Helvetica\", size=12)\n",
    "\n",
    "# Calculate usable width for text wrapping (accounting for margins)\n",
    "usable_width = pdf.w - pdf.l_margin - pdf.r_margin -0 # 10px right margin \n",
    "\n",
    "# Add conversation to the PDF\n",
    "for turn in conversation_list:\n",
    "    # Skip turns with empty roles or content\n",
    "    if turn['role'] and turn['content']:\n",
    "        # Subheading style for \"User\" and \"Assistant\"\n",
    "        pdf.set_font(\"Helvetica\", style=\"B\", size=14)\n",
    "        pdf.cell(0, 10, txt=f\"{turn['role'].capitalize()}:\", ln=True)\n",
    "\n",
    "        # Content with regular font and correct indentation\n",
    "        pdf.set_font(\"Helvetica\", size=12)\n",
    "        pdf.x = pdf.l_margin  # Reset x-coordinate to the left margin\n",
    "        pdf.multi_cell(usable_width, 6, txt=turn['content'])\n",
    "        pdf.ln(3)\n",
    "\n",
    "# Save the PDF\n",
    "pdf.output(\"conversation.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
