{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from webscrapper import WebScraper\n",
    "import fitz\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"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\"\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-proj-hOBF9U5T1HTBMEMrUexUT3BlbkFJsg7dgTVSB5X0Sg8hUm2H\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to extract answers from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa_from_pdf(pdf_path):\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Close the document\n",
    "    doc.close()\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    qa_dict = {}\n",
    "    current_speaker = None\n",
    "    current_message = []\n",
    "    first_user_statement = True\n",
    "    current_question = None\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == 'Assistant:':\n",
    "            if current_speaker == 'User' and not first_user_statement:\n",
    "                qa_dict[current_question] = ' '.join(current_message).strip()\n",
    "            current_speaker = 'Assistant'\n",
    "            current_message = []\n",
    "        elif line.strip() == 'User:':\n",
    "            if current_speaker == 'Assistant':\n",
    "                current_question = ' '.join(current_message).strip()\n",
    "            current_speaker = 'User'\n",
    "            current_message = []\n",
    "            if first_user_statement:\n",
    "                first_user_statement = False\n",
    "        elif line.strip():\n",
    "            current_message.append(line.strip())\n",
    "\n",
    "    # Handle the last message\n",
    "    if current_speaker == 'User' and not first_user_statement and current_question:\n",
    "        qa_dict[current_question] = ' '.join(current_message).strip()\n",
    "    qa_dict.pop(None,None)\n",
    "    return qa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "pdf_path = 'conversation.pdf'\n",
    "qa_dictionary = extract_qa_from_pdf(pdf_path)\n",
    "qa_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Hello! Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. To start, could you tell me about your experience with machine learning, particularly any projects or coursework you've completed in this area?\n",
      "A: I'm sure I have a total of six months of experience with machine learning after I entered the University of Kent. Right now I'm mainly working on Numpy and Pandas. Numpy is to analyze image information and Pandas to extract data from CSVs.\n",
      "\n",
      "Q: Thank you for sharing that information. Could you elaborate on a specific machine learning project you've worked on, perhaps one that involved Numpy or Pandas? What was the goal of the project, and what challenges did you face?\n",
      "A: I'm sure so one of the projects that I worked on was classifying the minst data set of images. Yeah basically it was done. I extracted the training set from the minst data, used a CNN algorithm to find out features from the images and then use the test set to predict the output of the model and it worked.\n",
      "\n",
      "Q: I see. For your next project, have you considered working with any advanced optimization methods or modern ML techniques beyond CNNs? If so, which ones interest you and why?\n",
      "A: Yes, so LLM seem to be the rage these days. I am trying or will be interested in working on fine-tuning an LLM model to my specific needs as a chatbot. But I have not thought of what the chatbot will do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, answer in qa_dictionary.items():\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to Decompose asnwers to find relevant sites on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-queries related to an answer by an interview candidate. \\n\n",
    "You will be provided the original question for context. The goal is to find the accuracy of the answer. For this\n",
    "you will break down the answer into a set of sub-problems / sub-queries that can be used as a search string in google to find the relevant information. \\n\n",
    "Here is the original question: {question}\n",
    "Generate multiple search queries related to: {answer} \\n\n",
    "Output (2 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. \"University of Kent machine learning projects coursework\"', '2. \"Numpy image analysis Pandas CSV data extraction\"']\n",
      "['1. \"Classifying MNIST dataset images using CNN algorithm project details\"', '2. \"Challenges faced in implementing CNN algorithm for image classification project\"']\n",
      "['1. \"Fine-tuning LLM model for chatbot applications\"', '2. \"Applications of LLM models in chatbots\"']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n--- Content from https://madewithml.com/courses/foundations/pandas/ ---\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n‚ö°Ô∏è Checkout our new End-to-end LLM Workflows Guide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMade With ML\\n\\n\\n\\n\\nPandas for Machine Learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInitializing search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGokuMohandas/MadeWithML\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\n\\n\\nAbout\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\nCommunity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMade With ML\\n\\n\\n\\n\\n\\n\\n\\nGokuMohandas/MadeWithML\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\n\\n\\nAbout\\n\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\nLessons\\n\\n\\n\\n\\n\\nüé® \\xa0 Design\\n\\n\\n\\n\\n\\nüé® \\xa0 Design\\n\\n\\n\\n\\nSetup\\n\\n\\n\\n\\nProduct\\n\\n\\n\\n\\nSystems\\n\\n\\n\\n\\n\\n\\n\\n\\nüî¢ \\xa0 Data\\n\\n\\n\\n\\n\\nüî¢ \\xa0 Data\\n\\n\\n\\n\\nPreparation\\n\\n\\n\\n\\nExploration\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nDistributed\\n\\n\\n\\n\\n\\n\\n\\n\\nüìà \\xa0 Model\\n\\n\\n\\n\\n\\nüìà \\xa0 Model\\n\\n\\n\\n\\nTraining\\n\\n\\n\\n\\nTracking\\n\\n\\n\\n\\nTuning\\n\\n\\n\\n\\nEvaluation\\n\\n\\n\\n\\nServing\\n\\n\\n\\n\\n\\n\\n\\n\\nüíª \\xa0 Developing\\n\\n\\n\\n\\n\\nüíª \\xa0 Developing\\n\\n\\n\\n\\nScripting\\n\\n\\n\\n\\nCLI\\n\\n\\n\\n\\n\\n\\n\\n\\nüì¶ \\xa0 Utilities\\n\\n\\n\\n\\n\\nüì¶ \\xa0 Utilities\\n\\n\\n\\n\\nLogging\\n\\n\\n\\n\\nDocumentation\\n\\n\\n\\n\\nStyling\\n\\n\\n\\n\\nPre-commit\\n\\n\\n\\n\\n\\n\\n\\n\\n‚úÖ \\xa0 Testing\\n\\n\\n\\n\\n\\n‚úÖ \\xa0 Testing\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\nData\\n\\n\\n\\n\\nModels\\n\\n\\n\\n\\n\\n\\n\\n\\n‚ôªÔ∏è \\xa0 Reproducibility\\n\\n\\n\\n\\n\\n‚ôªÔ∏è \\xa0 Reproducibility\\n\\n\\n\\n\\nVersioning\\n\\n\\n\\n\\n\\n\\n\\n\\nüöÄ \\xa0 Production\\n\\n\\n\\n\\n\\nüöÄ \\xa0 Production\\n\\n\\n\\n\\nJobs & Services\\n\\n\\n\\n\\nCI/CD workflows\\n\\n\\n\\n\\nMonitoring\\n\\n\\n\\n\\nData engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\nLessons\\n\\n\\n\\n\\n\\nüõ† \\xa0 Toolkit\\n\\n\\n\\n\\n\\nüõ† \\xa0 Toolkit\\n\\n\\n\\n\\nNotebooks\\n\\n\\n\\n\\nPython\\n\\n\\n\\n\\nNumPy\\n\\n\\n\\n\\n\\nPandas\\n\\n\\n\\nPandas\\n\\n\\n\\n\\nTable of contents\\n\\n\\n\\n\\nSet up\\n\\n\\n\\n\\nLoad data\\n\\n\\n\\n\\nExploratory data analysis (EDA)\\n\\n\\n\\n\\nFiltering\\n\\n\\n\\n\\nSorting\\n\\n\\n\\n\\nGrouping\\n\\n\\n\\n\\nIndexing\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nFeature engineering\\n\\n\\n\\n\\nSave data\\n\\n\\n\\n\\nScaling\\n\\n\\n\\n\\n\\n\\n\\nPyTorch\\n\\n\\n\\n\\n\\n\\n\\n\\nüî• \\xa0 Machine Learning\\n\\n\\n\\n\\n\\nüî• \\xa0 Machine Learning\\n\\n\\n\\n\\nLinear regression\\n\\n\\n\\n\\nLogistic regression\\n\\n\\n\\n\\nNeural networks\\n\\n\\n\\n\\nData quality\\n\\n\\n\\n\\nUtilities\\n\\n\\n\\n\\n\\n\\n\\n\\nü§ñ \\xa0 Deep Learning\\n\\n\\n\\n\\n\\nü§ñ \\xa0 Deep Learning\\n\\n\\n\\n\\nCNNs\\n\\n\\n\\n\\nEmbeddings\\n\\n\\n\\n\\nRNNs\\n\\n\\n\\n\\nAttention\\n\\n\\n\\n\\nTransformers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\nCommunity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of contents\\n\\n\\n\\n\\nSet up\\n\\n\\n\\n\\nLoad data\\n\\n\\n\\n\\nExploratory data analysis (EDA)\\n\\n\\n\\n\\nFiltering\\n\\n\\n\\n\\nSorting\\n\\n\\n\\n\\nGrouping\\n\\n\\n\\n\\nIndexing\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nFeature engineering\\n\\n\\n\\n\\nSave data\\n\\n\\n\\n\\nScaling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPandas for Machine Learning\\n\\n\\n\\n\\n\\n View all lessons\\n\\n\\n\\n\\n\\nData manipulation using the Pandas library.\\n\\n\\n\\n\\n\\n\\n\\nGoku Mohandas\\n\\n\\n\\n\\n ¬∑\\n\\n\\n\\n ¬∑\\n\\n\\n\\n ¬∑\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRepository\\n ¬∑ \\n\\n\\n\\nNotebook\\n\\n\\n\\n\\n\\n√ó\\n\\n\\n\\n\\n\\n\\n\\nSubscribe to our newsletter\\nüì¨\\xa0 Receive new lessons straight to your inbox (once a month) and join 40K+\\ndevelopers in learning how to responsibly deliver value with ML.\\n\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\n\\nSet up\\nFirst we\\'ll import the NumPy and Pandas libraries and set seeds for reproducibility. We\\'ll also download the dataset we\\'ll be working with to disk.\\n1\\n2import numpy as np\\nimport pandas as pd\\n\\n1\\n2# Set seed for reproducibility\\nnp.random.seed(seed=1234)\\n\\n\\nLoad data\\nWe\\'re going to work with the Titanic dataset which has data on the people who embarked the RMS Titanic in 1912 and whether they survived the expedition or not. It\\'s a very common and rich dataset which makes it very apt for exploratory data analysis with Pandas.\\nLet\\'s load the data from the CSV file into a Pandas dataframe. The header=0 signifies that the first row (0th index) is a header row which contains the names of each column in our dataset.\\n1\\n2\\n3# Read from CSV to Pandas DataFrame\\nurl = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/titanic.csv\"\\ndf = pd.read_csv(url, header=0)\\n\\n1\\n2# First few items\\ndf.head(3)\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0000\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n1\\n1\\nAllison, Master. Hudson Trevor\\nmale\\n0.9167\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n1\\n\\n\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n\\n\\nThese are the different features:\\n\\nclass: class of travel\\nname: full name of the passenger\\nsex: gender\\nage: numerical age\\nsibsp: # of siblings/spouse aboard\\nparch: number of parents/child aboard\\nticket: ticket number\\nfare: cost of the ticket\\ncabin: location of room\\nembarked: port that the passenger embarked at\\nsurvived: survival metric (0 - died, 1 - survived)\\n\\nExploratory data analysis (EDA)\\nNow that we loaded our data, we\\'re ready to start exploring it to find interesting information.\\n\\nBe sure to check out our entire lesson focused on EDA in our MLOps course.\\n\\n1import matplotlib.pyplot as plt\\n\\n\\nWe can use .describe() to extract some standard details about our numerical features.\\n1\\n2# Describe features\\ndf.describe()\\n\\n\\n\\n\\n\\n\\npclass\\nage\\nsibsp\\nparch\\nfare\\nsurvived\\n\\n\\n\\n\\ncount\\n1309.000000\\n1046.000000\\n1309.000000\\n1309.000000\\n1308.000000\\n1309.000000\\n\\n\\nmean\\n2.294882\\n29.881135\\n0.498854\\n0.385027\\n33.295479\\n0.381971\\n\\n\\nstd\\n0.837836\\n14.413500\\n1.041658\\n0.865560\\n51.758668\\n0.486055\\n\\n\\nmin\\n1.000000\\n0.166700\\n0.000000\\n0.000000\\n0.000000\\n0.000000\\n\\n\\n25%\\n2.000000\\n21.000000\\n0.000000\\n0.000000\\n7.895800\\n0.000000\\n\\n\\n50%\\n3.000000\\n28.000000\\n0.000000\\n0.000000\\n14.454200\\n0.000000\\n\\n\\n75%\\n3.000000\\n39.000000\\n1.000000\\n0.000000\\n31.275000\\n1.000000\\n\\n\\nmax\\n3.000000\\n80.000000\\n8.000000\\n9.000000\\n512.329200\\n1.000000\\n\\n\\n\\n\\n1\\n2\\n3\\n4\\n5\\n6\\n7# Correlation matrix\\nplt.matshow(df.corr())\\ncontinuous_features = df.describe().columns\\nplt.xticks(range(len(continuous_features)), continuous_features, rotation=\"45\")\\nplt.yticks(range(len(continuous_features)), continuous_features, rotation=\"45\")\\nplt.colorbar()\\nplt.show()\\n\\n\\n\\n\\nWe can also use .hist() to view the histogram of values for each feature.\\n1\\n2# Histograms\\ndf[\"age\"].hist()\\n\\n\\n\\n\\n1\\n2# Unique values\\ndf[\"embarked\"].unique()\\n\\n\\narray([\\'S\\', \\'C\\', nan, \\'Q\\'], dtype=object)\\n\\nFiltering\\nWe can filter our data by features and even by specific values (or value ranges) within specific features.\\n1\\n2# Selecting data by feature\\ndf[\"name\"].head()\\n\\n\\n0                      Allen, Miss. Elisabeth Walton\\n1                     Allison, Master. Hudson Trevor\\n2                       Allison, Miss. Helen Loraine\\n3               Allison, Mr. Hudson Joshua Creighton\\n4    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nName: name, dtype: object\\n\\n1\\n2# Filtering\\ndf[df[\"sex\"]==\"female\"].head() # only the female data appear\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n4\\n1\\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nfemale\\n25.0\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n6\\n1\\nAndrews, Miss. Kornelia Theodosia\\nfemale\\n63.0\\n1\\n0\\n13502\\n77.9583\\nD7\\nS\\n1\\n\\n\\n8\\n1\\nAppleton, Mrs. Edward Dale (Charlotte Lamson)\\nfemale\\n53.0\\n2\\n0\\n11769\\n51.4792\\nC101\\nS\\n1\\n\\n\\n\\n\\nSorting\\nWe can also sort our features in ascending or descending order.\\n1\\n2# Sorting\\ndf.sort_values(\"age\", ascending=False).head()\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n14\\n1\\nBarkworth, Mr. Algernon Henry Wilson\\nmale\\n80.0\\n0\\n0\\n27042\\n30.0000\\nA23\\nS\\n1\\n\\n\\n61\\n1\\nCavendish, Mrs. Tyrell William (Julia Florence...\\nfemale\\n76.0\\n1\\n0\\n19877\\n78.8500\\nC46\\nS\\n1\\n\\n\\n1235\\n3\\nSvensson, Mr. Johan\\nmale\\n74.0\\n0\\n0\\n347060\\n7.7750\\nNaN\\nS\\n0\\n\\n\\n135\\n1\\nGoldschmidt, Mr. George B\\nmale\\n71.0\\n0\\n0\\nPC 17754\\n34.6542\\nA5\\nC\\n0\\n\\n\\n9\\n1\\nArtagaveytia, Mr. Ramon\\nmale\\n71.0\\n0\\n0\\nPC 17609\\n49.5042\\nNaN\\nC\\n0\\n\\n\\n\\n\\nGrouping\\nWe can also get statistics across our features for certain groups. Here we wan to see the average of our continuous features based on whether the passenger survived or not.\\n1\\n2\\n3# Grouping\\nsurvived_group = df.groupby(\"survived\")\\nsurvived_group.mean()\\n\\n\\n\\n\\n\\nsurvived\\npclass\\nage\\nsibsp\\nparch\\nfare\\n\\n\\n\\n\\n0\\n2.500618\\n30.545369\\n0.521632\\n0.328801\\n23.353831\\n\\n\\n1\\n1.962000\\n28.918228\\n0.462000\\n0.476000\\n49.361184\\n\\n\\n\\n\\nIndexing\\nWe can use iloc to get rows or columns at particular positions in the dataframe.\\n1\\n2# Selecting row 0\\ndf.iloc[0, :]\\n\\n\\npclass                                  1\\nname        Allen, Miss. Elisabeth Walton\\nsex                                female\\nage                                    29\\nsibsp                                   0\\nparch                                   0\\nticket                              24160\\nfare                              211.338\\ncabin                                  B5\\nembarked                                S\\nsurvived                                1\\nName: 0, dtype: object\\n\\n1\\n2# Selecting a specific value\\ndf.iloc[0, 1]\\n\\n\\n\\'Allen, Miss. Elisabeth Walton\\'\\n\\nPreprocessing\\nAfter exploring, we can clean and preprocess our dataset.\\n\\nBe sure to check out our entire lesson focused on preprocessing in our MLOps course.\\n\\n1\\n2# Rows with at least one NaN value\\ndf[pd.isnull(df).any(axis=1)].head()\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n9\\n1\\nArtagaveytia, Mr. Ramon\\nmale\\n71.0\\n0\\n0\\nPC 17609\\n49.5042\\nNaN\\nC\\n0\\n\\n\\n13\\n1\\nBarber, Miss. Ellen \"Nellie\"\\nfemale\\n26.0\\n0\\n0\\n19877\\n78.8500\\nNaN\\nS\\n1\\n\\n\\n15\\n1\\nBaumann, Mr. John D\\nmale\\nNaN\\n0\\n0\\nPC 17318\\n25.9250\\nNaN\\nS\\n0\\n\\n\\n23\\n1\\nBidois, Miss. Rosalie\\nfemale\\n42.0\\n0\\n0\\nPC 17757\\n227.5250\\nNaN\\nC\\n1\\n\\n\\n25\\n1\\nBirnbaum, Mr. Jakob\\nmale\\n25.0\\n0\\n0\\n13905\\n26.0000\\nNaN\\nC\\n0\\n\\n\\n\\n\\n1\\n2\\n3\\n4# Drop rows with Nan values\\ndf = df.dropna() # removes rows with any NaN values\\ndf = df.reset_index() # reset\\'s row indexes in case any rows were dropped\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0000\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n1\\n1\\n1\\nAllison, Master. Hudson Trevor\\nmale\\n0.9167\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n1\\n\\n\\n2\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n3\\n3\\n1\\nAllison, Mr. Hudson Joshua Creighton\\nmale\\n30.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n4\\n4\\n1\\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nfemale\\n25.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n\\n\\n1\\n2\\n3# Dropping multiple columns\\ndf = df.drop([\"name\", \"cabin\", \"ticket\"], axis=1) # we won\\'t use text features for our initial basic models\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\nfemale\\n29.0000\\n0\\n0\\n211.3375\\nS\\n1\\n\\n\\n1\\n1\\n1\\nmale\\n0.9167\\n1\\n2\\n151.5500\\nS\\n1\\n\\n\\n2\\n2\\n1\\nfemale\\n2.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n3\\n3\\n1\\nmale\\n30.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n4\\n4\\n1\\nfemale\\n25.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n\\n\\n1\\n2\\n3\\n4# Map feature values\\ndf[\"sex\"] = df[\"sex\"].map( {\"female\": 0, \"male\": 1} ).astype(int)\\ndf[\"embarked\"] = df[\"embarked\"].dropna().map( {\"S\":0, \"C\":1, \"Q\":2} ).astype(int)\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n211.3375\\n0\\n1\\n\\n\\n1\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n151.5500\\n0\\n1\\n\\n\\n2\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n3\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n4\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n\\n\\nFeature engineering\\nWe\\'re now going to use feature engineering to create a column called family_size. We\\'ll first define a function called get_family_size that will determine the family size using the number of parents and siblings.\\n1\\n2\\n3\\n4# Lambda expressions to create new features\\ndef get_family_size(sibsp, parch):\\n    family_size = sibsp + parch\\n    return family_size\\n\\nOnce we define the function, we can use lambda to apply that function on each row (using the numbers of siblings and parents in each row to determine the family size for each row).\\n1\\n2df[\"family_size\"] = df[[\"sibsp\", \"parch\"]].apply(lambda x: get_family_size(x[\"sibsp\"], x[\"parch\"]), axis=1)\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\nfamily_size\\n\\n\\n\\n\\n0\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n211.3375\\n0\\n1\\n0\\n\\n\\n1\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n151.5500\\n0\\n1\\n3\\n\\n\\n2\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n3\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n4\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n\\n\\n1\\n2\\n3# Reorganize headers\\ndf = df[[\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"family_size\", \"fare\", \\'\"mbarked\", \"survived\"]]\\ndf.head()\\n\\n\\n\\n\\n\\n\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfamily_size\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n0\\n211.3375\\n0\\n1\\n\\n\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n3\\n151.5500\\n0\\n1\\n\\n\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n\\n\\n\\nTip\\nFeature engineering can be done in collaboration with domain experts that can guide us on what features to engineer and use.\\n\\nSave data\\nFinally, let\\'s save our preprocessed data into a new CSV file to use later.\\n1\\n2# Saving dataframe to CSV\\ndf.to_csv(\"processed_titanic.csv\", index=False)\\n\\n1\\n2# See the saved file\\n!ls -l\\n\\n\\ntotal 96\\n-rw-r--r-- 1 root root  6975 Dec  3 17:36 processed_titanic.csv\\ndrwxr-xr-x 1 root root  4096 Nov 21 16:30 sample_data\\n-rw-r--r-- 1 root root 85153 Dec  3 17:36 titanic.csv\\n\\nScaling\\nWhen working with very large datasets, our Pandas DataFrames can become very large and it can be very slow or impossible to operate on them. This is where packages that can distribute workloads or run on more efficient hardware can come in handy.\\n\\nDask: parallel computing to scale packages like Numpy, Pandas and scikit-learn on one/multiple machines.\\ncuDF: efficient dataframe loading and computation on a GPU.\\n\\nAnd, of course, we can combine these together (Dask-cuDF) to operate on partitions of a dataframe on the GPU.\\n\\nTo cite this content, please use:\\n1\\n2\\n3\\n4\\n5\\n6@article{madewithml,\\n    author       = {Goku Mohandas},\\n    title        = { Pandas - Made With ML },\\n    howpublished = {\\\\url{https://madewithml.com/}},\\n    year         = {2023}\\n}\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n¬© 2023 Anyscale, Inc.  Anyscale Privacy Policy\\n\\nMade with\\n\\nMaterial for MkDocs\\n\\n--- Content from https://www.geeksforgeeks.org/introduction-to-pandas-in-python/ ---\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTutorialsPython TutorialTaking Input in PythonPython OperatorsPython Data TypesPython NumbersPython StringPython ListsPython TuplesSets in PythonPython DictionaryPython Loops and Control FlowPython Conditional StatementsPython LoopsPython FunctionsPython OOPS ConceptPython Data StructuresPython DSALinked ListStackQueueTreeHeapHashingGraphSetsMapAdvance Data StructureSorting AlgorithmsSearching AlgorithmsPython Exception HandlingPython File HandlingPython ExercisesPython List ExercisePython String ExercisePython Tuple ExercisePython Dictionary ExercisePython Set ExercisePython Design PatternsPython Programming ExamplesPython Practice QuestionsJavaJava Programming LanguageJava TutorialData TypesVariablesOperatorsFlow Control in JavaLoops in JavaMethodsStringsArraysOOPs ConceptsOOPs ConceptsClasses and ObjectsAccess ModifiersInheritanceAbstractionEncapsulationPolymorphismInterfacePackagesMultithreadingFile HandlingRegular ExpressionJava CollectionsJava CollectionsCollection ClassList InterfaceArrayListLinkedList ClassQueue InterfaceSet InterfaceHashSet ClassMap InterfaceHashMap ClassHashTable ClassIteratorComparatorCollection Interview QuestionsJava 8 TutorialJava ProgramsJava Programming ExamplesJava Array ProgramsJava String ProgramsJava Date-Time ProgramsJava File Handling ProgramsJava Collection ProgramsJava JDBC ProgramsJava Apache POI ProgramsJava OpenCV ProgramsJava Interview QuestionsJava Interview QuestionsCore Java Interview Questions-FreshersJava Multithreading Interview QuestionsOOPs Interview Questions and AnswersJava ExercisesJava QuizJava QuizCore Java MCQJava ProjectsAdvance JavaSpring TutorialSpring Boot TutorialSpring Boot Interview QuestionsSpring MVC TutorialSpring MVC Interview QuestionsHibernate TutorialHibernate Interview QuestionsProgramming LanguagesCC++JavaScriptPHPR TutorialC#SQLScalaPerlGo LanguageKotlinSystem DesignSystem Design TutorialWhat is System DesignKey Terminologies in System DesignAnalysis and Architecture of SystemsScalability in System DesignDatabases in System DesignHigh Level Design or HLDLow Level Design or LLDCase Studies in Designing SystemsComplete System Design TutorialSoftware Design PatternsSystem Design RoadmapTop 10 System Design Interview Questions and AnswersInterview CornerCompany PreparationTop TopicsPractice Company QuestionsInterview ExperiencesExperienced InterviewsInternship InterviewsCompetitive ProgrammingMultiple Choice QuizzesAptitude for PlacementsComputer Science SubjectsOperating SystemDBMSComputer NetworksEngineering MathematicsComputer Organization and ArchitectureTheory of ComputationCompiler DesignDigital LogicSoftware EngineeringDevOpsGITAWSDockerKubernetesMicrosoft Azure TutorialGoogle Cloud PlatformLinuxLinux TutorialLinux Commands A-ZLinux Commands CheatsheetFile Permission CommandsLinux System AdministrationLinux File SystemLinux Shell ScriptingLinux NetworkingLinux Interview QuestionsSoftware TestingSoftware Testing TutorialSoftware Engineering TutorialTesting Interview QuestionsJiraDatabasesDBMS TutorialSQL TutorialPostgreSQL TutorialMongoDB TutorialSQL Interview QuestionsMySQL Interview QuestionsPL/SQL Interview QuestionsAndroidAndroid TutorialAndroid Studio TutorialKotlin For AndroidAndroid ProjectsAndroid Interview Questions6 Weeks of Android App DevelopmentExcelMS Excel TutorialIntroduction to MS ExcelData Analysis in ExcelBasic Excel Formulas & FunctionsData Analysis in Advanced ExcelWorkbooksStatistical FunctionsData Visualization in ExcelPivot Tables in ExcelExcel Spreadsheets in PythonBasic Excel ShortcutsMathematicsNumber SystemAlgebraLinear AlgebraTrigonometrySet TheoryStatisticsProbabilityGeometryMensurationLogarithmsCalculusDSAData StructuresArraysMatrixStringsLinked ListSingly Linked ListDoubly Linked ListCircular Linked ListDoubly Circular Linked ListLinked List TutorialStackQueueTreeGeneric TreeBinary TreeBinary Search TreeAVL TreeB TreeB+ TreeRed Black TreeTree Data Structure TutorialHeapHashingGraphSet Data StructureMap Data StructureAdvanced Data StructureData Structures TutorialAlgorithmsAnalysis of AlgorithmsDesign and Analysis of AlgorithmsAsymptotic AnalysisAsymptotic NotationsWorst, Average and Best CasesSearching AlgorithmsLinear SearchBinary SearchSearching Algorithms TutorialSorting AlgorithmsSelection SortBubble SortInsertion SortMerge SortQuick SortHeap SortCounting SortRadix SortBucket SortSorting Algorithms TutorialGreedy AlgorithmsDynamic ProgrammingGraph AlgorithmsPattern SearchingRecursionBacktrackingDivide and ConquerMathematical AlgorithmsGeometric AlgorithmsBitwise AlgorithmsRandomized AlgorithmsBranch and BoundAlgorithms TutorialDSA TutorialPracticeAll DSA ProblemsProblem of the DayCompany Wise Coding PracticeAmazonMicrosoftFlipkartExplore AllGfG SDE SheetPractice Problems Difficulty WiseSchoolBasicEasyMediumHardLanguage Wise Coding PracticeCPPJavaPythonCurated DSA ListsBeginner\\'s DSA SheetTop 50 Array ProblemsTop 50 String ProblemsTop 50 DP ProblemsTop 50 Graph ProblemsTop 50 Tree ProblemsCompetitive ProgrammingCompany Wise SDE SheetsFacebook SDE SheetAmazon SDE SheetApple SDE SheetNetflix SDE SheetGoogle SDE SheetDSA Cheat SheetsSDE SheetDSA Sheet for BeginnersFAANG Coding SheetProduct-Based Coding SheetCompany-Wise Preparation SheetTop Interview QuestionsPuzzlesAll PuzzlesTop 100 Puzzles Asked In InterviewsTop 20 Puzzles Commonly Asked During SDE InterviewsData SciencePython TutorialR TutorialMachine LearningData Science using PythonData Science using RData Science PackagesPandas TutorialNumPy TutorialData VisualizationPython Data Visualization TutorialData Visualization with RData AnalysisData Analysis with PythonData Analysis with RDeep LearningNLP TutorialWeb TechHTML TutorialCSS TutorialJavaScript TutorialPHP TutorialReactJS TutorialNodeJS TutorialAngularJS TutorialBootstrap TutorialTypescriptWeb Development Using PythonDjangoDjango TutorialDjango ProjectsDjango Interview QuestionsFlaskFlask TutorialFlask ProjectsFlask Interview QuestionsPostmanGithubWordpress TutorialWeb DesignCheat SheetsHTML Cheat SheetCSS Cheat SheetJavaScript Cheat SheetReact Cheat SheetAngular Cheat SheetjQuery Cheat SheetBootstrap Cheat SheetLearn Complete Web DevelopmentCoursesGo PremiumCoding for EveryoneDSA to DevelopmentMachine Learning & Data ScienceGenerative AI & ChatGPTBecome AWS CertifiedDSA CoursesData Structure & Algorithm(C++/JAVA)Data Structure & Algorithm(Python)Data Structure & Algorithm(JavaScript)Programming LanguagesCPPJavaPythonJavaScriptC\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAI ML DSData ScienceData AnalysisData VisualizationMachine LearningDeep LearningNLPComputer VisionArtificial IntelligenceAI ML DS Interview SeriesAI ML DS Projects seriesData EngineeringWeb Scrapping \\n\\n\\n\\n\\n‚ñ≤\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen In App\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPandas Introduction\\n\\n\\nLast Updated : \\n30 Jul, 2024\\n\\n\\n\\n \\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSummarize\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n \\n\\n\\nLike Article\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\nSave\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n\\n\\n\\n\\nReport\\n\\n\\n\\n\\n\\n\\n\\nPandas is a powerful and open-source Python library. The Pandas library is used for data manipulation and analysis. Pandas consist of data structures and functions to perform efficient operations on data.\\nThis free tutorial will cover an overview of Pandas, covering the fundamentals of Python Pandas.\\nTable of Content\\nWhat is Pandas Libray in Python?What is Python Pandas used for?Getting Started with PandasData Structures in Pandas LibraryPandas SeriesPandas DataFrameHow to run the Pandas Program in Python?What is Pandas Libray in Python?Pandas is a powerful and versatile library that simplifies the tasks of data manipulation in Python. Pandas is well-suited for working with tabular data, such as spreadsheets or SQL tables.\\nThe Pandas library is an essential tool for data analysts, scientists, and engineers working with structured data in Python.\\nWhat is Python Pandas used for?The Pandas library is generally used for data science, but have you wondered why? This is because the Pandas library is used in conjunction with other libraries that are used for data science.\\nIt is built on top of the NumPy library which means that a lot of the structures of NumPy are used or replicated in Pandas.\\nThe data produced by Pandas is often used as input for plotting functions in Matplotlib, statistical analysis in SciPy, and machine learning algorithms in Scikit-learn.\\nYou must be wondering, Why should you use the Pandas Library. Python‚Äôs Pandas library is the best tool to analyze, clean, and manipulate data.\\nHere is a list of things that we can do using Pandas.\\nData set cleaning, merging, and joining.Easy handling of missing data (represented as NaN) in floating point as well as non-floating point data.Columns can be inserted and deleted from DataFrame and higher-dimensional objects.Powerful group by functionality for performing split-apply-combine operations on data sets.Data Visualization.Getting Started with PandasLet‚Äôs see how to start working with the Python Pandas library:\\nInstalling PandasThe first step in working with Pandas is to ensure whether it is installed in the system or not. \\xa0If not, then we need to install it on our system using the pip command.\\nFollow these steps to install Pandas:\\nStep 1: Type ‚Äòcmd‚Äô in the search box and open it.Step 2: Locate the folder using the cd command where the python-pip file has been installed.Step 3: After locating it, type the command:\\npip install pandasFor more reference, take a look at this article on installing pandas follows.\\nImporting PandasAfter the Pandas have been installed in the system, you need to import the library. This module is generally imported as follows:\\nimport pandas as pdNote: Here, pd is referred to as an alias for the Pandas. However, it is not necessary to import the library using the alias, it just helps in writing less code every time a method or property is called.\\xa0\\nData Structures in Pandas LibraryPandas generally provide two data structures for manipulating data. They are:\\nSeriesDataFramePandas SeriesA Pandas Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, Python objects, etc.). The axis labels are collectively called indexes.\\nThe Pandas Series is nothing but a column in an Excel sheet. Labels need not be unique but must be of a hashable type.\\nThe object supports both integer and label-based indexing and provides a host of methods for performing operations involving the index.\\nPandas SeriesCreating a SeriesPandas Series is created by loading the datasets from existing storage (which can be a SQL database, a CSV file, or an Excel file).\\nPandas Series can be created from lists, dictionaries, scalar values, etc.\\nExample: Creating a series using the Pandas Library.\\n\\nPython\\n\\nimport pandas as pd \\nimport numpy as np\\n\\n# Creating empty series \\nser = pd.Series() \\nprint(\"Pandas Series: \", ser) \\n\\n# simple array \\ndata = np.array([\\'g\\', \\'e\\', \\'e\\', \\'k\\', \\'s\\']) \\n  \\nser = pd.Series(data) \\nprint(\"Pandas Series:\\\\n\", ser)\\n\\nOutput\\nPandas Series: Series([], dtype: float64)Pandas Series:0    g1    e2    e3    k4    sdtype: objectFor more information, refer to Creating a Pandas Series\\nPandas DataFramePandas DataFrame is a two-dimensional data structure with labeled axes (rows and columns).\\nCreating DataFramePandas DataFrame is created by loading the datasets from existing storage (which can be a SQL database, a CSV file, or an Excel file).\\nPandas DataFrame can be created from lists, dictionaries, a list of dictionaries, etc.\\nExample: Creating a DataFrame Using the Pandas Library\\n\\nPython\\n\\nimport pandas as pd \\n  \\n# Calling DataFrame constructor \\ndf = pd.DataFrame() \\nprint(df)\\n\\n# list of strings \\nlst = [\\'Geeks\\', \\'For\\', \\'Geeks\\', \\'is\\', \\'portal\\', \\'for\\', \\'Geeks\\'] \\n  \\n# Calling DataFrame constructor on list \\ndf = pd.DataFrame(lst) \\nprint(df)\\n\\nOutput:\\nEmpty DataFrameColumns: []Index: []        00   Geeks1     For2   Geeks3      is4  portal5     for6   GeeksNote: For more information, refer to Creating a Pandas DataFrame\\xa0\\nHow to run the Pandas Program in Python?The Pandas program can be run from any text editor, but it is recommended to use Jupyter Notebook for this, as Jupyter gives you the ability to execute code in a particular cell rather than the entire file.\\nJupyter also provides an easy way to visualize Pandas DataFrame and plots.\\nNote: For more information on Jupyter Notebook, refer to How To Use Jupyter Notebook ‚Äì An Ultimate Guide\\xa0\\nConclusionThis tutorial provides a solid foundation for mastering the Pandas library, from basic operations to advanced techniques. We have also covered the Pandas data structures (series and DataFrame) with examples.\\nAfter completing this tutorial, you will gain a complete idea of what is Python Pandas. What is Pandas used for? and how to use Python Pandas.\\nAs you apply these skills to your projects, you will discover how Pandas enhances your ability to explore, clean, and analyze data, making it an indispensable tool in the data scientist‚Äôs toolkit.\\nElevate your coding journey with a Premium subscription. Benefit from ad-free learning, unlimited article summaries, an AI bot, access to 35+ courses, and more-available only with GeeksforGeeks Premium! Explore now!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nN\\n\\n\\n\\n\\n \\n\\nnikhilaggarwal3 \\n\\n\\n\\n\\n\\n Follow \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n\\n\\nPrevious Article\\n\\n\\n\\nPandas Tutorial\\n\\n\\n\\n\\nNext Article\\n\\n\\n\\n\\nHow to Install Pandas in Python?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Please Login to comment...\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSimilar Reads\\n\\n\\n\\nPandas Series dt.day_name() Method | Get Day From Date in Pandas\\nPandas dt.day_name() method returns the day names of the DateTime Series objects with specified locale. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31 08:45\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) resu\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.weekday | Find Day of the Week in Pandas\\nThe dt.weekday attribute returns the day of the week. It is assumed the week starts on Monday, which is denoted by 0, and ends on Sunday which is denoted by 6. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.weekofyear Method | Get Week of Year in Pandas Series\\nThe dt.weekofyear attribute returns a Series containing the week ordinal of the year in the underlying data of the given series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index =\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.dayofyear | Get Day of Year in Pandas\\nPandas dt.dayofyear attribute returns the ordinal day of the year in the underlying DateTime data in the given Series object. Example: C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr =\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.minute | Extract Minute from DateTime Series in Pandas\\nPandas Series.dt.minute attribute returns a NumPy array containing the minutes of the DateTime in the underlying data of the given series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\']\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.days_in_month | Get Total Number of Days in Month in Pandas\\nThe Pandas dt.days_in_month attribute returns the total number of days in the month for the given Series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) r\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.dayofweek | Get Day of Week from DateTime Series in Pandas\\nPandas dt.dayofweek attribute returns the day of the week from the given DateTime Series Object. It is assumed the week starts on Monday, which is denoted by 0, and ends on Sunday which is denoted by 6. Example: C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.freq | Retrieve Frequency of Pandas Time Series\\nPandas dt.freq attribute returns the time series frequency applied on the given series object if any, else it returns None. Examples C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_da\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.daysinmonth | Get Number of Days in Month in Pandas Series\\nThe dt.daysinmonth attribute returns the number of days in the month for the given DateTime series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) result\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.normalize() | Normalize Time in Pandas Series\\nThe dt.normalize() method converts times to midnight. The time component of the date-time is converted to midnight i.e. 00:00:00. This is useful in cases when the time does not matter. Length is unaltered. The time zones are unaffected. Example: C/C++ Code import pandas as pd sr = pd.Series(pd.date_range(\\'2012-12-31 09:45\\', periods = 5, freq = \\'M\\',\\n\\n\\n\\n2 min read\\n\\n\\n\\nView More Articles\\n\\n\\n\\nArticle Tags : \\n\\n\\nAI-ML-DS\\n\\n\\nPandas\\n\\n\\nPython pandas-basics\\n \\n\\n\\n\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nExplore More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n                     Corporate & Communications Address:- A-143, 9th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) | Registered Address:- K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCompanyAbout UsLegalIn MediaContact UsAdvertise with usGFG Corporate SolutionPlacement Training ProgramGeeksforGeeks CommunityLanguagesPythonJavaC++PHPGoLangSQLR LanguageAndroid TutorialTutorials ArchiveDSAData StructuresAlgorithmsDSA for BeginnersBasic DSA ProblemsDSA RoadmapTop 100 DSA Interview ProblemsDSA Roadmap by Sandeep JainAll Cheat SheetsData Science & MLData Science With PythonData Science For BeginnerMachine Learning TutorialML MathsData Visualisation TutorialPandas TutorialNumPy TutorialNLP TutorialDeep Learning TutorialWeb TechnologiesHTMLCSSJavaScriptTypeScriptReactJSNextJSBootstrapWeb DesignPython TutorialPython Programming ExamplesPython ProjectsPython TkinterWeb ScrapingOpenCV TutorialPython Interview QuestionDjangoComputer ScienceOperating SystemsComputer NetworkDatabase Management SystemSoftware EngineeringDigital Logic DesignEngineering MathsSoftware DevelopmentSoftware TestingDevOpsGitLinuxAWSDockerKubernetesAzureGCPDevOps RoadmapSystem DesignHigh Level DesignLow Level DesignUML DiagramsInterview GuideDesign PatternsOOADSystem Design BootcampInterview QuestionsInteview PreparationCompetitive ProgrammingTop DS or Algo for CPCompany-Wise Recruitment ProcessCompany-Wise PreparationAptitude PreparationPuzzlesSchool SubjectsMathematicsPhysicsChemistryBiologySocial ScienceEnglish GrammarCommerceWorld GKGeeksforGeeks VideosDSAPythonJavaC++Web DevelopmentData ScienceCS Subjects \\n\\n\\n\\n\\n\\n\\n@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        We use cookies to ensure you have the best browsing experience on our website. By using our site, you\\r\\n        acknowledge that you have read and understood our\\r\\n        Cookie Policy &\\r\\n        Privacy Policy\\n\\n\\r\\n        Got It !\\r\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nImprovement\\n\\n\\n\\n\\n\\nPlease go through our recently updated Improvement Guidelines before submitting any improvements.\\nThis improvement is locked by another user right now. You can suggest the changes for now and it will be under \\'My Suggestions\\' Tab on Write.\\nYou will be notified via email once the article is available for improvement.\\r\\n                        Thank you for your valuable feedback!\\r\\n                    \\n\\nSuggest changes\\n\\n\\n\\nPlease go through our recently updated Improvement Guidelines before submitting any improvements.\\n\\n\\nSuggest Changes\\nHelp us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\nEnhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest Changes\\n\\n\\n\\n\\n\\n\\n\\nmin 4 words, max CharLimit:2000\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat kind of Experience do you want to share?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInterview Experiences\\n\\n\\n\\n\\n\\n\\n\\nAdmission Experiences\\n\\n\\n\\n\\n\\n\\n\\nCareer Journeys\\n\\n\\n\\n\\n\\n\\n\\nWork Experiences\\n\\n\\n\\n\\n\\n\\n\\nCampus Experiences\\n\\n\\n\\n\\n\\n\\n\\nCompetitive Exam Experiences\\n\\n\\n\\n\\n\\n\\n                        Can\\'t choose a topic to write? click here for suggested topics\\n                    \\n\\n\\n\\n                       Write and publish your own Article\\n\\n--- Content from https://madewithml.com/courses/foundations/pandas/ ---\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n‚ö°Ô∏è Checkout our new End-to-end LLM Workflows Guide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMade With ML\\n\\n\\n\\n\\nPandas for Machine Learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInitializing search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGokuMohandas/MadeWithML\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\n\\n\\nAbout\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\nCommunity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMade With ML\\n\\n\\n\\n\\n\\n\\n\\nGokuMohandas/MadeWithML\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\n\\n\\nAbout\\n\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\nLessons\\n\\n\\n\\n\\n\\nüé® \\xa0 Design\\n\\n\\n\\n\\n\\nüé® \\xa0 Design\\n\\n\\n\\n\\nSetup\\n\\n\\n\\n\\nProduct\\n\\n\\n\\n\\nSystems\\n\\n\\n\\n\\n\\n\\n\\n\\nüî¢ \\xa0 Data\\n\\n\\n\\n\\n\\nüî¢ \\xa0 Data\\n\\n\\n\\n\\nPreparation\\n\\n\\n\\n\\nExploration\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nDistributed\\n\\n\\n\\n\\n\\n\\n\\n\\nüìà \\xa0 Model\\n\\n\\n\\n\\n\\nüìà \\xa0 Model\\n\\n\\n\\n\\nTraining\\n\\n\\n\\n\\nTracking\\n\\n\\n\\n\\nTuning\\n\\n\\n\\n\\nEvaluation\\n\\n\\n\\n\\nServing\\n\\n\\n\\n\\n\\n\\n\\n\\nüíª \\xa0 Developing\\n\\n\\n\\n\\n\\nüíª \\xa0 Developing\\n\\n\\n\\n\\nScripting\\n\\n\\n\\n\\nCLI\\n\\n\\n\\n\\n\\n\\n\\n\\nüì¶ \\xa0 Utilities\\n\\n\\n\\n\\n\\nüì¶ \\xa0 Utilities\\n\\n\\n\\n\\nLogging\\n\\n\\n\\n\\nDocumentation\\n\\n\\n\\n\\nStyling\\n\\n\\n\\n\\nPre-commit\\n\\n\\n\\n\\n\\n\\n\\n\\n‚úÖ \\xa0 Testing\\n\\n\\n\\n\\n\\n‚úÖ \\xa0 Testing\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\nData\\n\\n\\n\\n\\nModels\\n\\n\\n\\n\\n\\n\\n\\n\\n‚ôªÔ∏è \\xa0 Reproducibility\\n\\n\\n\\n\\n\\n‚ôªÔ∏è \\xa0 Reproducibility\\n\\n\\n\\n\\nVersioning\\n\\n\\n\\n\\n\\n\\n\\n\\nüöÄ \\xa0 Production\\n\\n\\n\\n\\n\\nüöÄ \\xa0 Production\\n\\n\\n\\n\\nJobs & Services\\n\\n\\n\\n\\nCI/CD workflows\\n\\n\\n\\n\\nMonitoring\\n\\n\\n\\n\\nData engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\nLessons\\n\\n\\n\\n\\n\\nüõ† \\xa0 Toolkit\\n\\n\\n\\n\\n\\nüõ† \\xa0 Toolkit\\n\\n\\n\\n\\nNotebooks\\n\\n\\n\\n\\nPython\\n\\n\\n\\n\\nNumPy\\n\\n\\n\\n\\n\\nPandas\\n\\n\\n\\nPandas\\n\\n\\n\\n\\nTable of contents\\n\\n\\n\\n\\nSet up\\n\\n\\n\\n\\nLoad data\\n\\n\\n\\n\\nExploratory data analysis (EDA)\\n\\n\\n\\n\\nFiltering\\n\\n\\n\\n\\nSorting\\n\\n\\n\\n\\nGrouping\\n\\n\\n\\n\\nIndexing\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nFeature engineering\\n\\n\\n\\n\\nSave data\\n\\n\\n\\n\\nScaling\\n\\n\\n\\n\\n\\n\\n\\nPyTorch\\n\\n\\n\\n\\n\\n\\n\\n\\nüî• \\xa0 Machine Learning\\n\\n\\n\\n\\n\\nüî• \\xa0 Machine Learning\\n\\n\\n\\n\\nLinear regression\\n\\n\\n\\n\\nLogistic regression\\n\\n\\n\\n\\nNeural networks\\n\\n\\n\\n\\nData quality\\n\\n\\n\\n\\nUtilities\\n\\n\\n\\n\\n\\n\\n\\n\\nü§ñ \\xa0 Deep Learning\\n\\n\\n\\n\\n\\nü§ñ \\xa0 Deep Learning\\n\\n\\n\\n\\nCNNs\\n\\n\\n\\n\\nEmbeddings\\n\\n\\n\\n\\nRNNs\\n\\n\\n\\n\\nAttention\\n\\n\\n\\n\\nTransformers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\nCommunity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of contents\\n\\n\\n\\n\\nSet up\\n\\n\\n\\n\\nLoad data\\n\\n\\n\\n\\nExploratory data analysis (EDA)\\n\\n\\n\\n\\nFiltering\\n\\n\\n\\n\\nSorting\\n\\n\\n\\n\\nGrouping\\n\\n\\n\\n\\nIndexing\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nFeature engineering\\n\\n\\n\\n\\nSave data\\n\\n\\n\\n\\nScaling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPandas for Machine Learning\\n\\n\\n\\n\\n\\n View all lessons\\n\\n\\n\\n\\n\\nData manipulation using the Pandas library.\\n\\n\\n\\n\\n\\n\\n\\nGoku Mohandas\\n\\n\\n\\n\\n ¬∑\\n\\n\\n\\n ¬∑\\n\\n\\n\\n ¬∑\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRepository\\n ¬∑ \\n\\n\\n\\nNotebook\\n\\n\\n\\n\\n\\n√ó\\n\\n\\n\\n\\n\\n\\n\\nSubscribe to our newsletter\\nüì¨\\xa0 Receive new lessons straight to your inbox (once a month) and join 40K+\\ndevelopers in learning how to responsibly deliver value with ML.\\n\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\n\\nSet up\\nFirst we\\'ll import the NumPy and Pandas libraries and set seeds for reproducibility. We\\'ll also download the dataset we\\'ll be working with to disk.\\n1\\n2import numpy as np\\nimport pandas as pd\\n\\n1\\n2# Set seed for reproducibility\\nnp.random.seed(seed=1234)\\n\\n\\nLoad data\\nWe\\'re going to work with the Titanic dataset which has data on the people who embarked the RMS Titanic in 1912 and whether they survived the expedition or not. It\\'s a very common and rich dataset which makes it very apt for exploratory data analysis with Pandas.\\nLet\\'s load the data from the CSV file into a Pandas dataframe. The header=0 signifies that the first row (0th index) is a header row which contains the names of each column in our dataset.\\n1\\n2\\n3# Read from CSV to Pandas DataFrame\\nurl = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/titanic.csv\"\\ndf = pd.read_csv(url, header=0)\\n\\n1\\n2# First few items\\ndf.head(3)\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0000\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n1\\n1\\nAllison, Master. Hudson Trevor\\nmale\\n0.9167\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n1\\n\\n\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n\\n\\nThese are the different features:\\n\\nclass: class of travel\\nname: full name of the passenger\\nsex: gender\\nage: numerical age\\nsibsp: # of siblings/spouse aboard\\nparch: number of parents/child aboard\\nticket: ticket number\\nfare: cost of the ticket\\ncabin: location of room\\nembarked: port that the passenger embarked at\\nsurvived: survival metric (0 - died, 1 - survived)\\n\\nExploratory data analysis (EDA)\\nNow that we loaded our data, we\\'re ready to start exploring it to find interesting information.\\n\\nBe sure to check out our entire lesson focused on EDA in our MLOps course.\\n\\n1import matplotlib.pyplot as plt\\n\\n\\nWe can use .describe() to extract some standard details about our numerical features.\\n1\\n2# Describe features\\ndf.describe()\\n\\n\\n\\n\\n\\n\\npclass\\nage\\nsibsp\\nparch\\nfare\\nsurvived\\n\\n\\n\\n\\ncount\\n1309.000000\\n1046.000000\\n1309.000000\\n1309.000000\\n1308.000000\\n1309.000000\\n\\n\\nmean\\n2.294882\\n29.881135\\n0.498854\\n0.385027\\n33.295479\\n0.381971\\n\\n\\nstd\\n0.837836\\n14.413500\\n1.041658\\n0.865560\\n51.758668\\n0.486055\\n\\n\\nmin\\n1.000000\\n0.166700\\n0.000000\\n0.000000\\n0.000000\\n0.000000\\n\\n\\n25%\\n2.000000\\n21.000000\\n0.000000\\n0.000000\\n7.895800\\n0.000000\\n\\n\\n50%\\n3.000000\\n28.000000\\n0.000000\\n0.000000\\n14.454200\\n0.000000\\n\\n\\n75%\\n3.000000\\n39.000000\\n1.000000\\n0.000000\\n31.275000\\n1.000000\\n\\n\\nmax\\n3.000000\\n80.000000\\n8.000000\\n9.000000\\n512.329200\\n1.000000\\n\\n\\n\\n\\n1\\n2\\n3\\n4\\n5\\n6\\n7# Correlation matrix\\nplt.matshow(df.corr())\\ncontinuous_features = df.describe().columns\\nplt.xticks(range(len(continuous_features)), continuous_features, rotation=\"45\")\\nplt.yticks(range(len(continuous_features)), continuous_features, rotation=\"45\")\\nplt.colorbar()\\nplt.show()\\n\\n\\n\\n\\nWe can also use .hist() to view the histogram of values for each feature.\\n1\\n2# Histograms\\ndf[\"age\"].hist()\\n\\n\\n\\n\\n1\\n2# Unique values\\ndf[\"embarked\"].unique()\\n\\n\\narray([\\'S\\', \\'C\\', nan, \\'Q\\'], dtype=object)\\n\\nFiltering\\nWe can filter our data by features and even by specific values (or value ranges) within specific features.\\n1\\n2# Selecting data by feature\\ndf[\"name\"].head()\\n\\n\\n0                      Allen, Miss. Elisabeth Walton\\n1                     Allison, Master. Hudson Trevor\\n2                       Allison, Miss. Helen Loraine\\n3               Allison, Mr. Hudson Joshua Creighton\\n4    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nName: name, dtype: object\\n\\n1\\n2# Filtering\\ndf[df[\"sex\"]==\"female\"].head() # only the female data appear\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n4\\n1\\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nfemale\\n25.0\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n6\\n1\\nAndrews, Miss. Kornelia Theodosia\\nfemale\\n63.0\\n1\\n0\\n13502\\n77.9583\\nD7\\nS\\n1\\n\\n\\n8\\n1\\nAppleton, Mrs. Edward Dale (Charlotte Lamson)\\nfemale\\n53.0\\n2\\n0\\n11769\\n51.4792\\nC101\\nS\\n1\\n\\n\\n\\n\\nSorting\\nWe can also sort our features in ascending or descending order.\\n1\\n2# Sorting\\ndf.sort_values(\"age\", ascending=False).head()\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n14\\n1\\nBarkworth, Mr. Algernon Henry Wilson\\nmale\\n80.0\\n0\\n0\\n27042\\n30.0000\\nA23\\nS\\n1\\n\\n\\n61\\n1\\nCavendish, Mrs. Tyrell William (Julia Florence...\\nfemale\\n76.0\\n1\\n0\\n19877\\n78.8500\\nC46\\nS\\n1\\n\\n\\n1235\\n3\\nSvensson, Mr. Johan\\nmale\\n74.0\\n0\\n0\\n347060\\n7.7750\\nNaN\\nS\\n0\\n\\n\\n135\\n1\\nGoldschmidt, Mr. George B\\nmale\\n71.0\\n0\\n0\\nPC 17754\\n34.6542\\nA5\\nC\\n0\\n\\n\\n9\\n1\\nArtagaveytia, Mr. Ramon\\nmale\\n71.0\\n0\\n0\\nPC 17609\\n49.5042\\nNaN\\nC\\n0\\n\\n\\n\\n\\nGrouping\\nWe can also get statistics across our features for certain groups. Here we wan to see the average of our continuous features based on whether the passenger survived or not.\\n1\\n2\\n3# Grouping\\nsurvived_group = df.groupby(\"survived\")\\nsurvived_group.mean()\\n\\n\\n\\n\\n\\nsurvived\\npclass\\nage\\nsibsp\\nparch\\nfare\\n\\n\\n\\n\\n0\\n2.500618\\n30.545369\\n0.521632\\n0.328801\\n23.353831\\n\\n\\n1\\n1.962000\\n28.918228\\n0.462000\\n0.476000\\n49.361184\\n\\n\\n\\n\\nIndexing\\nWe can use iloc to get rows or columns at particular positions in the dataframe.\\n1\\n2# Selecting row 0\\ndf.iloc[0, :]\\n\\n\\npclass                                  1\\nname        Allen, Miss. Elisabeth Walton\\nsex                                female\\nage                                    29\\nsibsp                                   0\\nparch                                   0\\nticket                              24160\\nfare                              211.338\\ncabin                                  B5\\nembarked                                S\\nsurvived                                1\\nName: 0, dtype: object\\n\\n1\\n2# Selecting a specific value\\ndf.iloc[0, 1]\\n\\n\\n\\'Allen, Miss. Elisabeth Walton\\'\\n\\nPreprocessing\\nAfter exploring, we can clean and preprocess our dataset.\\n\\nBe sure to check out our entire lesson focused on preprocessing in our MLOps course.\\n\\n1\\n2# Rows with at least one NaN value\\ndf[pd.isnull(df).any(axis=1)].head()\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n9\\n1\\nArtagaveytia, Mr. Ramon\\nmale\\n71.0\\n0\\n0\\nPC 17609\\n49.5042\\nNaN\\nC\\n0\\n\\n\\n13\\n1\\nBarber, Miss. Ellen \"Nellie\"\\nfemale\\n26.0\\n0\\n0\\n19877\\n78.8500\\nNaN\\nS\\n1\\n\\n\\n15\\n1\\nBaumann, Mr. John D\\nmale\\nNaN\\n0\\n0\\nPC 17318\\n25.9250\\nNaN\\nS\\n0\\n\\n\\n23\\n1\\nBidois, Miss. Rosalie\\nfemale\\n42.0\\n0\\n0\\nPC 17757\\n227.5250\\nNaN\\nC\\n1\\n\\n\\n25\\n1\\nBirnbaum, Mr. Jakob\\nmale\\n25.0\\n0\\n0\\n13905\\n26.0000\\nNaN\\nC\\n0\\n\\n\\n\\n\\n1\\n2\\n3\\n4# Drop rows with Nan values\\ndf = df.dropna() # removes rows with any NaN values\\ndf = df.reset_index() # reset\\'s row indexes in case any rows were dropped\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0000\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n1\\n1\\n1\\nAllison, Master. Hudson Trevor\\nmale\\n0.9167\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n1\\n\\n\\n2\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n3\\n3\\n1\\nAllison, Mr. Hudson Joshua Creighton\\nmale\\n30.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n4\\n4\\n1\\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nfemale\\n25.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n\\n\\n1\\n2\\n3# Dropping multiple columns\\ndf = df.drop([\"name\", \"cabin\", \"ticket\"], axis=1) # we won\\'t use text features for our initial basic models\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\nfemale\\n29.0000\\n0\\n0\\n211.3375\\nS\\n1\\n\\n\\n1\\n1\\n1\\nmale\\n0.9167\\n1\\n2\\n151.5500\\nS\\n1\\n\\n\\n2\\n2\\n1\\nfemale\\n2.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n3\\n3\\n1\\nmale\\n30.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n4\\n4\\n1\\nfemale\\n25.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n\\n\\n1\\n2\\n3\\n4# Map feature values\\ndf[\"sex\"] = df[\"sex\"].map( {\"female\": 0, \"male\": 1} ).astype(int)\\ndf[\"embarked\"] = df[\"embarked\"].dropna().map( {\"S\":0, \"C\":1, \"Q\":2} ).astype(int)\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n211.3375\\n0\\n1\\n\\n\\n1\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n151.5500\\n0\\n1\\n\\n\\n2\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n3\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n4\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n\\n\\nFeature engineering\\nWe\\'re now going to use feature engineering to create a column called family_size. We\\'ll first define a function called get_family_size that will determine the family size using the number of parents and siblings.\\n1\\n2\\n3\\n4# Lambda expressions to create new features\\ndef get_family_size(sibsp, parch):\\n    family_size = sibsp + parch\\n    return family_size\\n\\nOnce we define the function, we can use lambda to apply that function on each row (using the numbers of siblings and parents in each row to determine the family size for each row).\\n1\\n2df[\"family_size\"] = df[[\"sibsp\", \"parch\"]].apply(lambda x: get_family_size(x[\"sibsp\"], x[\"parch\"]), axis=1)\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\nfamily_size\\n\\n\\n\\n\\n0\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n211.3375\\n0\\n1\\n0\\n\\n\\n1\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n151.5500\\n0\\n1\\n3\\n\\n\\n2\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n3\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n4\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n\\n\\n1\\n2\\n3# Reorganize headers\\ndf = df[[\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"family_size\", \"fare\", \\'\"mbarked\", \"survived\"]]\\ndf.head()\\n\\n\\n\\n\\n\\n\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfamily_size\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n0\\n211.3375\\n0\\n1\\n\\n\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n3\\n151.5500\\n0\\n1\\n\\n\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n\\n\\n\\nTip\\nFeature engineering can be done in collaboration with domain experts that can guide us on what features to engineer and use.\\n\\nSave data\\nFinally, let\\'s save our preprocessed data into a new CSV file to use later.\\n1\\n2# Saving dataframe to CSV\\ndf.to_csv(\"processed_titanic.csv\", index=False)\\n\\n1\\n2# See the saved file\\n!ls -l\\n\\n\\ntotal 96\\n-rw-r--r-- 1 root root  6975 Dec  3 17:36 processed_titanic.csv\\ndrwxr-xr-x 1 root root  4096 Nov 21 16:30 sample_data\\n-rw-r--r-- 1 root root 85153 Dec  3 17:36 titanic.csv\\n\\nScaling\\nWhen working with very large datasets, our Pandas DataFrames can become very large and it can be very slow or impossible to operate on them. This is where packages that can distribute workloads or run on more efficient hardware can come in handy.\\n\\nDask: parallel computing to scale packages like Numpy, Pandas and scikit-learn on one/multiple machines.\\ncuDF: efficient dataframe loading and computation on a GPU.\\n\\nAnd, of course, we can combine these together (Dask-cuDF) to operate on partitions of a dataframe on the GPU.\\n\\nTo cite this content, please use:\\n1\\n2\\n3\\n4\\n5\\n6@article{madewithml,\\n    author       = {Goku Mohandas},\\n    title        = { Pandas - Made With ML },\\n    howpublished = {\\\\url{https://madewithml.com/}},\\n    year         = {2023}\\n}\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n¬© 2023 Anyscale, Inc.  Anyscale Privacy Policy\\n\\nMade with\\n\\nMaterial for MkDocs\\n\\n--- Content from https://www.geeksforgeeks.org/introduction-to-pandas-in-python/ ---\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTutorialsPython TutorialTaking Input in PythonPython OperatorsPython Data TypesPython NumbersPython StringPython ListsPython TuplesSets in PythonPython DictionaryPython Loops and Control FlowPython Conditional StatementsPython LoopsPython FunctionsPython OOPS ConceptPython Data StructuresPython DSALinked ListStackQueueTreeHeapHashingGraphSetsMapAdvance Data StructureSorting AlgorithmsSearching AlgorithmsPython Exception HandlingPython File HandlingPython ExercisesPython List ExercisePython String ExercisePython Tuple ExercisePython Dictionary ExercisePython Set ExercisePython Design PatternsPython Programming ExamplesPython Practice QuestionsJavaJava Programming LanguageJava TutorialData TypesVariablesOperatorsFlow Control in JavaLoops in JavaMethodsStringsArraysOOPs ConceptsOOPs ConceptsClasses and ObjectsAccess ModifiersInheritanceAbstractionEncapsulationPolymorphismInterfacePackagesMultithreadingFile HandlingRegular ExpressionJava CollectionsJava CollectionsCollection ClassList InterfaceArrayListLinkedList ClassQueue InterfaceSet InterfaceHashSet ClassMap InterfaceHashMap ClassHashTable ClassIteratorComparatorCollection Interview QuestionsJava 8 TutorialJava ProgramsJava Programming ExamplesJava Array ProgramsJava String ProgramsJava Date-Time ProgramsJava File Handling ProgramsJava Collection ProgramsJava JDBC ProgramsJava Apache POI ProgramsJava OpenCV ProgramsJava Interview QuestionsJava Interview QuestionsCore Java Interview Questions-FreshersJava Multithreading Interview QuestionsOOPs Interview Questions and AnswersJava ExercisesJava QuizJava QuizCore Java MCQJava ProjectsAdvance JavaSpring TutorialSpring Boot TutorialSpring Boot Interview QuestionsSpring MVC TutorialSpring MVC Interview QuestionsHibernate TutorialHibernate Interview QuestionsProgramming LanguagesCC++JavaScriptPHPR TutorialC#SQLScalaPerlGo LanguageKotlinSystem DesignSystem Design TutorialWhat is System DesignKey Terminologies in System DesignAnalysis and Architecture of SystemsScalability in System DesignDatabases in System DesignHigh Level Design or HLDLow Level Design or LLDCase Studies in Designing SystemsComplete System Design TutorialSoftware Design PatternsSystem Design RoadmapTop 10 System Design Interview Questions and AnswersInterview CornerCompany PreparationTop TopicsPractice Company QuestionsInterview ExperiencesExperienced InterviewsInternship InterviewsCompetitive ProgrammingMultiple Choice QuizzesAptitude for PlacementsComputer Science SubjectsOperating SystemDBMSComputer NetworksEngineering MathematicsComputer Organization and ArchitectureTheory of ComputationCompiler DesignDigital LogicSoftware EngineeringDevOpsGITAWSDockerKubernetesMicrosoft Azure TutorialGoogle Cloud PlatformLinuxLinux TutorialLinux Commands A-ZLinux Commands CheatsheetFile Permission CommandsLinux System AdministrationLinux File SystemLinux Shell ScriptingLinux NetworkingLinux Interview QuestionsSoftware TestingSoftware Testing TutorialSoftware Engineering TutorialTesting Interview QuestionsJiraDatabasesDBMS TutorialSQL TutorialPostgreSQL TutorialMongoDB TutorialSQL Interview QuestionsMySQL Interview QuestionsPL/SQL Interview QuestionsAndroidAndroid TutorialAndroid Studio TutorialKotlin For AndroidAndroid ProjectsAndroid Interview Questions6 Weeks of Android App DevelopmentExcelMS Excel TutorialIntroduction to MS ExcelData Analysis in ExcelBasic Excel Formulas & FunctionsData Analysis in Advanced ExcelWorkbooksStatistical FunctionsData Visualization in ExcelPivot Tables in ExcelExcel Spreadsheets in PythonBasic Excel ShortcutsMathematicsNumber SystemAlgebraLinear AlgebraTrigonometrySet TheoryStatisticsProbabilityGeometryMensurationLogarithmsCalculusDSAData StructuresArraysMatrixStringsLinked ListSingly Linked ListDoubly Linked ListCircular Linked ListDoubly Circular Linked ListLinked List TutorialStackQueueTreeGeneric TreeBinary TreeBinary Search TreeAVL TreeB TreeB+ TreeRed Black TreeTree Data Structure TutorialHeapHashingGraphSet Data StructureMap Data StructureAdvanced Data StructureData Structures TutorialAlgorithmsAnalysis of AlgorithmsDesign and Analysis of AlgorithmsAsymptotic AnalysisAsymptotic NotationsWorst, Average and Best CasesSearching AlgorithmsLinear SearchBinary SearchSearching Algorithms TutorialSorting AlgorithmsSelection SortBubble SortInsertion SortMerge SortQuick SortHeap SortCounting SortRadix SortBucket SortSorting Algorithms TutorialGreedy AlgorithmsDynamic ProgrammingGraph AlgorithmsPattern SearchingRecursionBacktrackingDivide and ConquerMathematical AlgorithmsGeometric AlgorithmsBitwise AlgorithmsRandomized AlgorithmsBranch and BoundAlgorithms TutorialDSA TutorialPracticeAll DSA ProblemsProblem of the DayCompany Wise Coding PracticeAmazonMicrosoftFlipkartExplore AllGfG SDE SheetPractice Problems Difficulty WiseSchoolBasicEasyMediumHardLanguage Wise Coding PracticeCPPJavaPythonCurated DSA ListsBeginner\\'s DSA SheetTop 50 Array ProblemsTop 50 String ProblemsTop 50 DP ProblemsTop 50 Graph ProblemsTop 50 Tree ProblemsCompetitive ProgrammingCompany Wise SDE SheetsFacebook SDE SheetAmazon SDE SheetApple SDE SheetNetflix SDE SheetGoogle SDE SheetDSA Cheat SheetsSDE SheetDSA Sheet for BeginnersFAANG Coding SheetProduct-Based Coding SheetCompany-Wise Preparation SheetTop Interview QuestionsPuzzlesAll PuzzlesTop 100 Puzzles Asked In InterviewsTop 20 Puzzles Commonly Asked During SDE InterviewsData SciencePython TutorialR TutorialMachine LearningData Science using PythonData Science using RData Science PackagesPandas TutorialNumPy TutorialData VisualizationPython Data Visualization TutorialData Visualization with RData AnalysisData Analysis with PythonData Analysis with RDeep LearningNLP TutorialWeb TechHTML TutorialCSS TutorialJavaScript TutorialPHP TutorialReactJS TutorialNodeJS TutorialAngularJS TutorialBootstrap TutorialTypescriptWeb Development Using PythonDjangoDjango TutorialDjango ProjectsDjango Interview QuestionsFlaskFlask TutorialFlask ProjectsFlask Interview QuestionsPostmanGithubWordpress TutorialWeb DesignCheat SheetsHTML Cheat SheetCSS Cheat SheetJavaScript Cheat SheetReact Cheat SheetAngular Cheat SheetjQuery Cheat SheetBootstrap Cheat SheetLearn Complete Web DevelopmentCoursesGo PremiumCoding for EveryoneDSA to DevelopmentMachine Learning & Data ScienceGenerative AI & ChatGPTBecome AWS CertifiedDSA CoursesData Structure & Algorithm(C++/JAVA)Data Structure & Algorithm(Python)Data Structure & Algorithm(JavaScript)Programming LanguagesCPPJavaPythonJavaScriptC\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAI ML DSData ScienceData AnalysisData VisualizationMachine LearningDeep LearningNLPComputer VisionArtificial IntelligenceAI ML DS Interview SeriesAI ML DS Projects seriesData EngineeringWeb Scrapping \\n\\n\\n\\n\\n‚ñ≤\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen In App\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPandas Introduction\\n\\n\\nLast Updated : \\n30 Jul, 2024\\n\\n\\n\\n \\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSummarize\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n \\n\\n\\nLike Article\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\nSave\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n\\n\\n\\n\\nReport\\n\\n\\n\\n\\n\\n\\n\\nPandas is a powerful and open-source Python library. The Pandas library is used for data manipulation and analysis. Pandas consist of data structures and functions to perform efficient operations on data.\\nThis free tutorial will cover an overview of Pandas, covering the fundamentals of Python Pandas.\\nTable of Content\\nWhat is Pandas Libray in Python?What is Python Pandas used for?Getting Started with PandasData Structures in Pandas LibraryPandas SeriesPandas DataFrameHow to run the Pandas Program in Python?What is Pandas Libray in Python?Pandas is a powerful and versatile library that simplifies the tasks of data manipulation in Python. Pandas is well-suited for working with tabular data, such as spreadsheets or SQL tables.\\nThe Pandas library is an essential tool for data analysts, scientists, and engineers working with structured data in Python.\\nWhat is Python Pandas used for?The Pandas library is generally used for data science, but have you wondered why? This is because the Pandas library is used in conjunction with other libraries that are used for data science.\\nIt is built on top of the NumPy library which means that a lot of the structures of NumPy are used or replicated in Pandas.\\nThe data produced by Pandas is often used as input for plotting functions in Matplotlib, statistical analysis in SciPy, and machine learning algorithms in Scikit-learn.\\nYou must be wondering, Why should you use the Pandas Library. Python‚Äôs Pandas library is the best tool to analyze, clean, and manipulate data.\\nHere is a list of things that we can do using Pandas.\\nData set cleaning, merging, and joining.Easy handling of missing data (represented as NaN) in floating point as well as non-floating point data.Columns can be inserted and deleted from DataFrame and higher-dimensional objects.Powerful group by functionality for performing split-apply-combine operations on data sets.Data Visualization.Getting Started with PandasLet‚Äôs see how to start working with the Python Pandas library:\\nInstalling PandasThe first step in working with Pandas is to ensure whether it is installed in the system or not. \\xa0If not, then we need to install it on our system using the pip command.\\nFollow these steps to install Pandas:\\nStep 1: Type ‚Äòcmd‚Äô in the search box and open it.Step 2: Locate the folder using the cd command where the python-pip file has been installed.Step 3: After locating it, type the command:\\npip install pandasFor more reference, take a look at this article on installing pandas follows.\\nImporting PandasAfter the Pandas have been installed in the system, you need to import the library. This module is generally imported as follows:\\nimport pandas as pdNote: Here, pd is referred to as an alias for the Pandas. However, it is not necessary to import the library using the alias, it just helps in writing less code every time a method or property is called.\\xa0\\nData Structures in Pandas LibraryPandas generally provide two data structures for manipulating data. They are:\\nSeriesDataFramePandas SeriesA Pandas Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, Python objects, etc.). The axis labels are collectively called indexes.\\nThe Pandas Series is nothing but a column in an Excel sheet. Labels need not be unique but must be of a hashable type.\\nThe object supports both integer and label-based indexing and provides a host of methods for performing operations involving the index.\\nPandas SeriesCreating a SeriesPandas Series is created by loading the datasets from existing storage (which can be a SQL database, a CSV file, or an Excel file).\\nPandas Series can be created from lists, dictionaries, scalar values, etc.\\nExample: Creating a series using the Pandas Library.\\n\\nPython\\n\\nimport pandas as pd \\nimport numpy as np\\n\\n# Creating empty series \\nser = pd.Series() \\nprint(\"Pandas Series: \", ser) \\n\\n# simple array \\ndata = np.array([\\'g\\', \\'e\\', \\'e\\', \\'k\\', \\'s\\']) \\n  \\nser = pd.Series(data) \\nprint(\"Pandas Series:\\\\n\", ser)\\n\\nOutput\\nPandas Series: Series([], dtype: float64)Pandas Series:0    g1    e2    e3    k4    sdtype: objectFor more information, refer to Creating a Pandas Series\\nPandas DataFramePandas DataFrame is a two-dimensional data structure with labeled axes (rows and columns).\\nCreating DataFramePandas DataFrame is created by loading the datasets from existing storage (which can be a SQL database, a CSV file, or an Excel file).\\nPandas DataFrame can be created from lists, dictionaries, a list of dictionaries, etc.\\nExample: Creating a DataFrame Using the Pandas Library\\n\\nPython\\n\\nimport pandas as pd \\n  \\n# Calling DataFrame constructor \\ndf = pd.DataFrame() \\nprint(df)\\n\\n# list of strings \\nlst = [\\'Geeks\\', \\'For\\', \\'Geeks\\', \\'is\\', \\'portal\\', \\'for\\', \\'Geeks\\'] \\n  \\n# Calling DataFrame constructor on list \\ndf = pd.DataFrame(lst) \\nprint(df)\\n\\nOutput:\\nEmpty DataFrameColumns: []Index: []        00   Geeks1     For2   Geeks3      is4  portal5     for6   GeeksNote: For more information, refer to Creating a Pandas DataFrame\\xa0\\nHow to run the Pandas Program in Python?The Pandas program can be run from any text editor, but it is recommended to use Jupyter Notebook for this, as Jupyter gives you the ability to execute code in a particular cell rather than the entire file.\\nJupyter also provides an easy way to visualize Pandas DataFrame and plots.\\nNote: For more information on Jupyter Notebook, refer to How To Use Jupyter Notebook ‚Äì An Ultimate Guide\\xa0\\nConclusionThis tutorial provides a solid foundation for mastering the Pandas library, from basic operations to advanced techniques. We have also covered the Pandas data structures (series and DataFrame) with examples.\\nAfter completing this tutorial, you will gain a complete idea of what is Python Pandas. What is Pandas used for? and how to use Python Pandas.\\nAs you apply these skills to your projects, you will discover how Pandas enhances your ability to explore, clean, and analyze data, making it an indispensable tool in the data scientist‚Äôs toolkit.\\nElevate your coding journey with a Premium subscription. Benefit from ad-free learning, unlimited article summaries, an AI bot, access to 35+ courses, and more-available only with GeeksforGeeks Premium! Explore now!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nN\\n\\n\\n\\n\\n \\n\\nnikhilaggarwal3 \\n\\n\\n\\n\\n\\n Follow \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n\\n\\nPrevious Article\\n\\n\\n\\nPandas Tutorial\\n\\n\\n\\n\\nNext Article\\n\\n\\n\\n\\nHow to Install Pandas in Python?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Please Login to comment...\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSimilar Reads\\n\\n\\n\\nPandas Series dt.day_name() Method | Get Day From Date in Pandas\\nPandas dt.day_name() method returns the day names of the DateTime Series objects with specified locale. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31 08:45\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) resu\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.weekday | Find Day of the Week in Pandas\\nThe dt.weekday attribute returns the day of the week. It is assumed the week starts on Monday, which is denoted by 0, and ends on Sunday which is denoted by 6. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.weekofyear Method | Get Week of Year in Pandas Series\\nThe dt.weekofyear attribute returns a Series containing the week ordinal of the year in the underlying data of the given series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index =\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.dayofyear | Get Day of Year in Pandas\\nPandas dt.dayofyear attribute returns the ordinal day of the year in the underlying DateTime data in the given Series object. Example: C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr =\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.minute | Extract Minute from DateTime Series in Pandas\\nPandas Series.dt.minute attribute returns a NumPy array containing the minutes of the DateTime in the underlying data of the given series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\']\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.days_in_month | Get Total Number of Days in Month in Pandas\\nThe Pandas dt.days_in_month attribute returns the total number of days in the month for the given Series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) r\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.dayofweek | Get Day of Week from DateTime Series in Pandas\\nPandas dt.dayofweek attribute returns the day of the week from the given DateTime Series Object. It is assumed the week starts on Monday, which is denoted by 0, and ends on Sunday which is denoted by 6. Example: C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.freq | Retrieve Frequency of Pandas Time Series\\nPandas dt.freq attribute returns the time series frequency applied on the given series object if any, else it returns None. Examples C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_da\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.daysinmonth | Get Number of Days in Month in Pandas Series\\nThe dt.daysinmonth attribute returns the number of days in the month for the given DateTime series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) result\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.normalize() | Normalize Time in Pandas Series\\nThe dt.normalize() method converts times to midnight. The time component of the date-time is converted to midnight i.e. 00:00:00. This is useful in cases when the time does not matter. Length is unaltered. The time zones are unaffected. Example: C/C++ Code import pandas as pd sr = pd.Series(pd.date_range(\\'2012-12-31 09:45\\', periods = 5, freq = \\'M\\',\\n\\n\\n\\n2 min read\\n\\n\\n\\nView More Articles\\n\\n\\n\\nArticle Tags : \\n\\n\\nAI-ML-DS\\n\\n\\nPandas\\n\\n\\nPython pandas-basics\\n \\n\\n\\n\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nExplore More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n                     Corporate & Communications Address:- A-143, 9th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) | Registered Address:- K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCompanyAbout UsLegalIn MediaContact UsAdvertise with usGFG Corporate SolutionPlacement Training ProgramGeeksforGeeks CommunityLanguagesPythonJavaC++PHPGoLangSQLR LanguageAndroid TutorialTutorials ArchiveDSAData StructuresAlgorithmsDSA for BeginnersBasic DSA ProblemsDSA RoadmapTop 100 DSA Interview ProblemsDSA Roadmap by Sandeep JainAll Cheat SheetsData Science & MLData Science With PythonData Science For BeginnerMachine Learning TutorialML MathsData Visualisation TutorialPandas TutorialNumPy TutorialNLP TutorialDeep Learning TutorialWeb TechnologiesHTMLCSSJavaScriptTypeScriptReactJSNextJSBootstrapWeb DesignPython TutorialPython Programming ExamplesPython ProjectsPython TkinterWeb ScrapingOpenCV TutorialPython Interview QuestionDjangoComputer ScienceOperating SystemsComputer NetworkDatabase Management SystemSoftware EngineeringDigital Logic DesignEngineering MathsSoftware DevelopmentSoftware TestingDevOpsGitLinuxAWSDockerKubernetesAzureGCPDevOps RoadmapSystem DesignHigh Level DesignLow Level DesignUML DiagramsInterview GuideDesign PatternsOOADSystem Design BootcampInterview QuestionsInteview PreparationCompetitive ProgrammingTop DS or Algo for CPCompany-Wise Recruitment ProcessCompany-Wise PreparationAptitude PreparationPuzzlesSchool SubjectsMathematicsPhysicsChemistryBiologySocial ScienceEnglish GrammarCommerceWorld GKGeeksforGeeks VideosDSAPythonJavaC++Web DevelopmentData ScienceCS Subjects \\n\\n\\n\\n\\n\\n\\n@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        We use cookies to ensure you have the best browsing experience on our website. By using our site, you\\r\\n        acknowledge that you have read and understood our\\r\\n        Cookie Policy &\\r\\n        Privacy Policy\\n\\n\\r\\n        Got It !\\r\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nImprovement\\n\\n\\n\\n\\n\\nPlease go through our recently updated Improvement Guidelines before submitting any improvements.\\nThis improvement is locked by another user right now. You can suggest the changes for now and it will be under \\'My Suggestions\\' Tab on Write.\\nYou will be notified via email once the article is available for improvement.\\r\\n                        Thank you for your valuable feedback!\\r\\n                    \\n\\nSuggest changes\\n\\n\\n\\nPlease go through our recently updated Improvement Guidelines before submitting any improvements.\\n\\n\\nSuggest Changes\\nHelp us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\nEnhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest Changes\\n\\n\\n\\n\\n\\n\\n\\nmin 4 words, max CharLimit:2000\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat kind of Experience do you want to share?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInterview Experiences\\n\\n\\n\\n\\n\\n\\n\\nAdmission Experiences\\n\\n\\n\\n\\n\\n\\n\\nCareer Journeys\\n\\n\\n\\n\\n\\n\\n\\nWork Experiences\\n\\n\\n\\n\\n\\n\\n\\nCampus Experiences\\n\\n\\n\\n\\n\\n\\n\\nCompetitive Exam Experiences\\n\\n\\n\\n\\n\\n\\n                        Can\\'t choose a topic to write? click here for suggested topics\\n                    \\n\\n\\n\\n                       Write and publish your own Article\\n\\n--- Content from https://madewithml.com/courses/foundations/pandas/ ---\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n‚ö°Ô∏è Checkout our new End-to-end LLM Workflows Guide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMade With ML\\n\\n\\n\\n\\nPandas for Machine Learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInitializing search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGokuMohandas/MadeWithML\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\n\\n\\nAbout\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\nCommunity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMade With ML\\n\\n\\n\\n\\n\\n\\n\\nGokuMohandas/MadeWithML\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\n\\n\\nAbout\\n\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\n\\nCourse\\n\\n\\n\\n\\nLessons\\n\\n\\n\\n\\n\\nüé® \\xa0 Design\\n\\n\\n\\n\\n\\nüé® \\xa0 Design\\n\\n\\n\\n\\nSetup\\n\\n\\n\\n\\nProduct\\n\\n\\n\\n\\nSystems\\n\\n\\n\\n\\n\\n\\n\\n\\nüî¢ \\xa0 Data\\n\\n\\n\\n\\n\\nüî¢ \\xa0 Data\\n\\n\\n\\n\\nPreparation\\n\\n\\n\\n\\nExploration\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nDistributed\\n\\n\\n\\n\\n\\n\\n\\n\\nüìà \\xa0 Model\\n\\n\\n\\n\\n\\nüìà \\xa0 Model\\n\\n\\n\\n\\nTraining\\n\\n\\n\\n\\nTracking\\n\\n\\n\\n\\nTuning\\n\\n\\n\\n\\nEvaluation\\n\\n\\n\\n\\nServing\\n\\n\\n\\n\\n\\n\\n\\n\\nüíª \\xa0 Developing\\n\\n\\n\\n\\n\\nüíª \\xa0 Developing\\n\\n\\n\\n\\nScripting\\n\\n\\n\\n\\nCLI\\n\\n\\n\\n\\n\\n\\n\\n\\nüì¶ \\xa0 Utilities\\n\\n\\n\\n\\n\\nüì¶ \\xa0 Utilities\\n\\n\\n\\n\\nLogging\\n\\n\\n\\n\\nDocumentation\\n\\n\\n\\n\\nStyling\\n\\n\\n\\n\\nPre-commit\\n\\n\\n\\n\\n\\n\\n\\n\\n‚úÖ \\xa0 Testing\\n\\n\\n\\n\\n\\n‚úÖ \\xa0 Testing\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\nData\\n\\n\\n\\n\\nModels\\n\\n\\n\\n\\n\\n\\n\\n\\n‚ôªÔ∏è \\xa0 Reproducibility\\n\\n\\n\\n\\n\\n‚ôªÔ∏è \\xa0 Reproducibility\\n\\n\\n\\n\\nVersioning\\n\\n\\n\\n\\n\\n\\n\\n\\nüöÄ \\xa0 Production\\n\\n\\n\\n\\n\\nüöÄ \\xa0 Production\\n\\n\\n\\n\\nJobs & Services\\n\\n\\n\\n\\nCI/CD workflows\\n\\n\\n\\n\\nMonitoring\\n\\n\\n\\n\\nData engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\n\\nFoundations\\n\\n\\n\\n\\nLessons\\n\\n\\n\\n\\n\\nüõ† \\xa0 Toolkit\\n\\n\\n\\n\\n\\nüõ† \\xa0 Toolkit\\n\\n\\n\\n\\nNotebooks\\n\\n\\n\\n\\nPython\\n\\n\\n\\n\\nNumPy\\n\\n\\n\\n\\n\\nPandas\\n\\n\\n\\nPandas\\n\\n\\n\\n\\nTable of contents\\n\\n\\n\\n\\nSet up\\n\\n\\n\\n\\nLoad data\\n\\n\\n\\n\\nExploratory data analysis (EDA)\\n\\n\\n\\n\\nFiltering\\n\\n\\n\\n\\nSorting\\n\\n\\n\\n\\nGrouping\\n\\n\\n\\n\\nIndexing\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nFeature engineering\\n\\n\\n\\n\\nSave data\\n\\n\\n\\n\\nScaling\\n\\n\\n\\n\\n\\n\\n\\nPyTorch\\n\\n\\n\\n\\n\\n\\n\\n\\nüî• \\xa0 Machine Learning\\n\\n\\n\\n\\n\\nüî• \\xa0 Machine Learning\\n\\n\\n\\n\\nLinear regression\\n\\n\\n\\n\\nLogistic regression\\n\\n\\n\\n\\nNeural networks\\n\\n\\n\\n\\nData quality\\n\\n\\n\\n\\nUtilities\\n\\n\\n\\n\\n\\n\\n\\n\\nü§ñ \\xa0 Deep Learning\\n\\n\\n\\n\\n\\nü§ñ \\xa0 Deep Learning\\n\\n\\n\\n\\nCNNs\\n\\n\\n\\n\\nEmbeddings\\n\\n\\n\\n\\nRNNs\\n\\n\\n\\n\\nAttention\\n\\n\\n\\n\\nTransformers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\nCommunity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of contents\\n\\n\\n\\n\\nSet up\\n\\n\\n\\n\\nLoad data\\n\\n\\n\\n\\nExploratory data analysis (EDA)\\n\\n\\n\\n\\nFiltering\\n\\n\\n\\n\\nSorting\\n\\n\\n\\n\\nGrouping\\n\\n\\n\\n\\nIndexing\\n\\n\\n\\n\\nPreprocessing\\n\\n\\n\\n\\nFeature engineering\\n\\n\\n\\n\\nSave data\\n\\n\\n\\n\\nScaling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPandas for Machine Learning\\n\\n\\n\\n\\n\\n View all lessons\\n\\n\\n\\n\\n\\nData manipulation using the Pandas library.\\n\\n\\n\\n\\n\\n\\n\\nGoku Mohandas\\n\\n\\n\\n\\n ¬∑\\n\\n\\n\\n ¬∑\\n\\n\\n\\n ¬∑\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRepository\\n ¬∑ \\n\\n\\n\\nNotebook\\n\\n\\n\\n\\n\\n√ó\\n\\n\\n\\n\\n\\n\\n\\nSubscribe to our newsletter\\nüì¨\\xa0 Receive new lessons straight to your inbox (once a month) and join 40K+\\ndevelopers in learning how to responsibly deliver value with ML.\\n\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\n\\nSet up\\nFirst we\\'ll import the NumPy and Pandas libraries and set seeds for reproducibility. We\\'ll also download the dataset we\\'ll be working with to disk.\\n1\\n2import numpy as np\\nimport pandas as pd\\n\\n1\\n2# Set seed for reproducibility\\nnp.random.seed(seed=1234)\\n\\n\\nLoad data\\nWe\\'re going to work with the Titanic dataset which has data on the people who embarked the RMS Titanic in 1912 and whether they survived the expedition or not. It\\'s a very common and rich dataset which makes it very apt for exploratory data analysis with Pandas.\\nLet\\'s load the data from the CSV file into a Pandas dataframe. The header=0 signifies that the first row (0th index) is a header row which contains the names of each column in our dataset.\\n1\\n2\\n3# Read from CSV to Pandas DataFrame\\nurl = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/titanic.csv\"\\ndf = pd.read_csv(url, header=0)\\n\\n1\\n2# First few items\\ndf.head(3)\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0000\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n1\\n1\\nAllison, Master. Hudson Trevor\\nmale\\n0.9167\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n1\\n\\n\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n\\n\\nThese are the different features:\\n\\nclass: class of travel\\nname: full name of the passenger\\nsex: gender\\nage: numerical age\\nsibsp: # of siblings/spouse aboard\\nparch: number of parents/child aboard\\nticket: ticket number\\nfare: cost of the ticket\\ncabin: location of room\\nembarked: port that the passenger embarked at\\nsurvived: survival metric (0 - died, 1 - survived)\\n\\nExploratory data analysis (EDA)\\nNow that we loaded our data, we\\'re ready to start exploring it to find interesting information.\\n\\nBe sure to check out our entire lesson focused on EDA in our MLOps course.\\n\\n1import matplotlib.pyplot as plt\\n\\n\\nWe can use .describe() to extract some standard details about our numerical features.\\n1\\n2# Describe features\\ndf.describe()\\n\\n\\n\\n\\n\\n\\npclass\\nage\\nsibsp\\nparch\\nfare\\nsurvived\\n\\n\\n\\n\\ncount\\n1309.000000\\n1046.000000\\n1309.000000\\n1309.000000\\n1308.000000\\n1309.000000\\n\\n\\nmean\\n2.294882\\n29.881135\\n0.498854\\n0.385027\\n33.295479\\n0.381971\\n\\n\\nstd\\n0.837836\\n14.413500\\n1.041658\\n0.865560\\n51.758668\\n0.486055\\n\\n\\nmin\\n1.000000\\n0.166700\\n0.000000\\n0.000000\\n0.000000\\n0.000000\\n\\n\\n25%\\n2.000000\\n21.000000\\n0.000000\\n0.000000\\n7.895800\\n0.000000\\n\\n\\n50%\\n3.000000\\n28.000000\\n0.000000\\n0.000000\\n14.454200\\n0.000000\\n\\n\\n75%\\n3.000000\\n39.000000\\n1.000000\\n0.000000\\n31.275000\\n1.000000\\n\\n\\nmax\\n3.000000\\n80.000000\\n8.000000\\n9.000000\\n512.329200\\n1.000000\\n\\n\\n\\n\\n1\\n2\\n3\\n4\\n5\\n6\\n7# Correlation matrix\\nplt.matshow(df.corr())\\ncontinuous_features = df.describe().columns\\nplt.xticks(range(len(continuous_features)), continuous_features, rotation=\"45\")\\nplt.yticks(range(len(continuous_features)), continuous_features, rotation=\"45\")\\nplt.colorbar()\\nplt.show()\\n\\n\\n\\n\\nWe can also use .hist() to view the histogram of values for each feature.\\n1\\n2# Histograms\\ndf[\"age\"].hist()\\n\\n\\n\\n\\n1\\n2# Unique values\\ndf[\"embarked\"].unique()\\n\\n\\narray([\\'S\\', \\'C\\', nan, \\'Q\\'], dtype=object)\\n\\nFiltering\\nWe can filter our data by features and even by specific values (or value ranges) within specific features.\\n1\\n2# Selecting data by feature\\ndf[\"name\"].head()\\n\\n\\n0                      Allen, Miss. Elisabeth Walton\\n1                     Allison, Master. Hudson Trevor\\n2                       Allison, Miss. Helen Loraine\\n3               Allison, Mr. Hudson Joshua Creighton\\n4    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nName: name, dtype: object\\n\\n1\\n2# Filtering\\ndf[df[\"sex\"]==\"female\"].head() # only the female data appear\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n4\\n1\\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nfemale\\n25.0\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n6\\n1\\nAndrews, Miss. Kornelia Theodosia\\nfemale\\n63.0\\n1\\n0\\n13502\\n77.9583\\nD7\\nS\\n1\\n\\n\\n8\\n1\\nAppleton, Mrs. Edward Dale (Charlotte Lamson)\\nfemale\\n53.0\\n2\\n0\\n11769\\n51.4792\\nC101\\nS\\n1\\n\\n\\n\\n\\nSorting\\nWe can also sort our features in ascending or descending order.\\n1\\n2# Sorting\\ndf.sort_values(\"age\", ascending=False).head()\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n14\\n1\\nBarkworth, Mr. Algernon Henry Wilson\\nmale\\n80.0\\n0\\n0\\n27042\\n30.0000\\nA23\\nS\\n1\\n\\n\\n61\\n1\\nCavendish, Mrs. Tyrell William (Julia Florence...\\nfemale\\n76.0\\n1\\n0\\n19877\\n78.8500\\nC46\\nS\\n1\\n\\n\\n1235\\n3\\nSvensson, Mr. Johan\\nmale\\n74.0\\n0\\n0\\n347060\\n7.7750\\nNaN\\nS\\n0\\n\\n\\n135\\n1\\nGoldschmidt, Mr. George B\\nmale\\n71.0\\n0\\n0\\nPC 17754\\n34.6542\\nA5\\nC\\n0\\n\\n\\n9\\n1\\nArtagaveytia, Mr. Ramon\\nmale\\n71.0\\n0\\n0\\nPC 17609\\n49.5042\\nNaN\\nC\\n0\\n\\n\\n\\n\\nGrouping\\nWe can also get statistics across our features for certain groups. Here we wan to see the average of our continuous features based on whether the passenger survived or not.\\n1\\n2\\n3# Grouping\\nsurvived_group = df.groupby(\"survived\")\\nsurvived_group.mean()\\n\\n\\n\\n\\n\\nsurvived\\npclass\\nage\\nsibsp\\nparch\\nfare\\n\\n\\n\\n\\n0\\n2.500618\\n30.545369\\n0.521632\\n0.328801\\n23.353831\\n\\n\\n1\\n1.962000\\n28.918228\\n0.462000\\n0.476000\\n49.361184\\n\\n\\n\\n\\nIndexing\\nWe can use iloc to get rows or columns at particular positions in the dataframe.\\n1\\n2# Selecting row 0\\ndf.iloc[0, :]\\n\\n\\npclass                                  1\\nname        Allen, Miss. Elisabeth Walton\\nsex                                female\\nage                                    29\\nsibsp                                   0\\nparch                                   0\\nticket                              24160\\nfare                              211.338\\ncabin                                  B5\\nembarked                                S\\nsurvived                                1\\nName: 0, dtype: object\\n\\n1\\n2# Selecting a specific value\\ndf.iloc[0, 1]\\n\\n\\n\\'Allen, Miss. Elisabeth Walton\\'\\n\\nPreprocessing\\nAfter exploring, we can clean and preprocess our dataset.\\n\\nBe sure to check out our entire lesson focused on preprocessing in our MLOps course.\\n\\n1\\n2# Rows with at least one NaN value\\ndf[pd.isnull(df).any(axis=1)].head()\\n\\n\\n\\n\\n\\n\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n9\\n1\\nArtagaveytia, Mr. Ramon\\nmale\\n71.0\\n0\\n0\\nPC 17609\\n49.5042\\nNaN\\nC\\n0\\n\\n\\n13\\n1\\nBarber, Miss. Ellen \"Nellie\"\\nfemale\\n26.0\\n0\\n0\\n19877\\n78.8500\\nNaN\\nS\\n1\\n\\n\\n15\\n1\\nBaumann, Mr. John D\\nmale\\nNaN\\n0\\n0\\nPC 17318\\n25.9250\\nNaN\\nS\\n0\\n\\n\\n23\\n1\\nBidois, Miss. Rosalie\\nfemale\\n42.0\\n0\\n0\\nPC 17757\\n227.5250\\nNaN\\nC\\n1\\n\\n\\n25\\n1\\nBirnbaum, Mr. Jakob\\nmale\\n25.0\\n0\\n0\\n13905\\n26.0000\\nNaN\\nC\\n0\\n\\n\\n\\n\\n1\\n2\\n3\\n4# Drop rows with Nan values\\ndf = df.dropna() # removes rows with any NaN values\\ndf = df.reset_index() # reset\\'s row indexes in case any rows were dropped\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nname\\nsex\\nage\\nsibsp\\nparch\\nticket\\nfare\\ncabin\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\nAllen, Miss. Elisabeth Walton\\nfemale\\n29.0000\\n0\\n0\\n24160\\n211.3375\\nB5\\nS\\n1\\n\\n\\n1\\n1\\n1\\nAllison, Master. Hudson Trevor\\nmale\\n0.9167\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n1\\n\\n\\n2\\n2\\n1\\nAllison, Miss. Helen Loraine\\nfemale\\n2.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n3\\n3\\n1\\nAllison, Mr. Hudson Joshua Creighton\\nmale\\n30.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n4\\n4\\n1\\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)\\nfemale\\n25.0000\\n1\\n2\\n113781\\n151.5500\\nC22 C26\\nS\\n0\\n\\n\\n\\n\\n1\\n2\\n3# Dropping multiple columns\\ndf = df.drop([\"name\", \"cabin\", \"ticket\"], axis=1) # we won\\'t use text features for our initial basic models\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\nfemale\\n29.0000\\n0\\n0\\n211.3375\\nS\\n1\\n\\n\\n1\\n1\\n1\\nmale\\n0.9167\\n1\\n2\\n151.5500\\nS\\n1\\n\\n\\n2\\n2\\n1\\nfemale\\n2.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n3\\n3\\n1\\nmale\\n30.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n4\\n4\\n1\\nfemale\\n25.0000\\n1\\n2\\n151.5500\\nS\\n0\\n\\n\\n\\n\\n1\\n2\\n3\\n4# Map feature values\\ndf[\"sex\"] = df[\"sex\"].map( {\"female\": 0, \"male\": 1} ).astype(int)\\ndf[\"embarked\"] = df[\"embarked\"].dropna().map( {\"S\":0, \"C\":1, \"Q\":2} ).astype(int)\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n211.3375\\n0\\n1\\n\\n\\n1\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n151.5500\\n0\\n1\\n\\n\\n2\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n3\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n4\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n151.5500\\n0\\n0\\n\\n\\n\\n\\nFeature engineering\\nWe\\'re now going to use feature engineering to create a column called family_size. We\\'ll first define a function called get_family_size that will determine the family size using the number of parents and siblings.\\n1\\n2\\n3\\n4# Lambda expressions to create new features\\ndef get_family_size(sibsp, parch):\\n    family_size = sibsp + parch\\n    return family_size\\n\\nOnce we define the function, we can use lambda to apply that function on each row (using the numbers of siblings and parents in each row to determine the family size for each row).\\n1\\n2df[\"family_size\"] = df[[\"sibsp\", \"parch\"]].apply(lambda x: get_family_size(x[\"sibsp\"], x[\"parch\"]), axis=1)\\ndf.head()\\n\\n\\n\\n\\n\\n\\nindex\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfare\\nembarked\\nsurvived\\nfamily_size\\n\\n\\n\\n\\n0\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n211.3375\\n0\\n1\\n0\\n\\n\\n1\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n151.5500\\n0\\n1\\n3\\n\\n\\n2\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n3\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n4\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n151.5500\\n0\\n0\\n3\\n\\n\\n\\n\\n1\\n2\\n3# Reorganize headers\\ndf = df[[\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"family_size\", \"fare\", \\'\"mbarked\", \"survived\"]]\\ndf.head()\\n\\n\\n\\n\\n\\n\\npclass\\nsex\\nage\\nsibsp\\nparch\\nfamily_size\\nfare\\nembarked\\nsurvived\\n\\n\\n\\n\\n0\\n1\\n0\\n29.0000\\n0\\n0\\n0\\n211.3375\\n0\\n1\\n\\n\\n1\\n1\\n1\\n0.9167\\n1\\n2\\n3\\n151.5500\\n0\\n1\\n\\n\\n2\\n1\\n0\\n2.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n3\\n1\\n1\\n30.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n4\\n1\\n0\\n25.0000\\n1\\n2\\n3\\n151.5500\\n0\\n0\\n\\n\\n\\n\\n\\nTip\\nFeature engineering can be done in collaboration with domain experts that can guide us on what features to engineer and use.\\n\\nSave data\\nFinally, let\\'s save our preprocessed data into a new CSV file to use later.\\n1\\n2# Saving dataframe to CSV\\ndf.to_csv(\"processed_titanic.csv\", index=False)\\n\\n1\\n2# See the saved file\\n!ls -l\\n\\n\\ntotal 96\\n-rw-r--r-- 1 root root  6975 Dec  3 17:36 processed_titanic.csv\\ndrwxr-xr-x 1 root root  4096 Nov 21 16:30 sample_data\\n-rw-r--r-- 1 root root 85153 Dec  3 17:36 titanic.csv\\n\\nScaling\\nWhen working with very large datasets, our Pandas DataFrames can become very large and it can be very slow or impossible to operate on them. This is where packages that can distribute workloads or run on more efficient hardware can come in handy.\\n\\nDask: parallel computing to scale packages like Numpy, Pandas and scikit-learn on one/multiple machines.\\ncuDF: efficient dataframe loading and computation on a GPU.\\n\\nAnd, of course, we can combine these together (Dask-cuDF) to operate on partitions of a dataframe on the GPU.\\n\\nTo cite this content, please use:\\n1\\n2\\n3\\n4\\n5\\n6@article{madewithml,\\n    author       = {Goku Mohandas},\\n    title        = { Pandas - Made With ML },\\n    howpublished = {\\\\url{https://madewithml.com/}},\\n    year         = {2023}\\n}\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n¬© 2023 Anyscale, Inc.  Anyscale Privacy Policy\\n\\nMade with\\n\\nMaterial for MkDocs\\n\\n--- Content from https://www.geeksforgeeks.org/introduction-to-pandas-in-python/ ---\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTutorialsPython TutorialTaking Input in PythonPython OperatorsPython Data TypesPython NumbersPython StringPython ListsPython TuplesSets in PythonPython DictionaryPython Loops and Control FlowPython Conditional StatementsPython LoopsPython FunctionsPython OOPS ConceptPython Data StructuresPython DSALinked ListStackQueueTreeHeapHashingGraphSetsMapAdvance Data StructureSorting AlgorithmsSearching AlgorithmsPython Exception HandlingPython File HandlingPython ExercisesPython List ExercisePython String ExercisePython Tuple ExercisePython Dictionary ExercisePython Set ExercisePython Design PatternsPython Programming ExamplesPython Practice QuestionsJavaJava Programming LanguageJava TutorialData TypesVariablesOperatorsFlow Control in JavaLoops in JavaMethodsStringsArraysOOPs ConceptsOOPs ConceptsClasses and ObjectsAccess ModifiersInheritanceAbstractionEncapsulationPolymorphismInterfacePackagesMultithreadingFile HandlingRegular ExpressionJava CollectionsJava CollectionsCollection ClassList InterfaceArrayListLinkedList ClassQueue InterfaceSet InterfaceHashSet ClassMap InterfaceHashMap ClassHashTable ClassIteratorComparatorCollection Interview QuestionsJava 8 TutorialJava ProgramsJava Programming ExamplesJava Array ProgramsJava String ProgramsJava Date-Time ProgramsJava File Handling ProgramsJava Collection ProgramsJava JDBC ProgramsJava Apache POI ProgramsJava OpenCV ProgramsJava Interview QuestionsJava Interview QuestionsCore Java Interview Questions-FreshersJava Multithreading Interview QuestionsOOPs Interview Questions and AnswersJava ExercisesJava QuizJava QuizCore Java MCQJava ProjectsAdvance JavaSpring TutorialSpring Boot TutorialSpring Boot Interview QuestionsSpring MVC TutorialSpring MVC Interview QuestionsHibernate TutorialHibernate Interview QuestionsProgramming LanguagesCC++JavaScriptPHPR TutorialC#SQLScalaPerlGo LanguageKotlinSystem DesignSystem Design TutorialWhat is System DesignKey Terminologies in System DesignAnalysis and Architecture of SystemsScalability in System DesignDatabases in System DesignHigh Level Design or HLDLow Level Design or LLDCase Studies in Designing SystemsComplete System Design TutorialSoftware Design PatternsSystem Design RoadmapTop 10 System Design Interview Questions and AnswersInterview CornerCompany PreparationTop TopicsPractice Company QuestionsInterview ExperiencesExperienced InterviewsInternship InterviewsCompetitive ProgrammingMultiple Choice QuizzesAptitude for PlacementsComputer Science SubjectsOperating SystemDBMSComputer NetworksEngineering MathematicsComputer Organization and ArchitectureTheory of ComputationCompiler DesignDigital LogicSoftware EngineeringDevOpsGITAWSDockerKubernetesMicrosoft Azure TutorialGoogle Cloud PlatformLinuxLinux TutorialLinux Commands A-ZLinux Commands CheatsheetFile Permission CommandsLinux System AdministrationLinux File SystemLinux Shell ScriptingLinux NetworkingLinux Interview QuestionsSoftware TestingSoftware Testing TutorialSoftware Engineering TutorialTesting Interview QuestionsJiraDatabasesDBMS TutorialSQL TutorialPostgreSQL TutorialMongoDB TutorialSQL Interview QuestionsMySQL Interview QuestionsPL/SQL Interview QuestionsAndroidAndroid TutorialAndroid Studio TutorialKotlin For AndroidAndroid ProjectsAndroid Interview Questions6 Weeks of Android App DevelopmentExcelMS Excel TutorialIntroduction to MS ExcelData Analysis in ExcelBasic Excel Formulas & FunctionsData Analysis in Advanced ExcelWorkbooksStatistical FunctionsData Visualization in ExcelPivot Tables in ExcelExcel Spreadsheets in PythonBasic Excel ShortcutsMathematicsNumber SystemAlgebraLinear AlgebraTrigonometrySet TheoryStatisticsProbabilityGeometryMensurationLogarithmsCalculusDSAData StructuresArraysMatrixStringsLinked ListSingly Linked ListDoubly Linked ListCircular Linked ListDoubly Circular Linked ListLinked List TutorialStackQueueTreeGeneric TreeBinary TreeBinary Search TreeAVL TreeB TreeB+ TreeRed Black TreeTree Data Structure TutorialHeapHashingGraphSet Data StructureMap Data StructureAdvanced Data StructureData Structures TutorialAlgorithmsAnalysis of AlgorithmsDesign and Analysis of AlgorithmsAsymptotic AnalysisAsymptotic NotationsWorst, Average and Best CasesSearching AlgorithmsLinear SearchBinary SearchSearching Algorithms TutorialSorting AlgorithmsSelection SortBubble SortInsertion SortMerge SortQuick SortHeap SortCounting SortRadix SortBucket SortSorting Algorithms TutorialGreedy AlgorithmsDynamic ProgrammingGraph AlgorithmsPattern SearchingRecursionBacktrackingDivide and ConquerMathematical AlgorithmsGeometric AlgorithmsBitwise AlgorithmsRandomized AlgorithmsBranch and BoundAlgorithms TutorialDSA TutorialPracticeAll DSA ProblemsProblem of the DayCompany Wise Coding PracticeAmazonMicrosoftFlipkartExplore AllGfG SDE SheetPractice Problems Difficulty WiseSchoolBasicEasyMediumHardLanguage Wise Coding PracticeCPPJavaPythonCurated DSA ListsBeginner\\'s DSA SheetTop 50 Array ProblemsTop 50 String ProblemsTop 50 DP ProblemsTop 50 Graph ProblemsTop 50 Tree ProblemsCompetitive ProgrammingCompany Wise SDE SheetsFacebook SDE SheetAmazon SDE SheetApple SDE SheetNetflix SDE SheetGoogle SDE SheetDSA Cheat SheetsSDE SheetDSA Sheet for BeginnersFAANG Coding SheetProduct-Based Coding SheetCompany-Wise Preparation SheetTop Interview QuestionsPuzzlesAll PuzzlesTop 100 Puzzles Asked In InterviewsTop 20 Puzzles Commonly Asked During SDE InterviewsData SciencePython TutorialR TutorialMachine LearningData Science using PythonData Science using RData Science PackagesPandas TutorialNumPy TutorialData VisualizationPython Data Visualization TutorialData Visualization with RData AnalysisData Analysis with PythonData Analysis with RDeep LearningNLP TutorialWeb TechHTML TutorialCSS TutorialJavaScript TutorialPHP TutorialReactJS TutorialNodeJS TutorialAngularJS TutorialBootstrap TutorialTypescriptWeb Development Using PythonDjangoDjango TutorialDjango ProjectsDjango Interview QuestionsFlaskFlask TutorialFlask ProjectsFlask Interview QuestionsPostmanGithubWordpress TutorialWeb DesignCheat SheetsHTML Cheat SheetCSS Cheat SheetJavaScript Cheat SheetReact Cheat SheetAngular Cheat SheetjQuery Cheat SheetBootstrap Cheat SheetLearn Complete Web DevelopmentCoursesGo PremiumCoding for EveryoneDSA to DevelopmentMachine Learning & Data ScienceGenerative AI & ChatGPTBecome AWS CertifiedDSA CoursesData Structure & Algorithm(C++/JAVA)Data Structure & Algorithm(Python)Data Structure & Algorithm(JavaScript)Programming LanguagesCPPJavaPythonJavaScriptC\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAI ML DSData ScienceData AnalysisData VisualizationMachine LearningDeep LearningNLPComputer VisionArtificial IntelligenceAI ML DS Interview SeriesAI ML DS Projects seriesData EngineeringWeb Scrapping \\n\\n\\n\\n\\n‚ñ≤\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen In App\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPandas Introduction\\n\\n\\nLast Updated : \\n30 Jul, 2024\\n\\n\\n\\n \\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSummarize\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n \\n\\n\\nLike Article\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\nSave\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n\\n\\n\\n\\nReport\\n\\n\\n\\n\\n\\n\\n\\nPandas is a powerful and open-source Python library. The Pandas library is used for data manipulation and analysis. Pandas consist of data structures and functions to perform efficient operations on data.\\nThis free tutorial will cover an overview of Pandas, covering the fundamentals of Python Pandas.\\nTable of Content\\nWhat is Pandas Libray in Python?What is Python Pandas used for?Getting Started with PandasData Structures in Pandas LibraryPandas SeriesPandas DataFrameHow to run the Pandas Program in Python?What is Pandas Libray in Python?Pandas is a powerful and versatile library that simplifies the tasks of data manipulation in Python. Pandas is well-suited for working with tabular data, such as spreadsheets or SQL tables.\\nThe Pandas library is an essential tool for data analysts, scientists, and engineers working with structured data in Python.\\nWhat is Python Pandas used for?The Pandas library is generally used for data science, but have you wondered why? This is because the Pandas library is used in conjunction with other libraries that are used for data science.\\nIt is built on top of the NumPy library which means that a lot of the structures of NumPy are used or replicated in Pandas.\\nThe data produced by Pandas is often used as input for plotting functions in Matplotlib, statistical analysis in SciPy, and machine learning algorithms in Scikit-learn.\\nYou must be wondering, Why should you use the Pandas Library. Python‚Äôs Pandas library is the best tool to analyze, clean, and manipulate data.\\nHere is a list of things that we can do using Pandas.\\nData set cleaning, merging, and joining.Easy handling of missing data (represented as NaN) in floating point as well as non-floating point data.Columns can be inserted and deleted from DataFrame and higher-dimensional objects.Powerful group by functionality for performing split-apply-combine operations on data sets.Data Visualization.Getting Started with PandasLet‚Äôs see how to start working with the Python Pandas library:\\nInstalling PandasThe first step in working with Pandas is to ensure whether it is installed in the system or not. \\xa0If not, then we need to install it on our system using the pip command.\\nFollow these steps to install Pandas:\\nStep 1: Type ‚Äòcmd‚Äô in the search box and open it.Step 2: Locate the folder using the cd command where the python-pip file has been installed.Step 3: After locating it, type the command:\\npip install pandasFor more reference, take a look at this article on installing pandas follows.\\nImporting PandasAfter the Pandas have been installed in the system, you need to import the library. This module is generally imported as follows:\\nimport pandas as pdNote: Here, pd is referred to as an alias for the Pandas. However, it is not necessary to import the library using the alias, it just helps in writing less code every time a method or property is called.\\xa0\\nData Structures in Pandas LibraryPandas generally provide two data structures for manipulating data. They are:\\nSeriesDataFramePandas SeriesA Pandas Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, Python objects, etc.). The axis labels are collectively called indexes.\\nThe Pandas Series is nothing but a column in an Excel sheet. Labels need not be unique but must be of a hashable type.\\nThe object supports both integer and label-based indexing and provides a host of methods for performing operations involving the index.\\nPandas SeriesCreating a SeriesPandas Series is created by loading the datasets from existing storage (which can be a SQL database, a CSV file, or an Excel file).\\nPandas Series can be created from lists, dictionaries, scalar values, etc.\\nExample: Creating a series using the Pandas Library.\\n\\nPython\\n\\nimport pandas as pd \\nimport numpy as np\\n\\n# Creating empty series \\nser = pd.Series() \\nprint(\"Pandas Series: \", ser) \\n\\n# simple array \\ndata = np.array([\\'g\\', \\'e\\', \\'e\\', \\'k\\', \\'s\\']) \\n  \\nser = pd.Series(data) \\nprint(\"Pandas Series:\\\\n\", ser)\\n\\nOutput\\nPandas Series: Series([], dtype: float64)Pandas Series:0    g1    e2    e3    k4    sdtype: objectFor more information, refer to Creating a Pandas Series\\nPandas DataFramePandas DataFrame is a two-dimensional data structure with labeled axes (rows and columns).\\nCreating DataFramePandas DataFrame is created by loading the datasets from existing storage (which can be a SQL database, a CSV file, or an Excel file).\\nPandas DataFrame can be created from lists, dictionaries, a list of dictionaries, etc.\\nExample: Creating a DataFrame Using the Pandas Library\\n\\nPython\\n\\nimport pandas as pd \\n  \\n# Calling DataFrame constructor \\ndf = pd.DataFrame() \\nprint(df)\\n\\n# list of strings \\nlst = [\\'Geeks\\', \\'For\\', \\'Geeks\\', \\'is\\', \\'portal\\', \\'for\\', \\'Geeks\\'] \\n  \\n# Calling DataFrame constructor on list \\ndf = pd.DataFrame(lst) \\nprint(df)\\n\\nOutput:\\nEmpty DataFrameColumns: []Index: []        00   Geeks1     For2   Geeks3      is4  portal5     for6   GeeksNote: For more information, refer to Creating a Pandas DataFrame\\xa0\\nHow to run the Pandas Program in Python?The Pandas program can be run from any text editor, but it is recommended to use Jupyter Notebook for this, as Jupyter gives you the ability to execute code in a particular cell rather than the entire file.\\nJupyter also provides an easy way to visualize Pandas DataFrame and plots.\\nNote: For more information on Jupyter Notebook, refer to How To Use Jupyter Notebook ‚Äì An Ultimate Guide\\xa0\\nConclusionThis tutorial provides a solid foundation for mastering the Pandas library, from basic operations to advanced techniques. We have also covered the Pandas data structures (series and DataFrame) with examples.\\nAfter completing this tutorial, you will gain a complete idea of what is Python Pandas. What is Pandas used for? and how to use Python Pandas.\\nAs you apply these skills to your projects, you will discover how Pandas enhances your ability to explore, clean, and analyze data, making it an indispensable tool in the data scientist‚Äôs toolkit.\\nElevate your coding journey with a Premium subscription. Benefit from ad-free learning, unlimited article summaries, an AI bot, access to 35+ courses, and more-available only with GeeksforGeeks Premium! Explore now!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nN\\n\\n\\n\\n\\n \\n\\nnikhilaggarwal3 \\n\\n\\n\\n\\n\\n Follow \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n\\n\\nPrevious Article\\n\\n\\n\\nPandas Tutorial\\n\\n\\n\\n\\nNext Article\\n\\n\\n\\n\\nHow to Install Pandas in Python?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Please Login to comment...\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSimilar Reads\\n\\n\\n\\nPandas Series dt.day_name() Method | Get Day From Date in Pandas\\nPandas dt.day_name() method returns the day names of the DateTime Series objects with specified locale. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31 08:45\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) resu\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.weekday | Find Day of the Week in Pandas\\nThe dt.weekday attribute returns the day of the week. It is assumed the week starts on Monday, which is denoted by 0, and ends on Sunday which is denoted by 6. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.weekofyear Method | Get Week of Year in Pandas Series\\nThe dt.weekofyear attribute returns a Series containing the week ordinal of the year in the underlying data of the given series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index =\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.dayofyear | Get Day of Year in Pandas\\nPandas dt.dayofyear attribute returns the ordinal day of the year in the underlying DateTime data in the given Series object. Example: C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr =\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.minute | Extract Minute from DateTime Series in Pandas\\nPandas Series.dt.minute attribute returns a NumPy array containing the minutes of the DateTime in the underlying data of the given series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:22\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\']\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.days_in_month | Get Total Number of Days in Month in Pandas\\nThe Pandas dt.days_in_month attribute returns the total number of days in the month for the given Series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) r\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.dayofweek | Get Day of Week from DateTime Series in Pandas\\nPandas dt.dayofweek attribute returns the day of the week from the given DateTime Series Object. It is assumed the week starts on Monday, which is denoted by 0, and ends on Sunday which is denoted by 6. Example: C/C++ Code import pandas as pd sr = pd.Series([\\'2012-10-21 09:30\\', \\'2019-7-18 12:30\\', \\'2008-02-2 10:30\\', \\'2010-4-22 09:25\\', \\'2019-11-8 02:\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.freq | Retrieve Frequency of Pandas Time Series\\nPandas dt.freq attribute returns the time series frequency applied on the given series object if any, else it returns None. Examples C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_da\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.daysinmonth | Get Number of Days in Month in Pandas Series\\nThe dt.daysinmonth attribute returns the number of days in the month for the given DateTime series object. Example C/C++ Code import pandas as pd sr = pd.Series([\\'2012-12-31\\', \\'2019-1-1 12:30\\', \\'2008-02-2 10:30\\', \\'2010-1-1 09:25\\', \\'2019-12-31 00:00\\']) idx = [\\'Day 1\\', \\'Day 2\\', \\'Day 3\\', \\'Day 4\\', \\'Day 5\\'] sr.index = idx sr = pd.to_datetime(sr) result\\n\\n\\n\\n2 min read\\n\\n\\n\\n\\nPandas Series dt.normalize() | Normalize Time in Pandas Series\\nThe dt.normalize() method converts times to midnight. The time component of the date-time is converted to midnight i.e. 00:00:00. This is useful in cases when the time does not matter. Length is unaltered. The time zones are unaffected. Example: C/C++ Code import pandas as pd sr = pd.Series(pd.date_range(\\'2012-12-31 09:45\\', periods = 5, freq = \\'M\\',\\n\\n\\n\\n2 min read\\n\\n\\n\\nView More Articles\\n\\n\\n\\nArticle Tags : \\n\\n\\nAI-ML-DS\\n\\n\\nPandas\\n\\n\\nPython pandas-basics\\n \\n\\n\\n\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nExplore More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n                     Corporate & Communications Address:- A-143, 9th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) | Registered Address:- K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCompanyAbout UsLegalIn MediaContact UsAdvertise with usGFG Corporate SolutionPlacement Training ProgramGeeksforGeeks CommunityLanguagesPythonJavaC++PHPGoLangSQLR LanguageAndroid TutorialTutorials ArchiveDSAData StructuresAlgorithmsDSA for BeginnersBasic DSA ProblemsDSA RoadmapTop 100 DSA Interview ProblemsDSA Roadmap by Sandeep JainAll Cheat SheetsData Science & MLData Science With PythonData Science For BeginnerMachine Learning TutorialML MathsData Visualisation TutorialPandas TutorialNumPy TutorialNLP TutorialDeep Learning TutorialWeb TechnologiesHTMLCSSJavaScriptTypeScriptReactJSNextJSBootstrapWeb DesignPython TutorialPython Programming ExamplesPython ProjectsPython TkinterWeb ScrapingOpenCV TutorialPython Interview QuestionDjangoComputer ScienceOperating SystemsComputer NetworkDatabase Management SystemSoftware EngineeringDigital Logic DesignEngineering MathsSoftware DevelopmentSoftware TestingDevOpsGitLinuxAWSDockerKubernetesAzureGCPDevOps RoadmapSystem DesignHigh Level DesignLow Level DesignUML DiagramsInterview GuideDesign PatternsOOADSystem Design BootcampInterview QuestionsInteview PreparationCompetitive ProgrammingTop DS or Algo for CPCompany-Wise Recruitment ProcessCompany-Wise PreparationAptitude PreparationPuzzlesSchool SubjectsMathematicsPhysicsChemistryBiologySocial ScienceEnglish GrammarCommerceWorld GKGeeksforGeeks VideosDSAPythonJavaC++Web DevelopmentData ScienceCS Subjects \\n\\n\\n\\n\\n\\n\\n@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        We use cookies to ensure you have the best browsing experience on our website. By using our site, you\\r\\n        acknowledge that you have read and understood our\\r\\n        Cookie Policy &\\r\\n        Privacy Policy\\n\\n\\r\\n        Got It !\\r\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nImprovement\\n\\n\\n\\n\\n\\nPlease go through our recently updated Improvement Guidelines before submitting any improvements.\\nThis improvement is locked by another user right now. You can suggest the changes for now and it will be under \\'My Suggestions\\' Tab on Write.\\nYou will be notified via email once the article is available for improvement.\\r\\n                        Thank you for your valuable feedback!\\r\\n                    \\n\\nSuggest changes\\n\\n\\n\\nPlease go through our recently updated Improvement Guidelines before submitting any improvements.\\n\\n\\nSuggest Changes\\nHelp us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\nEnhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest Changes\\n\\n\\n\\n\\n\\n\\n\\nmin 4 words, max CharLimit:2000\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat kind of Experience do you want to share?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInterview Experiences\\n\\n\\n\\n\\n\\n\\n\\nAdmission Experiences\\n\\n\\n\\n\\n\\n\\n\\nCareer Journeys\\n\\n\\n\\n\\n\\n\\n\\nWork Experiences\\n\\n\\n\\n\\n\\n\\n\\nCampus Experiences\\n\\n\\n\\n\\n\\n\\n\\nCompetitive Exam Experiences\\n\\n\\n\\n\\n\\n\\n                        Can\\'t choose a topic to write? click here for suggested topics\\n                    \\n\\n\\n\\n                       Write and publish your own Article'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "content = \"\"\n",
    "# Run\n",
    "for question, answer in qa_dictionary.items():\n",
    "    queries = generate_queries_decomposition.invoke({\"question\":question,\"answer\":answer})\n",
    "    print(queries)\n",
    "    for query in queries:\n",
    "        scraper = WebScraper(answer,2)\n",
    "        # Call the method to get the file paths of the scraped data\n",
    "        content = \"\".join([content,scraper.get_scraped_data()])\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the relevant documents in a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(content)\n",
    "\n",
    "# Index\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking accuracy with  background context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the answer you need to check:\n",
    "\n",
    "\\n --- \\n {answer} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer + accuracy percentage + feedback:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context, your own knowledge and background question + answer + accuracy percentage + feedback\n",
    "on the subject matter to get the accuracy of the answer. A percentage accuracy score and also note down the \n",
    "places that the answer was inaccurate and give feedback for those places\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_qa_pair(question, answer, feedback):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\nFeedback: {feedback}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for question, answer in qa_dictionary.items():\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"answer\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "    feedback = rag_chain.invoke({\"question\":question,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(question,answer,feedback)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_pairs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
