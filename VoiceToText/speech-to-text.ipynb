{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \"TEST.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey, thanks for the question. A project that I worked on where I had to learn new technology and as well, AM Programming Language very quickly was when I built a Discord bot that is deployed serverlessly on Lambda using Amazon Web Services. So this project essentially, I don't know what the fuck I'm saying, I'm just saying random things, right? You know, I'm producing a semi-detoid I did this as well. So yeah, now I'm just like basically having chat about things. I'm just going to keep on talking for a little bit longer because I have genuinely got no idea what to say because this is very awkward. So yeah.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" Hey, thanks for the question. A project that I worked on where I had to learn new technology and as well, AM Programming Language very quickly was when I built a Discord bot that is deployed serverlessly on Lambda using Amazon Web Services. So this project essentially, I don't know what the fuck I'm saying, I'm just saying random things, right? You know, I'm producing a semi-detoid I did this as well. So yeah, now I'm just like basically having chat about things. I'm just going to keep on talking for a little bit longer because I have genuinely got no idea what to say because this is very awkward. So yeah.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 6.48,\n",
       "   'text': ' Hey, thanks for the question. A project that I worked on where I had to learn new technology',\n",
       "   'tokens': [50364,\n",
       "    1911,\n",
       "    11,\n",
       "    3231,\n",
       "    337,\n",
       "    264,\n",
       "    1168,\n",
       "    13,\n",
       "    316,\n",
       "    1716,\n",
       "    300,\n",
       "    286,\n",
       "    2732,\n",
       "    322,\n",
       "    689,\n",
       "    286,\n",
       "    632,\n",
       "    281,\n",
       "    1466,\n",
       "    777,\n",
       "    2899,\n",
       "    50688],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21276078475149054,\n",
       "   'compression_ratio': 1.465648854961832,\n",
       "   'no_speech_prob': 0.07269669324159622},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 6.48,\n",
       "   'end': 13.44,\n",
       "   'text': ' and as well, AM Programming Language very quickly was when I built a Discord bot that is deployed',\n",
       "   'tokens': [50688,\n",
       "    293,\n",
       "    382,\n",
       "    731,\n",
       "    11,\n",
       "    6475,\n",
       "    8338,\n",
       "    2810,\n",
       "    24445,\n",
       "    588,\n",
       "    2661,\n",
       "    390,\n",
       "    562,\n",
       "    286,\n",
       "    3094,\n",
       "    257,\n",
       "    32623,\n",
       "    10592,\n",
       "    300,\n",
       "    307,\n",
       "    17826,\n",
       "    51036],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21276078475149054,\n",
       "   'compression_ratio': 1.465648854961832,\n",
       "   'no_speech_prob': 0.07269669324159622},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 13.44,\n",
       "   'end': 21.92,\n",
       "   'text': \" serverlessly on Lambda using Amazon Web Services. So this project essentially, I don't know what the\",\n",
       "   'tokens': [51036,\n",
       "    7154,\n",
       "    12048,\n",
       "    322,\n",
       "    45691,\n",
       "    1228,\n",
       "    6795,\n",
       "    9573,\n",
       "    12124,\n",
       "    13,\n",
       "    407,\n",
       "    341,\n",
       "    1716,\n",
       "    4476,\n",
       "    11,\n",
       "    286,\n",
       "    500,\n",
       "    380,\n",
       "    458,\n",
       "    437,\n",
       "    264,\n",
       "    51460],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21276078475149054,\n",
       "   'compression_ratio': 1.465648854961832,\n",
       "   'no_speech_prob': 0.07269669324159622},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': 21.92,\n",
       "   'end': 26.64,\n",
       "   'text': \" fuck I'm saying, I'm just saying random things, right? You know, I'm producing a semi-detoid\",\n",
       "   'tokens': [51460,\n",
       "    3275,\n",
       "    286,\n",
       "    478,\n",
       "    1566,\n",
       "    11,\n",
       "    286,\n",
       "    478,\n",
       "    445,\n",
       "    1566,\n",
       "    4974,\n",
       "    721,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    509,\n",
       "    458,\n",
       "    11,\n",
       "    286,\n",
       "    478,\n",
       "    10501,\n",
       "    257,\n",
       "    12909,\n",
       "    12,\n",
       "    17863,\n",
       "    17079,\n",
       "    51696],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21276078475149054,\n",
       "   'compression_ratio': 1.465648854961832,\n",
       "   'no_speech_prob': 0.07269669324159622},\n",
       "  {'id': 4,\n",
       "   'seek': 2664,\n",
       "   'start': 27.44,\n",
       "   'end': 33.68,\n",
       "   'text': \" I did this as well. So yeah, now I'm just like basically having chat about things.\",\n",
       "   'tokens': [50404,\n",
       "    286,\n",
       "    630,\n",
       "    341,\n",
       "    382,\n",
       "    731,\n",
       "    13,\n",
       "    407,\n",
       "    1338,\n",
       "    11,\n",
       "    586,\n",
       "    286,\n",
       "    478,\n",
       "    445,\n",
       "    411,\n",
       "    1936,\n",
       "    1419,\n",
       "    5081,\n",
       "    466,\n",
       "    721,\n",
       "    13,\n",
       "    50716],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25415145744711665,\n",
       "   'compression_ratio': 1.4615384615384615,\n",
       "   'no_speech_prob': 0.021047841757535934},\n",
       "  {'id': 5,\n",
       "   'seek': 2664,\n",
       "   'start': 36.24,\n",
       "   'end': 41.120000000000005,\n",
       "   'text': \" I'm just going to keep on talking for a little bit longer because I have genuinely got no idea\",\n",
       "   'tokens': [50844,\n",
       "    286,\n",
       "    478,\n",
       "    445,\n",
       "    516,\n",
       "    281,\n",
       "    1066,\n",
       "    322,\n",
       "    1417,\n",
       "    337,\n",
       "    257,\n",
       "    707,\n",
       "    857,\n",
       "    2854,\n",
       "    570,\n",
       "    286,\n",
       "    362,\n",
       "    17839,\n",
       "    658,\n",
       "    572,\n",
       "    1558,\n",
       "    51088],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25415145744711665,\n",
       "   'compression_ratio': 1.4615384615384615,\n",
       "   'no_speech_prob': 0.021047841757535934},\n",
       "  {'id': 6,\n",
       "   'seek': 2664,\n",
       "   'start': 41.120000000000005,\n",
       "   'end': 51.519999999999996,\n",
       "   'text': ' what to say because this is very awkward. So yeah.',\n",
       "   'tokens': [51088,\n",
       "    437,\n",
       "    281,\n",
       "    584,\n",
       "    570,\n",
       "    341,\n",
       "    307,\n",
       "    588,\n",
       "    11411,\n",
       "    13,\n",
       "    407,\n",
       "    1338,\n",
       "    13,\n",
       "    51608],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25415145744711665,\n",
       "   'compression_ratio': 1.4615384615384615,\n",
       "   'no_speech_prob': 0.021047841757535934}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
