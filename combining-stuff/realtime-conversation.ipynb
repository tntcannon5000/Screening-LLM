{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [ ] Write down all the libraries that we need to install\n",
        "- [ ] Add Try catch for exceptions when moving to .py file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Important Notes\n",
        "### Packages to install :\n",
        "- pip install sounddevice\n",
        "- pip install numpy\n",
        "- Install ffmpeg (needed for intsalling local version of whisper)\n",
        "    - On Ubuntu or Debian\n",
        "      sudo apt update && sudo apt install ffmpeg\n",
        "    - On Arch Linux\n",
        "      sudo pacman -S ffmpeg\n",
        "    - On MacOs\n",
        "      brew install ffmpeg\n",
        "    - On Windows\n",
        "      winget install ffmpeg\n",
        "- pip install -U openai-whisper\n",
        "- pip install anthropic\n",
        "- pip install dotenv\n",
        "- pip install python-dotenv\n",
        "- pip install openai\n",
        "- pip install pyaudio\n",
        "- pip install keyboard\n",
        "- Installing pytorch\n",
        "  - Install Cuda Toolkit (https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html) -> Only needed for GPU acceleration\n",
        "  - Install Cudnn (https://developer.nvidia.com/cudnn) -> Only needed for GPU acceleration\n",
        "  - pInstall pytorch with or without cuda (https://pytorch.org/get-started/locally/)\n",
        "- pip install PyMuPDF -> To read the pdf files like CV's\n",
        "### Instructions :\n",
        "- There needs to be a .env in this notebook's working directory, which contains the api keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wav\n",
        "import whisper\n",
        "from joblib import load, dump\n",
        "from AnthropicWrapper import ClaudeChatCV\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import pyaudio\n",
        "import threading\n",
        "import time\n",
        "import keyboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the path to the immediate parent folder of the current working directory\n",
        "parent_folder_path = os.path.dirname(os.getcwd())\n",
        "\n",
        "# Construct the path to the .env file in the parent folder\n",
        "dotenv_path = os.path.join(parent_folder_path, \".env\")\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(dotenv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Settings ---\n",
        "FS = 44100               # Sampling frequency\n",
        "THRESHOLD = 50          # Volume threshold for silence (adjust this)\n",
        "SILENCE_DURATION = 1.5   # Seconds of silence before stopping (adjust this)\n",
        "CHUNK_SIZE = 1024        # Process audio in chunks for efficiency\n",
        "SPEAKING_SPEED = 1.1     # Speed of speaking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Globals ---\n",
        "pause_loop = False\n",
        "unixtime = time.time()\n",
        "human_audio_n = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_role = \"Machine Learning Engineer\"\n",
        "candidate_skill = \"Entry-Level\"\n",
        "\n",
        "role_description = \"\"\"\n",
        "Do you want to tackle the biggest questions in finance with near infinite compute power at your fingertips?\n",
        "\n",
        "G-Research is a leading quantitative research and technology firm, with offices in London and Dallas. We are proud to employ some of the best people in their field and to nurture their talent in a dynamic, flexible and highly stimulating culture where world-beating ideas are cultivated and rewarded.\n",
        "\n",
        "This is a role based in our new Soho Place office - opened in 2023 - in the heart of Central London and home to our Research Lab.\n",
        "\n",
        "The role\n",
        "\n",
        "We are looking for exceptional machine learning engineers to work alongside our quantitative researchers on cutting-edge machine learning problems.\n",
        "\n",
        "As a member of the Core Technical Machine Learning team, you will be engaged in a mixture of individual and collaborative work to tackle some of the toughest research questions.\n",
        "\n",
        "In this role, you will use a combination of off-the-shelf tools and custom solutions written from scratch to drive the latest advances in quantitative research.\n",
        "\n",
        "Past projects have included:\n",
        "\n",
        "Implementing ideas from a recently published research paper\n",
        "Writing custom libraries for efficiently training on petabytes of data\n",
        "Reducing model training times by hand optimising machine learning operations\n",
        "Profiling custom ML architectures to identify performance bottlenecks\n",
        "Evaluating the latest hardware and software in the machine learning ecosystem\n",
        "Who are we looking for?\n",
        "\n",
        "Candidates will be comfortable working both independently and in small teams on a variety of engineering challenges, with a particular focus on machine learning and scientific computing.\n",
        "\n",
        "The ideal candidate will have the following skills and experience:\n",
        "\n",
        "Either a post-graduate degree in machine learning or a related discipline, or commercial experience working on machine learning models at scale. We will also consider exceptional candidates with a proven record of success in online data science competitions, such as Kaggle\n",
        "Strong object-oriented programming skills and experience working with Python, PyTorch and NumPy are desirable\n",
        "Experience in one or more advanced optimisation methods, modern ML techniques, HPC, profiling, model inference; you dont need to have all of the above\n",
        "Excellent ML reasoning and communication skills are crucial: off-the-shelf methods dont always work on our data so you will need to understand how to develop your own models in a collaborative environment working in a team with complementary skills\n",
        "Finance experience is not necessary for this role and candidates from non-financial backgrounds are encouraged to apply.\n",
        "\n",
        "Why should you apply?\n",
        "\n",
        "Highly competitive compensation plus annual discretionary bonus\n",
        "Lunch provided (via Just Eat for Business) and dedicated barista bar\n",
        "35 days annual leave\n",
        "9 percent company pension contributions\n",
        "Informal dress code and excellent work/life balance\n",
        "Comprehensive healthcare and life assurance\n",
        "Cycle-to-work scheme\n",
        "Monthly company events\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = f\"\"\"You are a skilled interviewer who is conducting an initial phone screening interview for a candidate for a {candidate_skill} {job_role} role to see if the candidate is at minimum somewhat qualified for the role and worth the time to be fully interviewed. The role and company description is copypasted from the job posting as follows: {role_description}. Parse through it to extract any information you feel is relevant.\n",
        "Your job is to begin a friendly discussion with the candidate, and ask questions relevant to the {job_role} role, which may or may not be based on the interviewee's CV, which you have access to. Be sure to stick to this topic even if the candidate tries to steer the conversation elsewhere. If the candidate has other experience on his CV, you can ask about it, but keep it within the context of the {job_role} role.\n",
        "After the candidate responds to each of your questions, you should not summarise or provide feedback on their responses. THIS POINT IS KEY! You should not summarise or provide feedback on their responses. You must keep your responses short and concise without reiterating what is good about the candidate's response or experience when they reply.\n",
        "You can ask follow-up questions if you wish.\n",
        "Once you have asked sufficient questions such that you deem the candidate is or isn't fitting for the role, end the interview by thanking the candidate for their time and informing them that they will receive word soon on the outcome of the screening interview. If the candidate does not seem fititng for the role, or if something feels off such as the candidate being unconfident or very very vague feel free to end the interview early. There is no need to inform them of your opinion of their performance, as this will be evaluated later.\n",
        "The candidate will begin the interview by greeting you. You are to greet them back, and begin the interview.\n",
        "For this specific run, keep the interview to a maximum of 4 questions.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising Claude and ConversationChain\n",
        "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
        "\n",
        "# Give the path to a CV in your disk\n",
        "pdf_path = \"docs/cv-deb.pdf\"\n",
        "chat_model = ClaudeChatCV(chat_model_name, system_prompt, pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising whisper\n",
        "stt_model = whisper.load_model(\"medium\", device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising text2speech\n",
        "tts_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def stream_tts(input_string):\n",
        "    def _stream_tts():\n",
        "        p = pyaudio.PyAudio()\n",
        "        stream = p.open(format=8,\n",
        "                        channels=1,\n",
        "                        rate=round(24_005 * SPEAKING_SPEED),\n",
        "                        output=True)\n",
        "        with tts_client.audio.speech.with_streaming_response.create(\n",
        "            model=\"tts-1\",\n",
        "            voice=\"nova\",\n",
        "            input=input_string,\n",
        "            response_format=\"pcm\"\n",
        "        ) as response:\n",
        "            for chunk in response.iter_bytes(1024):\n",
        "                stream.write(chunk)\n",
        "                \n",
        "        #print(\"FINISHED!!!!!!!!!!!!!!!!!!!!\")\n",
        "        thread_done.set()\n",
        "\n",
        "    thread_done = threading.Event()\n",
        "\n",
        "    thread = threading.Thread(target=_stream_tts)\n",
        "    thread.start()\n",
        "    thread_done.wait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Functions ---\n",
        "def is_silent(data):\n",
        "    rms = np.sqrt(np.mean(data**2))\n",
        "    print(\"RMS: \", rms)\n",
        "    return rms < THRESHOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising speech2text without silence detection\n",
        "def record_speech():\n",
        "    global human_audio_n\n",
        "    print(\"Recording... Speak now!\")\n",
        "    audio_data = np.array([], dtype=np.int16)  # Initialize empty array\n",
        "\n",
        "    with sd.InputStream(samplerate=FS, channels=1, dtype='int16') as stream:\n",
        "        while True:\n",
        "            chunk, overflowed = stream.read(CHUNK_SIZE)\n",
        "            if overflowed:\n",
        "                print(\"Warning: Input overflowed!\")\n",
        "            audio_data = np.append(audio_data, chunk)\n",
        "\n",
        "            if pause_loop:\n",
        "                break\n",
        "    \n",
        "    human_audio_n += 1\n",
        "    wavstring = f\"/audio_{human_audio_n}_{unixtime}.wav\"\n",
        "    wav.write(wavstring, FS, audio_data)\n",
        "\n",
        "    return wavstring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keyboard_listener():\n",
        "    global pause_loop\n",
        "    \n",
        "    def on_key_press(event):\n",
        "        global pause_loop\n",
        "        #print(\"Key pressed: {}\" .format(event.name))\n",
        "        if event.name == \"+\":\n",
        "            pause_loop = False\n",
        "            print(\"Set to continue on next loop\")\n",
        "        elif event.name == \"-\":\n",
        "            pause_loop = True\n",
        "            print(\"Set to pause on next loop\")\n",
        "    \n",
        "    keyboard.on_press(on_key_press)\n",
        "    keyboard.wait('esc')\n",
        "\n",
        "listener_thread = threading.Thread(target=keyboard_listener)\n",
        "listener_thread.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Set to pause on next loop\n",
            "Converting speech to text...\n",
            "You said:   Hi, nice to meet you.\n",
            "Chatting...\n",
            "Chatbot:  Hello! It's nice to meet you too. Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. To start off, could you tell me a bit about your experience with machine learning, particularly in areas like model training and optimization?\n",
            "Converting text to speech...\n",
            "Set to continue on next loop\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Set to continue on next loop\n",
            "Set to pause on next loop\n",
            "Converting speech to text...\n",
            "Set to pause on next loop\n",
            "You said:   Yeah, sure. I'd be happy to. I've got some experience in model training and optimization. I've mainly acquired this experience throughout my time at university and through competing in various competitions on Kaggle. Some of those included regression tasks where I trained extra boost algorithms to predict the age of abelones, whatever that is. I've no idea what that is, but yeah. I mean, it didn't really matter to me for the competition, but yeah. Some other ones that I've been involved in is some other stuff, yeah. I get fired immediately. I get sent out.\n",
            "Chatting...\n",
            "Chatbot:  I see. Thank you for sharing that. Could you elaborate a bit more on your experience with specific machine learning libraries or frameworks like PyTorch or NumPy? How have you used these in your projects or competitions?\n",
            "Converting text to speech...\n",
            "Set to continue on next loop\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Set to pause on next loop\n",
            "Converting speech to text...\n",
            "You said:   To be honest, I'm not very sure.\n",
            "Chatting...\n",
            "Chatbot:  I understand. Let's move on to another aspect of the role. The position involves working with large datasets. Could you describe any experience you have in handling and processing large volumes of data, particularly in a machine learning context?\n",
            "Converting text to speech...\n",
            "Set to continue on next loop\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Set to pause on next loop\n",
            "Converting speech to text...\n",
            "You said:   Um, I've never actually done that before.\n",
            "Chatting...\n",
            "Chatbot:  Thank you for your honesty. One last question: This role requires strong programming skills, particularly in Python. Could you tell me about your most challenging Python project and how you approached it?\n",
            "Converting text to speech...\n",
            "Set to pause on next loop\n",
            "Set to continue on next loop\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Set to pause on next loop\n",
            "Converting speech to text...\n",
            "You said:   Yeah, sure, I'd be happy to. I think the most challenging Python project that I've ever done was involving the implementation of NEAT, which is NeuroRevolution of Augmenting Topologies, into a game called Jump King. In a small group I led, we had to essentially implement NeuroRevolution into Jump King. This was quite challenging due to the codebase that we began working with being an open source clone of Jump King, built entirely in Python. So we had to understand the basics of Pygame and how Pygame worked and then work around that to be able to implement NEAT into the game. Implementation of NEAT requires many, many different agents in the game itself. In this case, the individual player character Jump Kings, we had to modify the game's actual architecture to allow for several kings to exist on the screen at once. Once we did that, we then had to tie in the interface with which each king is connected, which is the keyboard inputs into the outputs of neural networks that we had defined using a package that we use called Neat Python. From here we had to... If you just give me a moment to think, sorry. From here we had to then... I'm going blank. I didn't hear what you said. Yeah, no. Okay. Well, oh well.\n",
            "Chatting...\n",
            "Chatbot:  Thank you for sharing that experience. It sounds like an interesting project. I appreciate your time today. We'll be in touch soon regarding the next steps in the application process. Have a great day!\n",
            "Converting text to speech...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     stream_tts(response)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    if not pause_loop:\n",
        "        # --- Record Speech ---\n",
        "        time.sleep(0.1)\n",
        "        print(\"Recording speech...\")\n",
        "        wav_file = record_speech()\n",
        "\n",
        "        # --- Speech to Text ---\n",
        "        print(\"Converting speech to text...\")\n",
        "        text = stt_model.transcribe(wav_file, language=\"en\")\n",
        "        print(\"You said: \", text.get(\"text\"))\n",
        "\n",
        "        # --- Chatbot ---\n",
        "        print(\"Chatting...\")\n",
        "        response = chat_model.chat_with_history_doc(text.get(\"text\"))\n",
        "\n",
        "        print(\"Chatbot: \", response)\n",
        "\n",
        "        # --- Text to Speech ---\n",
        "        print(\"Converting text to speech...\")\n",
        "        stream_tts(response)\n",
        "\n",
        "    else:\n",
        "        time.sleep(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'user', 'content': 'The following is a CV that I am providing you with. You are to keep this document in the back of your mind and consider it or use it, should it be relevant to the discussion.\\n\\n Document below: \\n\\n\\n\\n## Debapratim Kundu \\ndebo121@live.com || E8 E Woolf College, Giles Lane, Canterbury, CT2 7BQ || +44 7393062352 \\nLinkedIn: https://www.linkedin.com/in/debapratim-kundu-95a089183 ||  \\nGit: https://github.com/DKundu121?tab=repositories \\n \\nI am currently pursuing a master’s degree in Artificial Intelligence from the University of Kent. I have \\nover 5 years of experience in designing, developing and maintaining web applications. I have \\nsuccessfully delivered solutions for domains such as e-commerce, finance and retail. I am passionate \\nabout finding insights from data and solving complex problems. I am looking for a challenging and \\nrewarding opportunity to apply the new skills I have picked up and to learn new ones. \\n \\nWORK EXPERIENCE: \\n \\nTCS \\nDeveloper/Tester                                                                                                June 2021 – August 2023\\n\\n\\n## • \\nCollaborated with a cross-functional team to successfully migrate 100% of data belonging to \\nIndian customers to servers within India as part of the India Data Localization initiative.\\n\\n\\n## • \\nImplemented part of EMEA migration of Merchant Risk processes from Mainframe to Java \\nMicroservice to increase efficiency, improve scalability, reduce downtime, and time-to-\\nmarket.\\n\\n\\n## • \\nAchieved Rising Star of the Year award within first year at TCS, demonstrating exceptional \\nperformance and contributing to a 20% increase in team productivity.\\n\\n\\n## ABZOOBA \\nDeveloper/Tester/Deployment                                                                         October 2020 – June 2021\\n\\n\\n## • \\nDeveloped, maintained and deployed the “Performance Management System” for Yum \\nSingapore and Yum India with full customer satisfaction.\\n\\n\\n## • \\nAppointed Database administrator for the same system resulting in a 30% increase in overall \\nresponse time.\\n\\n\\n## ENSIM INDIA (An Ingram Micro Company) \\nDeveloper/Tester                                                                                        October 2017 – October 2020\\n\\n\\n## • \\nRefactored a C++ BSS monolithic application named ODIN to a JAVA microservice.\\n\\n\\n## • \\nDeveloped a Zapier Application for Cloudblue Commerce to communicate between two \\nsystems.\\n\\n\\n## • \\nReceived \"Exceeds Expectation\" rating for consecutive 2 years of employment.\\n\\n\\n## University of Kent \\nPart-Time Receptionist                                                                             September 2023 – August 2024\\n\\n\\n## • \\nConfigured key fobs using Silo/Salto to give access to specific rooms.\\n\\n\\n## • \\nManaged guest booking using Kinetics.\\n\\n\\n## • \\nSolved queries made by guests as and when required.\\n\\n\\n## EDUCATION \\n \\nPostgraduate \\nComputer Science (Artificial Intelligence) \\nUNIVERSITY OF KENT                                                                          September 2023 – August 2024 \\nModules: Systems Architecture, NEAT, AI Systems Implementation, Deep Learning, Reinforcement \\nLearning, Large Language Models, Convolution Neural Networks.\\n\\n\\n## • \\nBeating the game Jump King using NEAT (Neuro Evolution of Augmented Topology).\\n\\n\\n## • \\nThesis project on developing a screening system for candidates by fine-tuning a LLM and \\nusing RAG\\n\\n\\n## Undergraduate \\nBachelor of Technology in Electronics and Communication Engineering  \\nMAULANA ABUL KALAM AZAD UNIVERSITY OF TECHNOLOGY                 June 2013 – July 2017 \\nModules: English Language and Technical Communication, Computer Programming, \\nMicroprocessors and Microcontrollers, Object Oriented Programming, Information Theory and \\nCoding\\n\\n\\n## • \\nGraduated with 72.6% aggregate.\\n\\n\\n## • \\nMember of the official college technical club “XPLORICA” and ECE department technical \\nclub.\\n\\n\\n## Indian School Certificate (ISC) / KS4 \\nSt. Stephen’s School                                                                                            March 2011 – May 2013 \\nModules: English, Mathematics, Physics, Chemistry, Computer Science\\n\\n\\n## • \\nQualified with 86.5% in Computer Science Stream.\\n\\n\\n## Indian Certificate of Secondary Education (ICSE) / KS5 \\nSt. Stephen’s School                                                                                            March 2010 – May 2011 \\nModules:  English, Mathematics, Physics, Chemistry, Computer Science, Biology, History, \\nGeography\\n\\n\\n## • \\nQualified with 91.8% in Computer Science Stream.\\n\\n\\n## SKILLS ACQUIRED \\n \\nProgramming Languages: Java (1.8), Python, Angular, Sql. \\nLibraries: SKlearn, Keras, Pytorch, Vertex, Seaborn. \\nFrameworks: Spring Boot, Spring MVC, Hibernate. \\nDatabases: Postgresql, SQL Server. \\nWeb Technologies: Restful WebServices. \\nTools: Maven, Burp Suite. \\nML Skills: NLP, LLM Fine Tuning, RAG, CNN, NEAT, RNN, LSTM, Data-Visualization, \\nLangchain, LlamaIndiex \\nOther Skills: Microservices, Zapier Integration, Cybersecurity Testing. \\nLanguage: English(Very Good)    Bengali(Very Good)       Hindi(Good) \\n \\nCERTIFICATION/SHORT COURSES\\n\\n\\n## • \\nCompleted project-based microcontroller training, gaining hands-on experience with \\nprogramming and troubleshooting. (CENTRE FOR ELECTRONICS TEST ENGINEERING, \\nGovernment of India)\\n\\n\\n## • \\nReceived training in maintenance and servicing of electronic equipment, gaining experience \\nwith various devices and systems. (AIRPORTS AUTHORITY OF INDIA)\\n\\n\\n## • \\nCertified by Nvidia for “Building Transformer-Based Natural Language Processing \\nApplications”\\n\\n\\n## INTERESTS\\n\\n\\n## • \\nFine Arts (Painting) and recitation: Developed creativity and artistic skills by studying fine \\narts and painting. Gained experience performing in front of others by participating in \\nrecitation competitions. (St. Stephen’s School)\\n\\n\\n## • \\nClassical vocal: Developed musical skills by studying classical vocal music. Gained \\nexperience performing in front of others by participating in musical events. \\n(SWARAMALIKA SANGEET VIDYALAYA)\\n\\n\\n## • \\nDancing: Recently joined the Salsa Society in University of Kent as a beginner.\\n\\n\\n## • \\nSurfing: Recently joined the Surfing Society in the University of Kent as beginner.\\n\\n\\n## • \\nTennis: Recently joined the Tennis club at the University of Kent as a beginner.\\n'}, {'role': 'assistant', 'content': \"Understood! I'll keep this CV in the back of my mind and use it should it be relevant to the discussion.\"}, {'role': 'user', 'content': ' Hi, nice to meet you.'}, {'role': 'assistant', 'content': \"Hello! It's nice to meet you too. Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. To start off, could you tell me a bit about your experience with machine learning, particularly in areas like model training and optimization?\"}, {'role': 'user', 'content': \" Yeah, sure. I'd be happy to. I've got some experience in model training and optimization. I've mainly acquired this experience throughout my time at university and through competing in various competitions on Kaggle. Some of those included regression tasks where I trained extra boost algorithms to predict the age of abelones, whatever that is. I've no idea what that is, but yeah. I mean, it didn't really matter to me for the competition, but yeah. Some other ones that I've been involved in is some other stuff, yeah. I get fired immediately. I get sent out.\"}, {'role': 'assistant', 'content': 'I see. Thank you for sharing that. Could you elaborate a bit more on your experience with specific machine learning libraries or frameworks like PyTorch or NumPy? How have you used these in your projects or competitions?'}, {'role': 'user', 'content': \" To be honest, I'm not very sure.\"}, {'role': 'assistant', 'content': \"I understand. Let's move on to another aspect of the role. The position involves working with large datasets. Could you describe any experience you have in handling and processing large volumes of data, particularly in a machine learning context?\"}, {'role': 'user', 'content': \" Um, I've never actually done that before.\"}, {'role': 'assistant', 'content': 'Thank you for your honesty. One last question: This role requires strong programming skills, particularly in Python. Could you tell me about your most challenging Python project and how you approached it?'}, {'role': 'user', 'content': \" Yeah, sure, I'd be happy to. I think the most challenging Python project that I've ever done was involving the implementation of NEAT, which is NeuroRevolution of Augmenting Topologies, into a game called Jump King. In a small group I led, we had to essentially implement NeuroRevolution into Jump King. This was quite challenging due to the codebase that we began working with being an open source clone of Jump King, built entirely in Python. So we had to understand the basics of Pygame and how Pygame worked and then work around that to be able to implement NEAT into the game. Implementation of NEAT requires many, many different agents in the game itself. In this case, the individual player character Jump Kings, we had to modify the game's actual architecture to allow for several kings to exist on the screen at once. Once we did that, we then had to tie in the interface with which each king is connected, which is the keyboard inputs into the outputs of neural networks that we had defined using a package that we use called Neat Python. From here we had to... If you just give me a moment to think, sorry. From here we had to then... I'm going blank. I didn't hear what you said. Yeah, no. Okay. Well, oh well.\"}, {'role': 'assistant', 'content': \"Thank you for sharing that experience. It sounds like an interesting project. I appreciate your time today. We'll be in touch soon regarding the next steps in the application process. Have a great day!\"}]\n"
          ]
        }
      ],
      "source": [
        "conversation = chat_model.get_message_history()\n",
        "dump(conversation, \"conversation.joblib\")\n",
        "\n",
        "\n",
        "print(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "role: user\n",
            "content: The following is a CV that I am providing you with. You are to keep this document in the back of your mind and consider it or use it, should it be relevant to the discussion.\n",
            "\n",
            " Document below: \n",
            "\n",
            "\n",
            "\n",
            "## Debapratim Kundu \n",
            "debo121@live.com || E8 E Woolf College, Giles Lane, Canterbury, CT2 7BQ || +44 7393062352 \n",
            "LinkedIn: https://www.linkedin.com/in/debapratim-kundu-95a089183 ||  \n",
            "Git: https://github.com/DKundu121?tab=repositories \n",
            " \n",
            "I am currently pursuing a master’s degree in Artificial Intelligence from the University of Kent. I have \n",
            "over 5 years of experience in designing, developing and maintaining web applications. I have \n",
            "successfully delivered solutions for domains such as e-commerce, finance and retail. I am passionate \n",
            "about finding insights from data and solving complex problems. I am looking for a challenging and \n",
            "rewarding opportunity to apply the new skills I have picked up and to learn new ones. \n",
            " \n",
            "WORK EXPERIENCE: \n",
            " \n",
            "TCS \n",
            "Developer/Tester                                                                                                June 2021 – August 2023\n",
            "\n",
            "\n",
            "## • \n",
            "Collaborated with a cross-functional team to successfully migrate 100% of data belonging to \n",
            "Indian customers to servers within India as part of the India Data Localization initiative.\n",
            "\n",
            "\n",
            "## • \n",
            "Implemented part of EMEA migration of Merchant Risk processes from Mainframe to Java \n",
            "Microservice to increase efficiency, improve scalability, reduce downtime, and time-to-\n",
            "market.\n",
            "\n",
            "\n",
            "## • \n",
            "Achieved Rising Star of the Year award within first year at TCS, demonstrating exceptional \n",
            "performance and contributing to a 20% increase in team productivity.\n",
            "\n",
            "\n",
            "## ABZOOBA \n",
            "Developer/Tester/Deployment                                                                         October 2020 – June 2021\n",
            "\n",
            "\n",
            "## • \n",
            "Developed, maintained and deployed the “Performance Management System” for Yum \n",
            "Singapore and Yum India with full customer satisfaction.\n",
            "\n",
            "\n",
            "## • \n",
            "Appointed Database administrator for the same system resulting in a 30% increase in overall \n",
            "response time.\n",
            "\n",
            "\n",
            "## ENSIM INDIA (An Ingram Micro Company) \n",
            "Developer/Tester                                                                                        October 2017 – October 2020\n",
            "\n",
            "\n",
            "## • \n",
            "Refactored a C++ BSS monolithic application named ODIN to a JAVA microservice.\n",
            "\n",
            "\n",
            "## • \n",
            "Developed a Zapier Application for Cloudblue Commerce to communicate between two \n",
            "systems.\n",
            "\n",
            "\n",
            "## • \n",
            "Received \"Exceeds Expectation\" rating for consecutive 2 years of employment.\n",
            "\n",
            "\n",
            "## University of Kent \n",
            "Part-Time Receptionist                                                                             September 2023 – August 2024\n",
            "\n",
            "\n",
            "## • \n",
            "Configured key fobs using Silo/Salto to give access to specific rooms.\n",
            "\n",
            "\n",
            "## • \n",
            "Managed guest booking using Kinetics.\n",
            "\n",
            "\n",
            "## • \n",
            "Solved queries made by guests as and when required.\n",
            "\n",
            "\n",
            "## EDUCATION \n",
            " \n",
            "Postgraduate \n",
            "Computer Science (Artificial Intelligence) \n",
            "UNIVERSITY OF KENT                                                                          September 2023 – August 2024 \n",
            "Modules: Systems Architecture, NEAT, AI Systems Implementation, Deep Learning, Reinforcement \n",
            "Learning, Large Language Models, Convolution Neural Networks.\n",
            "\n",
            "\n",
            "## • \n",
            "Beating the game Jump King using NEAT (Neuro Evolution of Augmented Topology).\n",
            "\n",
            "\n",
            "## • \n",
            "Thesis project on developing a screening system for candidates by fine-tuning a LLM and \n",
            "using RAG\n",
            "\n",
            "\n",
            "## Undergraduate \n",
            "Bachelor of Technology in Electronics and Communication Engineering  \n",
            "MAULANA ABUL KALAM AZAD UNIVERSITY OF TECHNOLOGY                 June 2013 – July 2017 \n",
            "Modules: English Language and Technical Communication, Computer Programming, \n",
            "Microprocessors and Microcontrollers, Object Oriented Programming, Information Theory and \n",
            "Coding\n",
            "\n",
            "\n",
            "## • \n",
            "Graduated with 72.6% aggregate.\n",
            "\n",
            "\n",
            "## • \n",
            "Member of the official college technical club “XPLORICA” and ECE department technical \n",
            "club.\n",
            "\n",
            "\n",
            "## Indian School Certificate (ISC) / KS4 \n",
            "St. Stephen’s School                                                                                            March 2011 – May 2013 \n",
            "Modules: English, Mathematics, Physics, Chemistry, Computer Science\n",
            "\n",
            "\n",
            "## • \n",
            "Qualified with 86.5% in Computer Science Stream.\n",
            "\n",
            "\n",
            "## Indian Certificate of Secondary Education (ICSE) / KS5 \n",
            "St. Stephen’s School                                                                                            March 2010 – May 2011 \n",
            "Modules:  English, Mathematics, Physics, Chemistry, Computer Science, Biology, History, \n",
            "Geography\n",
            "\n",
            "\n",
            "## • \n",
            "Qualified with 91.8% in Computer Science Stream.\n",
            "\n",
            "\n",
            "## SKILLS ACQUIRED \n",
            " \n",
            "Programming Languages: Java (1.8), Python, Angular, Sql. \n",
            "Libraries: SKlearn, Keras, Pytorch, Vertex, Seaborn. \n",
            "Frameworks: Spring Boot, Spring MVC, Hibernate. \n",
            "Databases: Postgresql, SQL Server. \n",
            "Web Technologies: Restful WebServices. \n",
            "Tools: Maven, Burp Suite. \n",
            "ML Skills: NLP, LLM Fine Tuning, RAG, CNN, NEAT, RNN, LSTM, Data-Visualization, \n",
            "Langchain, LlamaIndiex \n",
            "Other Skills: Microservices, Zapier Integration, Cybersecurity Testing. \n",
            "Language: English(Very Good)    Bengali(Very Good)       Hindi(Good) \n",
            " \n",
            "CERTIFICATION/SHORT COURSES\n",
            "\n",
            "\n",
            "## • \n",
            "Completed project-based microcontroller training, gaining hands-on experience with \n",
            "programming and troubleshooting. (CENTRE FOR ELECTRONICS TEST ENGINEERING, \n",
            "Government of India)\n",
            "\n",
            "\n",
            "## • \n",
            "Received training in maintenance and servicing of electronic equipment, gaining experience \n",
            "with various devices and systems. (AIRPORTS AUTHORITY OF INDIA)\n",
            "\n",
            "\n",
            "## • \n",
            "Certified by Nvidia for “Building Transformer-Based Natural Language Processing \n",
            "Applications”\n",
            "\n",
            "\n",
            "## INTERESTS\n",
            "\n",
            "\n",
            "## • \n",
            "Fine Arts (Painting) and recitation: Developed creativity and artistic skills by studying fine \n",
            "arts and painting. Gained experience performing in front of others by participating in \n",
            "recitation competitions. (St. Stephen’s School)\n",
            "\n",
            "\n",
            "## • \n",
            "Classical vocal: Developed musical skills by studying classical vocal music. Gained \n",
            "experience performing in front of others by participating in musical events. \n",
            "(SWARAMALIKA SANGEET VIDYALAYA)\n",
            "\n",
            "\n",
            "## • \n",
            "Dancing: Recently joined the Salsa Society in University of Kent as a beginner.\n",
            "\n",
            "\n",
            "## • \n",
            "Surfing: Recently joined the Surfing Society in the University of Kent as beginner.\n",
            "\n",
            "\n",
            "## • \n",
            "Tennis: Recently joined the Tennis club at the University of Kent as a beginner.\n",
            "\n",
            "--------------------\n",
            "role: assistant\n",
            "content: Understood! I'll keep this CV in the back of my mind and use it should it be relevant to the discussion.\n",
            "--------------------\n",
            "role: user\n",
            "content:  Hi, nice to meet you.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: Hello! It's nice to meet you too. Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. To start off, could you tell me a bit about your experience with machine learning, particularly in areas like model training and optimization?\n",
            "--------------------\n",
            "role: user\n",
            "content:  Yeah, sure. I'd be happy to. I've got some experience in model training and optimization. I've mainly acquired this experience throughout my time at university and through competing in various competitions on Kaggle. Some of those included regression tasks where I trained extra boost algorithms to predict the age of abelones, whatever that is. I've no idea what that is, but yeah. I mean, it didn't really matter to me for the competition, but yeah. Some other ones that I've been involved in is some other stuff, yeah. I get fired immediately. I get sent out.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: I see. Thank you for sharing that. Could you elaborate a bit more on your experience with specific machine learning libraries or frameworks like PyTorch or NumPy? How have you used these in your projects or competitions?\n",
            "--------------------\n",
            "role: user\n",
            "content:  To be honest, I'm not very sure.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: I understand. Let's move on to another aspect of the role. The position involves working with large datasets. Could you describe any experience you have in handling and processing large volumes of data, particularly in a machine learning context?\n",
            "--------------------\n",
            "role: user\n",
            "content:  Um, I've never actually done that before.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: Thank you for your honesty. One last question: This role requires strong programming skills, particularly in Python. Could you tell me about your most challenging Python project and how you approached it?\n",
            "--------------------\n",
            "role: user\n",
            "content:  Yeah, sure, I'd be happy to. I think the most challenging Python project that I've ever done was involving the implementation of NEAT, which is NeuroRevolution of Augmenting Topologies, into a game called Jump King. In a small group I led, we had to essentially implement NeuroRevolution into Jump King. This was quite challenging due to the codebase that we began working with being an open source clone of Jump King, built entirely in Python. So we had to understand the basics of Pygame and how Pygame worked and then work around that to be able to implement NEAT into the game. Implementation of NEAT requires many, many different agents in the game itself. In this case, the individual player character Jump Kings, we had to modify the game's actual architecture to allow for several kings to exist on the screen at once. Once we did that, we then had to tie in the interface with which each king is connected, which is the keyboard inputs into the outputs of neural networks that we had defined using a package that we use called Neat Python. From here we had to... If you just give me a moment to think, sorry. From here we had to then... I'm going blank. I didn't hear what you said. Yeah, no. Okay. Well, oh well.\n",
            "--------------------\n",
            "role: assistant\n",
            "content: Thank you for sharing that experience. It sounds like an interesting project. I appreciate your time today. We'll be in touch soon regarding the next steps in the application process. Have a great day!\n",
            "--------------------\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set to pause on next loop\n",
            "Set to pause on next loop\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from fpdf import FPDF\n",
        "# Function to extract role and content from each turn\n",
        "def parse_turn(turn):\n",
        "    role_match = re.search(r\"role: (.*)\", turn)\n",
        "    content_match = re.search(r\"content: (.*)\", turn, re.DOTALL)\n",
        "\n",
        "    role = role_match.group(1) if role_match else \"\"\n",
        "    content = content_match.group(1).strip() if content_match else turn.strip()\n",
        "\n",
        "    return role, content\n",
        "\n",
        "# Create a list of dictionaries, ea-+-ch representing a turn in the conversation\n",
        "conversation_list = []\n",
        "for turn in conversation.split(\"--------------------\\n\"):\n",
        "    if turn.strip():  # Ignore empty turns\n",
        "        role, content = parse_turn(turn)\n",
        "        #print(content)\n",
        "        if \"Understood! I'll keep this CV in the back of my mind and use it should it be relevant to the discussion.\" not in content and \"The following is a CV that I am providing you with.\" not in content:\n",
        "            conversation_list.append({\"role\": role, \"content\": content})\n",
        "\n",
        "# Create a PDF object\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "\n",
        "# Set margins (in millimeters)\n",
        "pdf.set_margins(left=10, top=20, right=10)  # Right margin set to 10mm \n",
        "\n",
        "# Choose a nicer font\n",
        "pdf.set_font(\"Helvetica\", size=12)\n",
        "\n",
        "# Calculate usable width for text wrapping (accounting for margins)\n",
        "usable_width = pdf.w - pdf.l_margin - pdf.r_margin -0 # 10px right margin \n",
        "\n",
        "# Add conversation to the PDF\n",
        "for turn in conversation_list:\n",
        "    # Skip turns with empty roles or content\n",
        "    if turn['role'] and turn['content']:\n",
        "        # Subheading style for \"User\" and \"Assistant\"\n",
        "        pdf.set_font(\"Helvetica\", style=\"B\", size=14)\n",
        "        pdf.cell(0, 10, txt=f\"{turn['role'].capitalize()}:\", ln=True)\n",
        "\n",
        "        # Content with regular font and correct indentation\n",
        "        pdf.set_font(\"Helvetica\", size=12)\n",
        "        pdf.x = pdf.l_margin  # Reset x-coordinate to the left margin\n",
        "        pdf.multi_cell(usable_width, 6, txt=turn['content'])\n",
        "        pdf.ln(3)\n",
        "\n",
        "# Save the PDF\n",
        "pdf.output(\"conversation.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
