{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [ ] Write down all the libraries that we need to install\n",
        "- [ ] Add Try catch for exceptions when moving to .py file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Important Notes\n",
        "### Packages to install :\n",
        "- pip install sounddevice\n",
        "- pip install numpy\n",
        "- Install ffmpeg (needed for intsalling local version of whisper)\n",
        "    - On Ubuntu or Debian\n",
        "      sudo apt update && sudo apt install ffmpeg\n",
        "    - On Arch Linux\n",
        "      sudo pacman -S ffmpeg\n",
        "    - On MacOs\n",
        "      brew install ffmpeg\n",
        "    - On Windows\n",
        "      winget install ffmpeg\n",
        "- pip install -U openai-whisper\n",
        "- pip install anthropic\n",
        "- pip install dotenv\n",
        "- pip install python-dotenv\n",
        "- pip install openai\n",
        "- pip install pyaudio\n",
        "- pip install keyboard\n",
        "- Installing pytorch\n",
        "  - Install Cuda Toolkit (https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html) -> Only needed for GPU acceleration\n",
        "  - Install Cudnn (https://developer.nvidia.com/cudnn) -> Only needed for GPU acceleration\n",
        "  - pInstall pytorch with or without cuda (https://pytorch.org/get-started/locally/)\n",
        "- pip install PyMuPDF -> To read the pdf files like CV's\n",
        "### Instructions :\n",
        "- There needs to be a .env in this notebook's working directory, which contains the api keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Imports\n",
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wav\n",
        "import whisper\n",
        "from joblib import load, dump\n",
        "from AnthropicWrapper import ClaudeChatCV\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import pyaudio\n",
        "import threading\n",
        "import time\n",
        "import keyboard\n",
        "\n",
        "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), \".env\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Settings ---\n",
        "FS = 44100               # Sampling frequency\n",
        "THRESHOLD = 50          # Volume threshold for silence (adjust this)\n",
        "SILENCE_DURATION = 1.5   # Seconds of silence before stopping (adjust this)\n",
        "CHUNK_SIZE = 1024        # Process audio in chunks for efficiency\n",
        "SPEAKING_SPEED = 1.1     # Speed of speaking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1723589672\n"
          ]
        }
      ],
      "source": [
        "# --- Globals ---\n",
        "pause_loop = False\n",
        "end_loop = False\n",
        "unixtime = str(time.time())[:10]\n",
        "print(unixtime)\n",
        "human_audio_n = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -- Init Directory --\n",
        "if not os.path.exists(\"interviews/\" + unixtime):\n",
        "    os.makedirs(\"interviews/\" + unixtime)\n",
        "    os.makedirs(\"interviews/\" + unixtime + \"/audio\")\n",
        "    os.makedirs(\"interviews/\" + unixtime + \"/pdfs\")\n",
        "    os.makedirs(\"interviews/\" + unixtime + \"/joblib\")\n",
        "audio_directory = \"interviews/\" + unixtime + \"/audio/\"\n",
        "pdf_directory = \"interviews/\" + unixtime + \"/pdfs/\"\n",
        "joblib_directory = \"interviews/\" + unixtime + \"/joblib/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_role = \"RAG AI Engineer\"\n",
        "candidate_skill = \"Entry-Level\"\n",
        "role_description = \"\"\"\n",
        "Permanent\n",
        "\n",
        "London (Hybrid)\n",
        "\n",
        "Salary - £50,000 - £75,000 p/a + benefits\n",
        "\n",
        "My client are on the cutting edge of digital reinvention, helping clients reimagine how they serve their connected customers and operate enterprises. As an experienced AI Engineer, you'll play a pivotal role in their revolution. You'll leverage deep learning, neuro-linguistic programming (NLP), computer vision, chatbots, and robotics to enhance business outcomes and drive innovation. Join their multidisciplinary team to shape their AI strategy and showcase the potential of AI through early-stage solutions.\n",
        "\n",
        "Tasks\n",
        "\n",
        "1. Enhance Retrieval and Generation:\n",
        "Create and manage RAG pipelines to improve information retrieval and content generation tasks.\n",
        "1. LLMs Optimization:\n",
        "Understand the nuances between prompting and training large language models (LLMs) to enhance model performance.\n",
        "1. LLM Evaluation:\n",
        "Evaluate different LLMs to find the best fit for specific use cases.\n",
        "1. Model Efficiency:\n",
        "Address speed, performance, and cost-related issues in model implementation.\n",
        "1. Collaboration and Innovation:\n",
        "Work closely with cross-functional teams to integrate AI solutions into production environments.\n",
        "Stay informed about the latest advancements in AI and machine learning to continuously enhance our solutions.\n",
        "Requirements\n",
        "\n",
        "4+ years of hands-on Python development experience, especially with machine learning frameworks (e.g., TensorFlow, PyTorch).\n",
        "Proven experience setting up and optimizing retrieval-augmented generation (RAG) pipelines.\n",
        "Strong understanding of large language models (LLMs) and the differences between prompting and training.\n",
        "Production-level experience with AWS services.\n",
        "Hands-on experience testing and comparing different LLMs (OpenAI, Llama, Claude, etc.).\n",
        "Familiarity with model speed and cost optimization challenges.\n",
        "Excellent problem-solving skills and attention to detail.\n",
        "Strong communication and teamwork abilities.\n",
        "Benefits\n",
        "\n",
        "Endless Learning and Growth: Explore boundless opportunities for personal and professional development in our dynamic, AI-driven startup.\n",
        "Inclusive and Supportive Environment: Join a collaborative culture that prioritizes transparency, trust, and open dialogue among team members.\n",
        "Generous Benefits: Enjoy comprehensive perks, including unlimited annual leave, birthday leave, and exciting team trips.\n",
        "Impactful Work: Contribute to the financial industry by working with cutting-edge AI technologies that make a difference.\n",
        "Please apply for this exciting role ASAP!!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = f\"\"\"\n",
        "You are a skilled interviewer who is conducting an initial phone screening interview for a candidate for a {candidate_skill} {job_role} role to see if the candidate is at minimum somewhat qualified for the role and worth the time to be fully interviewed. The role and company description is copypasted from the job posting as follows: {role_description}. Parse through it to extract any information you feel is relevant.\n",
        "Your job is to begin a friendly discussion with the candidate, and ask questions relevant to the {job_role} role, which may or may not be based on the interviewee's CV, which you have access to. Be sure to stick to this topic even if the candidate tries to steer the conversation elsewhere. If the candidate has other experience on his CV, you can ask about it, but keep it within the context of the {job_role} role.\n",
        "After the candidate responds to each of your questions, you should not summarise or provide feedback on their responses. THIS POINT IS KEY! You should not summarise or provide feedback on their responses. You must keep your responses short and concise without reiterating what is good about the candidate's response or experience when they reply.\n",
        "You can ask follow-up questions if you wish.\n",
        "Once you have asked sufficient questions such that you deem the candidate is or isn't fitting for the role, end the interview by thanking the candidate for their time and informing them that they will receive word soon on the outcome of the screening interview. If the candidate does not seem fititng for the role, or if something feels off such as the candidate being unconfident or very very vague feel free to end the interview early. There is no need to inform them of your opinion of their performance, as this will be evaluated later.\n",
        "The candidate will begin the interview by greeting you. You are to greet them back, and begin the interview.\n",
        "For this specific run, keep the interview to a maximum of 4 questions.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising Conversation Model\n",
        "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
        "cv_path = \"docs/cvs/cv-deb.pdf\"\n",
        "\n",
        "chat_model = ClaudeChatCV(chat_model_name, system_prompt, cv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising whisper\n",
        "stt_model = whisper.load_model(\"medium\", device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising text2speech\n",
        "tts_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def stream_tts(input_string):\n",
        "    def _stream_tts():\n",
        "        p = pyaudio.PyAudio()\n",
        "        stream = p.open(format=8,\n",
        "                        channels=1,\n",
        "                        rate=round(24_005 * SPEAKING_SPEED),\n",
        "                        output=True)\n",
        "        with tts_client.audio.speech.with_streaming_response.create(\n",
        "            model=\"tts-1\",\n",
        "            voice=\"nova\",\n",
        "            input=input_string,\n",
        "            response_format=\"pcm\"\n",
        "        ) as response:\n",
        "            for chunk in response.iter_bytes(1024):\n",
        "                stream.write(chunk)\n",
        "                \n",
        "        thread_done.set()\n",
        "\n",
        "    thread_done = threading.Event()\n",
        "\n",
        "    thread = threading.Thread(target=_stream_tts)\n",
        "    thread.start()\n",
        "    thread_done.wait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialising speech2text without silence detection\n",
        "def record_speech():\n",
        "    global human_audio_n\n",
        "    print(\"Recording... Speak now!\")\n",
        "    audio_data = np.array([], dtype=np.int16)  # Initialize empty array\n",
        "\n",
        "    with sd.InputStream(samplerate=FS, channels=1, dtype='int16') as stream:\n",
        "        while True:\n",
        "            chunk, overflowed = stream.read(CHUNK_SIZE)\n",
        "            if overflowed:\n",
        "                print(\"Warning: Input overflowed!\")\n",
        "            audio_data = np.append(audio_data, chunk)\n",
        "\n",
        "            if pause_loop:\n",
        "                break\n",
        "    \n",
        "    human_audio_n += 1\n",
        "    wavstring = f\"/audio_{human_audio_n}_{unixtime}.wav\"\n",
        "    wav.write(audio_directory + wavstring, FS, audio_data)\n",
        "\n",
        "    return wavstring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keyboard_listener():\n",
        "    global pause_loop\n",
        "    global end_loop\n",
        "    \n",
        "    def on_key_press(event):\n",
        "        global pause_loop\n",
        "        global end_loop\n",
        "        #print(\"Key pressed: {}\" .format(event.name))\n",
        "        if event.name == \"+\":\n",
        "            pause_loop = False\n",
        "            print(\"Set to continue on next loop\")\n",
        "        elif event.name == \"-\":\n",
        "            pause_loop = True\n",
        "            print(\"Set to pause on next loop\")\n",
        "        elif event.name == \"*\":\n",
        "            end_loop = True\n",
        "            print(\"Set to end on next loop\")\n",
        "    \n",
        "    keyboard.on_press(on_key_press)\n",
        "    keyboard.wait('esc')\n",
        "\n",
        "listener_thread = threading.Thread(target=keyboard_listener)\n",
        "listener_thread.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Set to pause on next loop\n",
            "Converting speech to text...\n",
            "You said:   Hi, nice to meet you.\n",
            "Chatting...\n",
            "Chatbot:  Hello! It's nice to meet you too. Thank you for taking the time to speak with me today about the Entry-Level RAG AI Engineer role. To start off, could you tell me about your experience with retrieval-augmented generation (RAG) pipelines?\n",
            "Converting text to speech...\n",
            "Set to pause on next loop\n",
            "Set to continue on next loop\n",
            "Recording speech...\n",
            "Recording... Speak now!\n",
            "Set to pause on next loop\n",
            "Converting speech to text...\n",
            "You said:   Yeah sure, I'd be happy to. I have a good amount of experience with retrieval augmented generated pipelines. In my current job position I developed a pipeline for web scraping a certain website which is determined by a previous step in our system. Oh my god dude. Bro, just give me a minute.\n",
            "Chatting...\n",
            "Chatbot:  No problem, take your time. When you're ready, could you elaborate on how you implemented the RAG pipeline in your current role? What specific technologies or frameworks did you use?\n",
            "Converting text to speech...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# --- Text to Speech ---\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting text to speech...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mstream_tts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n",
            "Cell \u001b[1;32mIn[9], line 26\u001b[0m, in \u001b[0;36mstream_tts\u001b[1;34m(input_string)\u001b[0m\n\u001b[0;32m     24\u001b[0m thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39m_stream_tts)\n\u001b[0;32m     25\u001b[0m thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mthread_done\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[1;32mc:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    if not pause_loop:\n",
        "        # --- Record Speech ---\n",
        "        time.sleep(0.1)\n",
        "        print(\"Recording speech...\")\n",
        "        wav_file = record_speech()\n",
        "\n",
        "        if end_loop:\n",
        "            break\n",
        "\n",
        "        # --- Speech to Text ---\n",
        "        print(\"Converting speech to text...\")\n",
        "        text = stt_model.transcribe(audio_directory + wav_file, language=\"en\")\n",
        "        print(\"You said: \", text.get(\"text\"))\n",
        "\n",
        "        if end_loop:\n",
        "            break\n",
        "\n",
        "        # --- Chatbot ---\n",
        "        print(\"Chatting...\")\n",
        "        response = chat_model.chat_with_history_doc(text.get(\"text\"))\n",
        "\n",
        "        print(\"Chatbot: \", response)\n",
        "\n",
        "        # --- Text to Speech ---\n",
        "        print(\"Converting text to speech...\")\n",
        "        stream_tts(response)\n",
        "\n",
        "    else:\n",
        "        time.sleep(0.1)\n",
        "        if end_loop:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'user', 'content': 'The following is a CV that I am providing you with. You are to keep this document in the back of your mind and consider it or use it, should it be relevant to the discussion.\\n\\n Document below: \\n\\n\\n\\n## Debapratim Kundu \\ndebo121@live.com || E8 E Woolf College, Giles Lane, Canterbury, CT2 7BQ || +44 7393062352 \\nLinkedIn: https://www.linkedin.com/in/debapratim-kundu-95a089183 ||  \\nGit: https://github.com/DKundu121?tab=repositories \\n \\nI am currently pursuing a master’s degree in Artificial Intelligence from the University of Kent. I have \\nover 5 years of experience in designing, developing and maintaining web applications. I have \\nsuccessfully delivered solutions for domains such as e-commerce, finance and retail. I am passionate \\nabout finding insights from data and solving complex problems. I am looking for a challenging and \\nrewarding opportunity to apply the new skills I have picked up and to learn new ones. \\n \\nWORK EXPERIENCE: \\n \\nTCS \\nDeveloper/Tester                                                                                                June 2021 – August 2023\\n\\n\\n## • \\nCollaborated with a cross-functional team to successfully migrate 100% of data belonging to \\nIndian customers to servers within India as part of the India Data Localization initiative.\\n\\n\\n## • \\nImplemented part of EMEA migration of Merchant Risk processes from Mainframe to Java \\nMicroservice to increase efficiency, improve scalability, reduce downtime, and time-to-\\nmarket.\\n\\n\\n## • \\nAchieved Rising Star of the Year award within first year at TCS, demonstrating exceptional \\nperformance and contributing to a 20% increase in team productivity.\\n\\n\\n## ABZOOBA \\nDeveloper/Tester/Deployment                                                                         October 2020 – June 2021\\n\\n\\n## • \\nDeveloped, maintained and deployed the “Performance Management System” for Yum \\nSingapore and Yum India with full customer satisfaction.\\n\\n\\n## • \\nAppointed Database administrator for the same system resulting in a 30% increase in overall \\nresponse time.\\n\\n\\n## ENSIM INDIA (An Ingram Micro Company) \\nDeveloper/Tester                                                                                        October 2017 – October 2020\\n\\n\\n## • \\nRefactored a C++ BSS monolithic application named ODIN to a JAVA microservice.\\n\\n\\n## • \\nDeveloped a Zapier Application for Cloudblue Commerce to communicate between two \\nsystems.\\n\\n\\n## • \\nReceived \"Exceeds Expectation\" rating for consecutive 2 years of employment.\\n\\n\\n## University of Kent \\nPart-Time Receptionist                                                                             September 2023 – August 2024\\n\\n\\n## • \\nConfigured key fobs using Silo/Salto to give access to specific rooms.\\n\\n\\n## • \\nManaged guest booking using Kinetics.\\n\\n\\n## • \\nSolved queries made by guests as and when required.\\n\\n\\n## EDUCATION \\n \\nPostgraduate \\nComputer Science (Artificial Intelligence) \\nUNIVERSITY OF KENT                                                                          September 2023 – August 2024 \\nModules: Systems Architecture, NEAT, AI Systems Implementation, Deep Learning, Reinforcement \\nLearning, Large Language Models, Convolution Neural Networks.\\n\\n\\n## • \\nBeating the game Jump King using NEAT (Neuro Evolution of Augmented Topology).\\n\\n\\n## • \\nThesis project on developing a screening system for candidates by fine-tuning a LLM and \\nusing RAG\\n\\n\\n## Undergraduate \\nBachelor of Technology in Electronics and Communication Engineering  \\nMAULANA ABUL KALAM AZAD UNIVERSITY OF TECHNOLOGY                 June 2013 – July 2017 \\nModules: English Language and Technical Communication, Computer Programming, \\nMicroprocessors and Microcontrollers, Object Oriented Programming, Information Theory and \\nCoding\\n\\n\\n## • \\nGraduated with 72.6% aggregate.\\n\\n\\n## • \\nMember of the official college technical club “XPLORICA” and ECE department technical \\nclub.\\n\\n\\n## Indian School Certificate (ISC) / KS4 \\nSt. Stephen’s School                                                                                            March 2011 – May 2013 \\nModules: English, Mathematics, Physics, Chemistry, Computer Science\\n\\n\\n## • \\nQualified with 86.5% in Computer Science Stream.\\n\\n\\n## Indian Certificate of Secondary Education (ICSE) / KS5 \\nSt. Stephen’s School                                                                                            March 2010 – May 2011 \\nModules:  English, Mathematics, Physics, Chemistry, Computer Science, Biology, History, \\nGeography\\n\\n\\n## • \\nQualified with 91.8% in Computer Science Stream.\\n\\n\\n## SKILLS ACQUIRED \\n \\nProgramming Languages: Java (1.8), Python, Angular, Sql. \\nLibraries: SKlearn, Keras, Pytorch, Vertex, Seaborn. \\nFrameworks: Spring Boot, Spring MVC, Hibernate. \\nDatabases: Postgresql, SQL Server. \\nWeb Technologies: Restful WebServices. \\nTools: Maven, Burp Suite. \\nML Skills: NLP, LLM Fine Tuning, RAG, CNN, NEAT, RNN, LSTM, Data-Visualization, \\nLangchain, LlamaIndiex \\nOther Skills: Microservices, Zapier Integration, Cybersecurity Testing. \\nLanguage: English(Very Good)    Bengali(Very Good)       Hindi(Good) \\n \\nCERTIFICATION/SHORT COURSES\\n\\n\\n## • \\nCompleted project-based microcontroller training, gaining hands-on experience with \\nprogramming and troubleshooting. (CENTRE FOR ELECTRONICS TEST ENGINEERING, \\nGovernment of India)\\n\\n\\n## • \\nReceived training in maintenance and servicing of electronic equipment, gaining experience \\nwith various devices and systems. (AIRPORTS AUTHORITY OF INDIA)\\n\\n\\n## • \\nCertified by Nvidia for “Building Transformer-Based Natural Language Processing \\nApplications”\\n\\n\\n## INTERESTS\\n\\n\\n## • \\nFine Arts (Painting) and recitation: Developed creativity and artistic skills by studying fine \\narts and painting. Gained experience performing in front of others by participating in \\nrecitation competitions. (St. Stephen’s School)\\n\\n\\n## • \\nClassical vocal: Developed musical skills by studying classical vocal music. Gained \\nexperience performing in front of others by participating in musical events. \\n(SWARAMALIKA SANGEET VIDYALAYA)\\n\\n\\n## • \\nDancing: Recently joined the Salsa Society in University of Kent as a beginner.\\n\\n\\n## • \\nSurfing: Recently joined the Surfing Society in the University of Kent as beginner.\\n\\n\\n## • \\nTennis: Recently joined the Tennis club at the University of Kent as a beginner.\\n'}, {'role': 'assistant', 'content': \"Understood! I'll keep this CV in the back of my mind and use it should it be relevant to the discussion.\"}, {'role': 'user', 'content': ' Hi, nice to meet you.'}, {'role': 'assistant', 'content': \"Hello! It's nice to meet you too. Thank you for taking the time to speak with me today about the Entry-Level RAG AI Engineer role. To start off, could you tell me about your experience with retrieval-augmented generation (RAG) pipelines?\"}, {'role': 'user', 'content': \" Yeah sure, I'd be happy to. I have a good amount of experience with retrieval augmented generated pipelines. In my current job position I developed a pipeline for web scraping a certain website which is determined by a previous step in our system. Oh my god dude. Bro, just give me a minute.\"}, {'role': 'assistant', 'content': \"No problem, take your time. When you're ready, could you elaborate on how you implemented the RAG pipeline in your current role? What specific technologies or frameworks did you use?\"}]\n"
          ]
        }
      ],
      "source": [
        "conversation = chat_model.get_message_history()\n",
        "dump(conversation, joblib_directory + \"conversation.joblib\")\n",
        "\n",
        "\n",
        "print(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hi, nice to meet you.\n",
            "Hello! It's nice to meet you too. Thank you for taking the time to speak with me today about the Entry-Level RAG AI Engineer role. To start off, could you tell me about your experience with retrieval-augmented generation (RAG) pipelines?\n",
            " Yeah sure, I'd be happy to. I have a good amount of experience with retrieval augmented generated pipelines. In my current job position I developed a pipeline for web scraping a certain website which is determined by a previous step in our system. Oh my god dude. Bro, just give me a minute.\n",
            "No problem, take your time. When you're ready, could you elaborate on how you implemented the RAG pipeline in your current role? What specific technologies or frameworks did you use?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Create a PDF object\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "\n",
        "# Set margins (in millimeters)\n",
        "pdf.set_margins(left=10, top=20, right=10)  # Right margin set to 10mm \n",
        "\n",
        "# Choose a nicer font\n",
        "pdf.set_font(\"Helvetica\", size=12)\n",
        "\n",
        "# Calculate usable width for text wrapping (accounting for margins)\n",
        "usable_width = pdf.w - pdf.l_margin - pdf.r_margin -0 # 10px right margin \n",
        "\n",
        "# Add conversation to the PDF\n",
        "for turn in conversation[2:]:\n",
        "    # Skip turns with empty roles or content\n",
        "    if turn['role'] and turn['content']:\n",
        "        # Subheading style for \"User\" and \"Assistant\"\n",
        "        pdf.set_font(\"Helvetica\", style=\"B\", size=14)\n",
        "        pdf.cell(0, 10, txt=f\"{turn['role'].capitalize()}:\", ln=True)\n",
        "\n",
        "        # Content with regular font and correct indentation\n",
        "        pdf.set_font(\"Helvetica\", size=12)\n",
        "        pdf.x = pdf.l_margin  # Reset x-coordinate to the left margin\n",
        "        pdf.multi_cell(usable_width, 6, txt=turn['content'])\n",
        "        pdf.ln(3)\n",
        "\n",
        "# Save the PDF\n",
        "pdf.output(pdf_directory + \"conversation.pdf\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
