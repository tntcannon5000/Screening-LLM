{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import whisper\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pyaudio\n",
    "import threading\n",
    "import time\n",
    "import keyboard\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Settings ---\n",
    "FS = 44100               # Sampling frequency\n",
    "THRESHOLD = 30          # Volume threshold for silence (adjust this)\n",
    "SILENCE_DURATION = 2   # Seconds of silence before stopping (adjust this)\n",
    "CHUNK_SIZE = 1024        # Process audio in chunks for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Globals ---\n",
    "pause_loop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Gemini and ConversationChain\n",
    "chat_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", max_output_tokens=4096)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    memory=ConversationBufferMemory(),\n",
    ")\n",
    "\n",
    "# Initialising whisper\n",
    "model = whisper.load_model(\"base\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising text2speech\n",
    "tts_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def stream_tts(input_string):\n",
    "    def _stream_tts():\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=8,\n",
    "                        channels=1,\n",
    "                        rate=24_000,\n",
    "                        output=True)\n",
    "        with tts_client.audio.speech.with_streaming_response.create(\n",
    "            model=\"tts-1\",\n",
    "            voice=\"nova\",\n",
    "            input=input_string,\n",
    "            response_format=\"pcm\"\n",
    "        ) as response:\n",
    "            for chunk in response.iter_bytes(1024):\n",
    "                stream.write(chunk)\n",
    "                \n",
    "        print(\"FINISHED!!!!!!!!!!!!!!!!!!!!\")\n",
    "        thread_done.set()\n",
    "\n",
    "    thread_done = threading.Event()\n",
    "\n",
    "    thread = threading.Thread(target=_stream_tts)\n",
    "    thread.start()\n",
    "    thread_done.wait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Functions ---\n",
    "def is_silent(data):\n",
    "    rms = np.sqrt(np.mean(data**2))\n",
    "    #print(\"RMS: \", rms)\n",
    "    return rms < THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising speech2text\n",
    "def record_speech():\n",
    "    print(\"Recording... Speak now!\")\n",
    "    audio_data = np.array([], dtype=np.int16)  # Initialize empty array\n",
    "    silent_chunks = 0\n",
    "\n",
    "    with sd.InputStream(samplerate=FS, channels=1, dtype='int16') as stream:\n",
    "        while True:\n",
    "            chunk, overflowed = stream.read(CHUNK_SIZE)\n",
    "            if overflowed:\n",
    "                print(\"Warning: Input overflowed!\")\n",
    "            audio_data = np.append(audio_data, chunk)\n",
    "\n",
    "            if is_silent(chunk):\n",
    "                #print(\"Silent Chunk Detected!!\")\n",
    "                silent_chunks += 1\n",
    "            else:\n",
    "                silent_chunks = 0\n",
    "\n",
    "            if silent_chunks > int(SILENCE_DURATION * FS / CHUNK_SIZE):\n",
    "                #print(\"Silence detected, stopping recording.\")\n",
    "                break\n",
    "    \n",
    "    wav.write(\"g97613g9f0g8.wav\", FS, audio_data)\n",
    "\n",
    "    return \"g97613g9f0g8.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyboard_listener():\n",
    "    global pause_loop\n",
    "    \n",
    "    def on_key_press(event):\n",
    "        global pause_loop\n",
    "        #print(\"Key pressed: {}\" .format(event.name))\n",
    "        if event.name == \"+\":\n",
    "            pause_loop = False\n",
    "            print(\"Set to continue on next loop\")\n",
    "        elif event.name == \"-\":\n",
    "            pause_loop = True\n",
    "            print(\"Set to pause on next loop\")\n",
    "    \n",
    "    keyboard.on_press(on_key_press)\n",
    "    keyboard.wait('esc')\n",
    "\n",
    "listener_thread = threading.Thread(target=keyboard_listener)\n",
    "listener_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording speech...\n",
      "Recording... Speak now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\AppData\\Local\\Temp\\ipykernel_4892\\2817379458.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  rms = np.sqrt(np.mean(data**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set to pause on next loop\n",
      "Converting speech to text...\n",
      "You said:   Hey, when did the iPhone 14 launch?\n",
      "Chatting...\n",
      "Chatbot:  The iPhone 14 was announced on September 7, 2022, and was released on September 16, 2022.  It was the successor to the iPhone 13, and came in four models: iPhone 14, iPhone 14 Plus, iPhone 14 Pro, and iPhone 14 Pro Max.  It featured a new A16 Bionic chip, a new camera system, and a new safety feature called Crash Detection. \n",
      "\n",
      "Converting text to speech...\n",
      "FINISHED!!!!!!!!!!!!!!!!!!!!\n",
      "Set to continue on next loop\n",
      "Recording speech...\n",
      "Recording... Speak now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\AppData\\Local\\Temp\\ipykernel_4892\\2817379458.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  rms = np.sqrt(np.mean(data**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting speech to text...\n",
      "You said:   Yes, pretty cool. So what are the main differences between that and the iPhone 13, for example?\n",
      "Chatting...\n",
      "Chatbot:  The iPhone 14 has a few key differences from the iPhone 13. Here's a breakdown:\n",
      "\n",
      "**Processor:** The iPhone 14 features the new A16 Bionic chip, which is faster and more efficient than the A15 Bionic chip in the iPhone 13.\n",
      "\n",
      "**Camera:** The iPhone 14 has a slightly improved camera system compared to the iPhone 13. It features a new main camera sensor with a larger aperture, which allows for better low-light performance. The iPhone 14 also has a new Photonic Engine that helps improve image quality across all lighting conditions.\n",
      "\n",
      "**Safety Features:** The iPhone 14 introduces a new safety feature called Crash Detection. This feature uses sensors to detect a car crash and automatically contacts emergency services. \n",
      "\n",
      "**Other Differences:**\n",
      "\n",
      "* **iPhone 14 Plus:** This is a new model that was not available in the iPhone 13 lineup. It features a larger 6.7-inch display and a longer battery life.\n",
      "* **Satellite Connectivity:** While not available at launch, the iPhone 14 models include satellite connectivity for emergency SOS messaging, allowing users to send messages even without cellular service.\n",
      "\n",
      "**Similarities:**\n",
      "\n",
      "* **Design:** The iPhone 14 and iPhone 13 have a very similar design. \n",
      "* **Display:** Both models feature a Super Retina XDR display with a notch at the top of the screen.\n",
      "* **Face ID:** Both models use Face ID for authentication.\n",
      "\n",
      "Overall, the iPhone 14 is a modest upgrade over the iPhone 13, with improvements in performance, camera capabilities, and safety features. However, if you're happy with your iPhone 13, the differences might not be significant enough to warrant an upgrade. \n",
      "\n",
      "Converting text to speech...\n",
      "Set to pause on next loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-17 (_stream_tts):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 69, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 113, in __iter__\n",
      "    for part in self._httpcore_stream:\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 367, in __iter__\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 363, in __iter__\n",
      "    for part in self._stream:\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_sync\\http11.py\", line 349, in __iter__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_sync\\http11.py\", line 341, in __iter__\n",
      "    for chunk in self._connection._receive_response_body(**kwargs):\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_sync\\http11.py\", line 210, in _receive_response_body\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_sync\\http11.py\", line 220, in _receive_event\n",
      "    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\niran\\AppData\\Local\\Temp\\ipykernel_4892\\3116854713.py\", line 17, in _stream_tts\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_response.py\", line 351, in iter_bytes\n",
      "    for chunk in self.http_response.iter_bytes(chunk_size):\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_models.py\", line 829, in iter_bytes\n",
      "    for raw_bytes in self.iter_raw():\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_models.py\", line 883, in iter_raw\n",
      "    for raw_stream_bytes in self.stream:\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_client.py\", line 126, in __iter__\n",
      "    for chunk in self._stream:\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 112, in __iter__\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 86, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    if not pause_loop:\n",
    "        # --- Record Speech ---\n",
    "        time.sleep(0.5)\n",
    "        print(\"Recording speech...\")\n",
    "        wav_file = record_speech()\n",
    "\n",
    "        # --- Speech to Text ---\n",
    "        print(\"Converting speech to text...\")\n",
    "        text = model.transcribe(wav_file, language=\"en\")\n",
    "        print(\"You said: \", text.get(\"text\"))\n",
    "\n",
    "        # --- Chatbot ---\n",
    "        print(\"Chatting...\")\n",
    "        response = conversation.invoke(text.get(\"text\"))\n",
    "\n",
    "        response2 = response.get(\"response\")\n",
    "        print(\"Chatbot: \", response2)\n",
    "\n",
    "        # --- Text to Speech ---\n",
    "        print(\"Converting text to speech...\")\n",
    "        stream_tts(response2)\n",
    "\n",
    "    else:\n",
    "        time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
