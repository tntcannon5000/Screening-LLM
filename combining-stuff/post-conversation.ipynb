{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnthropicWrapper import ClaudeChat, ClaudeChatCV\n",
    "from HumeWrapper import HumeSentimentAnalyzer\n",
    "#import conversationVerifier\n",
    "from dotenv import load_dotenv\n",
    "from joblib import load\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Global Variables --\n",
    "chatlog = load('conversation.joblib') # Loading in the list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_chatlog(chatlog):\n",
    "    dropped_context = chatlog[3:]\n",
    "    outputchatlog = []\n",
    "\n",
    "    for i in range(0, len(dropped_context), 2):\n",
    "        # Check if there are enough elements for both interviewer and candidate\n",
    "        if i + 1 < len(dropped_context):\n",
    "            tempdict = {\n",
    "                'interviewer': dropped_context[i]['content'],\n",
    "                'candidate': dropped_context[i+1]['content']\n",
    "            }\n",
    "\n",
    "            outputchatlog.append(tempdict)\n",
    "        else:\n",
    "            # Handle the case where the last turn is only from the interviewer\n",
    "            tempdict = {\n",
    "                'interviewer': dropped_context[i]['content'],\n",
    "                'candidate': ''  # Or any other suitable placeholder\n",
    "            }\n",
    "            outputchatlog.append(tempdict)\n",
    "            break  # Stop the loop since we've reached the end\n",
    "\n",
    "    return outputchatlog\n",
    "\n",
    "chatlog_chat = reformat_chatlog(chatlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'interviewer': \"Hello! It's nice to meet you too. Thank you for taking the time to speak with me today about the Entry-Level Machine Learning Engineer position at G-Research. To start off, could you tell me a bit about your experience with machine learning, particularly in areas like model training and optimization?\", 'candidate': \" Yeah, sure. I'd be happy to. I've got some experience in model training and optimization. I've mainly acquired this experience throughout my time at university and through competing in various competitions on Kaggle. Some of those included regression tasks where I trained extra boost algorithms to predict the age of abelones, whatever that is. I've no idea what that is, but yeah. I mean, it didn't really matter to me for the competition, but yeah. Some other ones that I've been involved in is some other stuff, yeah. I get fired immediately. I get sent out.\"}\n",
      "{'interviewer': 'I see. Thank you for sharing that. Could you elaborate a bit more on your experience with specific machine learning libraries or frameworks like PyTorch or NumPy? How have you used these in your projects or competitions?', 'candidate': \" To be honest, I'm not very sure.\"}\n",
      "{'interviewer': \"I understand. Let's move on to another aspect of the role. The position involves working with large datasets. Could you describe any experience you have in handling and processing large volumes of data, particularly in a machine learning context?\", 'candidate': \" Um, I've never actually done that before.\"}\n",
      "{'interviewer': 'Thank you for your honesty. One last question: This role requires strong programming skills, particularly in Python. Could you tell me about your most challenging Python project and how you approached it?', 'candidate': \" Yeah, sure, I'd be happy to. I think the most challenging Python project that I've ever done was involving the implementation of NEAT, which is NeuroRevolution of Augmenting Topologies, into a game called Jump King. In a small group I led, we had to essentially implement NeuroRevolution into Jump King. This was quite challenging due to the codebase that we began working with being an open source clone of Jump King, built entirely in Python. So we had to understand the basics of Pygame and how Pygame worked and then work around that to be able to implement NEAT into the game. Implementation of NEAT requires many, many different agents in the game itself. In this case, the individual player character Jump Kings, we had to modify the game's actual architecture to allow for several kings to exist on the screen at once. Once we did that, we then had to tie in the interface with which each king is connected, which is the keyboard inputs into the outputs of neural networks that we had defined using a package that we use called Neat Python. From here we had to... If you just give me a moment to think, sorry. From here we had to then... I'm going blank. I didn't hear what you said. Yeah, no. Okay. Well, oh well.\"}\n",
      "{'interviewer': \"Thank you for sharing that experience. It sounds like an interesting project. I appreciate your time today. We'll be in touch soon regarding the next steps in the application process. Have a great day!\", 'candidate': ''}\n"
     ]
    }
   ],
   "source": [
    "for item in chatlog_chat:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv_path = os.path.join(os.path.dirname(os.getcwd()), \".env\")\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the Sentiment Analyser\n",
    "sentiment_analyser = HumeSentimentAnalyzer(os.getenv(\"HUME_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Sentiment Summariser\n",
    "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "system_prompt = \"\"\"You are a skilled emotions analyst provided with a detailed breakdown of sentiment analysis scores from Hume.ai, for a single response in an interview to a question from the interviewer. The scores are split into 3 sections. All numbers are from 0 to 1, linearly scaling, with 1 being a very strong representation of the indicator in question.\n",
    "\n",
    "First, Emotions. This contains several human emotions with a numerical value indicating the strength of the corresponding emotion.\n",
    "Second, Sentiments. This contains a scale from 1 to 9, each containing a numerical value indicating the magnitude of the sentiment of the topic of the conversation. A negative topic such as murder will have a high value lower in the scale, such as 1 or 2, and a positive topic will have a high value from 0 to 1 higher in the scale such as 8 or 9.\n",
    "Third, Toxicity. This contains several toxic representations such as hate, insult, etc, with a value from 0 to 1 for each representation identified in the audio.\n",
    "\n",
    "Your job is to provide a concise detailed one sentence breakdown of how the individual was feeling for the particular scores provided. You must be highly objective as your job is to discern whether or not a candidate was exhibiting traits which would or would not be fitting for a successful interview. \n",
    "Model your answer beginning with something along the lines of \"For this particular response, the candidate...\".\n",
    "\"\"\"\n",
    "\n",
    "sentiment_analyser = ClaudeChat(chat_model_name, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising verifier\n",
    "#inaccuracies = conversationVerifier.process_qa_pair(chatlog[3], chatlog[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Evaluation LLM\n",
    "\n",
    "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "system_prompt = \"Claude, write me a sonnet about the beauty of the universe.\"\n",
    "\n",
    "sentiment_analyser = ClaudeChatCV(chat_model_name, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sentiment_analyser.analyze_audio(os.path.join(script_directory, \"interview_audio.wav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
