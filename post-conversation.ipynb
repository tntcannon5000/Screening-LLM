{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.anthropicwrapper import ClaudeChat, ClaudeChatAssess, ClaudeChatHistory\n",
    "from src.utils.humewrapper import HumeSentimentAnalyzer\n",
    "from src.modules import ConversationVerifier\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from joblib import load\n",
    "from pprint import pprint\n",
    "import traceback\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Global Variables --\n",
    "timestamp = 1723758342\n",
    "directory = f'data/interviews/{timestamp}/'\n",
    "chatlog = load(os.path.join(directory, \"joblib/conversation.joblib\")) # Loading in the list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'interviewer': \"Hello! It's nice to meet you too. Thank you for taking the time to speak with me today about the Entry-Level RAG AI Engineer role. To start off, could you tell me about your experience with retrieval-augmented generation (RAG) pipelines?\", 'candidate': \" Yeah sure, I'd be happy to. I do have some experience with these. I have built a web scraping pipeline before which scrapes the web and puts all the information that is gathered into a very relevant query into the Chroma Vectorize database and then uses an in-banks model to get a similarity between the input tokens and the Vectorize database to then figure out what sections of the database are relevant and to put that into the context window of the LLM allowing the LLM to respond using information obtained from the web that was scraped.\"}\n",
      "{'interviewer': \"That's interesting. Can you elaborate on how you handled the efficiency and performance aspects of this RAG pipeline, particularly in terms of speed and cost optimization?\", 'candidate': \" Sure, yeah. So mainly when it comes to speed, there's two variables that I can mainly play with to increase the performance of the entire system. The first one is when actually conducting the web scraping, ensuring that the web scraping is done entirely in parallel. So this involves generating all the list of queries and then sending off the requests using threads and then waiting for all the threads to be rejoined back and then just making a list of all the retrieved data by this appending onto that list and then from there onwards you can continue processing. And the second one is to generate the relevant search query. You can use a cheaper model instead of like a very large expensive LLM. So for example, I could use Gemini 1.5 Flash instead of Gemini 1.5 Pro, which is a smaller and cheaper model to run, which also saves in terms of the cost.\"}\n",
      "{'interviewer': \"Thank you for that explanation. Moving on, could you describe your experience with different large language models (LLMs)? Have you worked with or compared models like OpenAI's GPT, Llama, or Claude?\", 'candidate': \" Yep, I have got some experience when it comes to these different language models. There is a lot of differences between these three models and the aforementioned Google Gemini. For example, Llama is open source, which means I can download it and run it locally or run it online and host it. But because it's open source, I'm not tied down explicitly to open AI terms of service, nor am I tied down to having to run my code on open AI servers. So if my application is strongly tied to security, that would be a good example. An alternative would be to use, for example, something like Google Gemini, which has some benefits over Llama and OpenAI's chat GPT, in that it has a much larger context window of 1 million tokens. So if there is a vast amount of data that I need to run and process all at once, I can fit all that into the context window, such as frame-by-frame analysis of an entire movie, for example, that would be possible inside of Gemini, that would not be possible in cloud or GPT.\"}\n",
      "{'interviewer': 'I see. For our final question, how would you approach integrating an AI solution, specifically a RAG system, into a production environment? What considerations would you keep in mind?', 'candidate': \" Sure, there are several considerations that I have to keep in mind. For example, if I'm deploying a large language model for users to use, they may attempt to prompt engineer it themselves, which is actually a surprisingly intuitive thing for regular people to try to do, by asking it to do other things or telling it to ignore its instructions and then do something else, etc. So that would be a consideration that I'd have to keep in mind. When it comes to RAG systems, if the user is feeding in documents into the system, I would need to keep in mind the fact that users will only be restricted to only submitting a certain type of documents or appropriate documents that is fitting to what the purpose is of our system. And so there'd have to be some pre-processing to all the input documents that is being provided. That's about the two biggest ones, but there's definitely some more as well that don't immediately come to mind.\"}\n",
      "{'interviewer': \"Thank you for your time and responses. We appreciate you taking part in this screening interview for the Entry-Level RAG AI Engineer role. You'll be hearing from us soon regarding the outcome of this interview. Have a great day!\", 'candidate': 'Thank you, goodbye'}\n"
     ]
    }
   ],
   "source": [
    "def reformat_chatlog(chatlog):\n",
    "    dropped_context = chatlog[3:]\n",
    "    outputchatlog = []\n",
    "\n",
    "    for i in range(0, len(dropped_context), 2):\n",
    "        if i + 1 < len(dropped_context):\n",
    "            tempdict = {\n",
    "                'interviewer': dropped_context[i]['content'],\n",
    "                'candidate': dropped_context[i+1]['content']\n",
    "            }\n",
    "\n",
    "            outputchatlog.append(tempdict)\n",
    "        else:\n",
    "            tempdict = {\n",
    "                'interviewer': dropped_context[i]['content'],\n",
    "                'candidate': 'Thank you, goodbye'  \n",
    "            }\n",
    "            outputchatlog.append(tempdict)\n",
    "            break \n",
    "\n",
    "    return outputchatlog\n",
    "\n",
    "chatlog_chat = reformat_chatlog(chatlog)\n",
    "for item in chatlog_chat:\n",
    "   print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the Sentiment Analyser\n",
    "sentiment_analyser = HumeSentimentAnalyzer(api_key=os.getenv(\"HUME_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Sentiment Summariser\n",
    "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "system_prompt = \"\"\"You are a skilled emotions analyst provided with a detailed breakdown of sentiment analysis scores from Hume.ai, for a single response in an interview to a question from the interviewer. The scores are split into 3 sections. All numbers are from 0 to 1, linearly scaling, with 1 being a very strong representation of the indicator in question.\n",
    "\n",
    "First, Emotions. This contains several human emotions with a numerical value indicating the strength of the corresponding emotion.\n",
    "Second, Sentiments. This contains a scale from 1 to 9, each containing a numerical value indicating the magnitude of the sentiment of the topic of the conversation. A negative topic such as murder will have a high value lower in the scale, such as 1 or 2, and a positive topic will have a high value from 0 to 1 higher in the scale such as 8 or 9.\n",
    "Third, Toxicity. This contains several toxic representations such as hate, insult, etc, with a value from 0 to 1 for each representation identified in the audio.\n",
    "\n",
    "Your job is to provide a concise detailed one sentence breakdown of how the individual was feeling for the particular scores provided. You must be highly objective as your job is to discern whether or not a candidate was exhibiting traits which would or would not be fitting for a successful interview. \n",
    "Model your answer beginning with something along the lines of \"For this particular response, the candidate...\".\n",
    "\"\"\"\n",
    "\n",
    "sentiment_summariser = ClaudeChat(chat_model_name, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Evaluation LLM\n",
    "chat_model_name = \"claude-3-5-sonnet-20240620\"\n",
    "system_prompt = \"\"\"You are a highly skilled interviewer currently tasked with reviewing a phone screening interview candidate to decide whether they are to pass on to the next stage of the interview process. There is a high volume of candidates and as such, the percentage of candidates allowed to pass should be 47%\n",
    "You will be provided with the following information to aid your decision:\n",
    "1. A copy of the job description.\n",
    "2. Transcript of the phone interview between the interviewer and candidate.\n",
    "3. Sentiment analysis summary to provide you with insight into the tone of the candidate in the call\n",
    "4. A summary of any factual inaccuracies the candidate may have made during discussions in the call\n",
    "5. A copy of the candidate's CV, which will be provided next.\n",
    "\n",
    "You are to evaluate the candidate, primarily on the transcript, and use the additional information provided to identify any potential red-flags. Your response should include a detailed breakdown of why the candidate is chosen to continue onwards to further interviewing. You must end the breakdown with a simple one word response on a new line, \"pass\" or \"fail\".\"\"\"\n",
    "\n",
    "pdf_path = \"data/cvs/cv-deb.pdf\"\n",
    "candidate_evaluator = ClaudeChatAssess(chat_model_name, system_prompt, pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected IDs to be a non-empty list, got 0 IDs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mConversationVerifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_qa_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchatlog_chat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Hidden Desktop\\OneDrive\\Cross Device\\Work\\Project\\Code\\Screening-LLM\\src\\modules\\ConversationVerifier.py:56\u001b[0m, in \u001b[0;36mprocess_qa_pair\u001b[1;34m(chat_log)\u001b[0m\n\u001b[0;32m     51\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter\u001b[38;5;241m.\u001b[39mfrom_tiktoken_encoder(\n\u001b[0;32m     52\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, \n\u001b[0;32m     53\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     54\u001b[0m )\n\u001b[0;32m     55\u001b[0m splits \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents)\n\u001b[1;32m---> 56\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Accuracy checking template\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\niran\\miniconda3\\envs\\disso\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:878\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    876\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    877\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\niran\\miniconda3\\envs\\disso\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:842\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    836\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[0;32m    837\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[0;32m    838\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    839\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    840\u001b[0m         )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 842\u001b[0m     \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[1;32mc:\\Users\\niran\\miniconda3\\envs\\disso\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:326\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[0;32m    321\u001b[0m             embeddings\u001b[38;5;241m=\u001b[39membeddings_without_metadatas,\n\u001b[0;32m    322\u001b[0m             documents\u001b[38;5;241m=\u001b[39mtexts_without_metadatas,\n\u001b[0;32m    323\u001b[0m             ids\u001b[38;5;241m=\u001b[39mids_without_metadatas,\n\u001b[0;32m    324\u001b[0m         )\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "File \u001b[1;32mc:\\Users\\niran\\miniconda3\\envs\\disso\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:296\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert\u001b[39m(\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    267\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    278\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     (\n\u001b[0;32m    291\u001b[0m         ids,\n\u001b[0;32m    292\u001b[0m         embeddings,\n\u001b[0;32m    293\u001b[0m         metadatas,\n\u001b[0;32m    294\u001b[0m         documents,\n\u001b[0;32m    295\u001b[0m         uris,\n\u001b[1;32m--> 296\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_upsert_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_upsert(\n\u001b[0;32m    301\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    302\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m         uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[0;32m    307\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\niran\\miniconda3\\envs\\disso\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:525\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_upsert_request\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_and_prepare_upsert_request\u001b[39m(\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    500\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     Optional[URIs],\n\u001b[0;32m    517\u001b[0m ]:\n\u001b[0;32m    518\u001b[0m     (\n\u001b[0;32m    519\u001b[0m         ids,\n\u001b[0;32m    520\u001b[0m         embeddings,\n\u001b[0;32m    521\u001b[0m         metadatas,\n\u001b[0;32m    522\u001b[0m         documents,\n\u001b[0;32m    523\u001b[0m         images,\n\u001b[0;32m    524\u001b[0m         uris,\n\u001b[1;32m--> 525\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\niran\\miniconda3\\envs\\disso\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:173\u001b[0m, in \u001b[0;36mCollectionCommon._validate_embedding_set\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_embedding_set\u001b[39m(\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    153\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m     Optional[URIs],\n\u001b[0;32m    172\u001b[0m ]:\n\u001b[1;32m--> 173\u001b[0m     valid_ids \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_cast_one_to_many_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     valid_embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    175\u001b[0m         validate_embeddings(\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    181\u001b[0m     valid_metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    182\u001b[0m         validate_metadatas(maybe_cast_one_to_many_metadata(metadatas))\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\niran\\miniconda3\\envs\\disso\\Lib\\site-packages\\chromadb\\api\\types.py:248\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[1;34m(ids)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ids)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a non-empty list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    250\u001b[0m dups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got 0 IDs"
     ]
    }
   ],
   "source": [
    "e = ConversationVerifier.process_qa_pair(chatlog_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filepath\n",
    "filepath = f'data/interviews/{timestamp}/audio'\n",
    "\n",
    "# Get all files in the filepath\n",
    "files = [f for f in os.listdir(filepath) if os.path.isfile(os.path.join(filepath, f))]\n",
    "\n",
    "if len(chatlog_chat) < len(files):\n",
    "    files = files[:len(chatlog_chat)]\n",
    "\n",
    "# Loop through each file\n",
    "sentiments = []\n",
    "for count, file in enumerate(files, 1):\n",
    "    # Print the file name\n",
    "    print(os.path.join(filepath, str(file)))\n",
    "    result = sentiment_analyser.analyze_audio(os.path.join(filepath, str(file)))\n",
    "    sentiment_summary = sentiment_summariser.chat(str(result))\n",
    "    sentiments.append((result, sentiment_summary))\n",
    "    chatlog_chat[count-1]['sentiment'] = sentiment_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(chatlog_chat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Analysing the post-conversation to make a decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = candidate_evaluator.chat(str(chatlog_chat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(chatlog_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pprint(evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
