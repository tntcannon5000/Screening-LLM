{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Required Packages if you don't have them:\n",
    "# !pip install python-dotenv joblib anthropic hume-api\n",
    "\n",
    "# Import Statements\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from joblib import load\n",
    "from pprint import pprint\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "# Custom Modules (Assuming these are in your project structure)\n",
    "from src.utils.anthropicwrapper import ClaudeChat, ClaudeChatAssess\n",
    "from src.utils.humewrapper import HumeSentimentAnalyzer\n",
    "from src.modules import ConversationVerifier\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/interviews/1725232852/joblib/conversation.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# --- Load Data ---\u001b[39;00m\n\u001b[0;32m      8\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/interviews/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 9\u001b[0m chatlog \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjoblib/conversation.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\debo1\\miniconda3\\envs\\disso\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/interviews/1725232852/joblib/conversation.joblib'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Load Environment Variables ---\n",
    "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), \".env\"))\n",
    "\n",
    "# --- Timestamp Input ---\n",
    "timestamp = 1725232852  # Example timestamp, replace with your input \n",
    "\n",
    "# --- Load Data ---\n",
    "directory = f'data/interviews/{timestamp}/'\n",
    "chatlog = load(os.path.join(directory, \"joblib/conversation.joblib\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing PDF: no such file: 'data/cvs/cv-deb.pdf'\n"
     ]
    }
   ],
   "source": [
    "# --- Model Setup --- \n",
    "try:\n",
    "    sentiment_analyser = HumeSentimentAnalyzer(api_key=os.getenv(\"HUME_API_KEY\"))\n",
    "\n",
    "    sentiment_system_prompt = \"\"\"You are a skilled emotions analyst provided with a detailed breakdown of sentiment analysis scores from Hume.ai, for a single response in an interview to a question from the interviewer. The scores are split into 3 sections. All numbers are from 0 to 1, linearly scaling, with 1 being a very strong representation of the indicator in question.\n",
    "\n",
    "    First, Emotions. This contains several human emotions with a numerical value indicating the strength of the corresponding emotion.\n",
    "    Second, Sentiments. This contains a scale from 1 to 9, each containing a numerical value indicating the magnitude of the sentiment of the topic of the conversation. A negative topic such as murder will have a high value lower in the scale, such as 1 or 2, and a positive topic will have a high value from 0 to 1 higher in the scale such as 8 or 9.\n",
    "    Third, Toxicity. This contains several toxic representations such as hate, insult, etc, with a value from 0 to 1 for each representation identified in the audio.\n",
    "\n",
    "    Your job is to provide a concise detailed one sentence breakdown of how the individual was feeling for the particular scores provided. You must be highly objective as your job is to discern whether or not a candidate was exhibiting traits which would or would not be fitting for a successful interview. \n",
    "    Model your answer beginning with something along the lines of \"For this particular response, the candidate...\"\"\"\n",
    "    \n",
    "    sentiment_summariser = ClaudeChat(\"claude-3-5-sonnet-20240620\", sentiment_system_prompt)\n",
    "\n",
    "    evaluation_system_prompt = \"\"\"You are a highly skilled interviewer currently tasked with reviewing a phone screening interview candidate to decide whether they are to pass on to the next stage of the interview process. There is a high volume of candidates and as such only 47% of candidates should be allowed to pass.\n",
    "    You will be provided with the following information to aid your decision:\n",
    "    1. A copy of the job description.\n",
    "    2. Transcript of the phone interview between the interviewer and candidate.\n",
    "    3. Sentiment analysis summary to provide you with insight into the tone of the candidate in the call\n",
    "    4. A summary of any factual inaccuracies the candidate may have made during discussions in the call\n",
    "    5. A copy of the candidate's CV, which will be provided next.\n",
    "\n",
    "    You are to evaluate the candidate, primarily on the transcript, and use the additional information provided to identify any potential red-flags. Your response should include a detailed breakdown of why the candidate is chosen to continue onwards to further interviewing. You must end the breakdown with a simple one word response on a new line, \"pass\" or \"fail\".\"\"\"\n",
    "\n",
    "    candidate_evaluator = ClaudeChatAssess(\"claude-3-5-sonnet-20240620\", evaluation_system_prompt, \"data/cvs/cv-deb.pdf\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model setup: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reformat Chatlog ---\n",
    "def reformat_chatlog(chatlog):\n",
    "    dropped_context = chatlog[3:]\n",
    "    outputchatlog = []\n",
    "\n",
    "    for i in range(0, len(dropped_context), 2):\n",
    "        if i + 1 < len(dropped_context):\n",
    "            tempdict = {\n",
    "                'interviewer': dropped_context[i]['content'],\n",
    "                'candidate': dropped_context[i+1]['content']\n",
    "            }\n",
    "            outputchatlog.append(tempdict)\n",
    "        else:\n",
    "            break \n",
    "            \n",
    "    return outputchatlog\n",
    "\n",
    "# --- Process Sentiments ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentiments(chatlog_chat, timestamp):\n",
    "    filepath = os.path.join('data', 'interviews', str(timestamp), 'audio')\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Full audio directory path: {os.path.abspath(filepath)}\")\n",
    "\n",
    "    files = [f for f in os.listdir(filepath) if os.path.isfile(os.path.join(filepath, f))]\n",
    "    \n",
    "    if len(chatlog_chat) < len(files):\n",
    "        files = files[:len(chatlog_chat)]\n",
    "\n",
    "    for f in files:\n",
    "        print(f\"File found: {f}\")\n",
    "\n",
    "    sentiments = []\n",
    "    \n",
    "    for count, file in enumerate(files, 1):\n",
    "        full_file_path = os.path.join(filepath, file)\n",
    "        print(f\"Processing file: {full_file_path}\")\n",
    "        \n",
    "        # Add a small delay and re-check file existence\n",
    "        time.sleep(0.1)\n",
    "        if not os.path.exists(full_file_path):\n",
    "            print(f\"File not found (after delay): {full_file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = sentiment_analyser.analyze_audio(full_file_path)\n",
    "            sentiment_summary = sentiment_summariser.chat(str(result))\n",
    "            sentiments.append((result, sentiment_summary))\n",
    "            chatlog_chat[count-1]['sentiment'] = sentiment_summary\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {full_file_path}: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    return chatlog_chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate Candidate --- \n",
    "def evaluate_candidate(chatlog_chat):\n",
    "    ConversationVerifier.process_qa_pair(chatlog_chat)\n",
    "    print(\"The Feedback JSON from the sentiment analyser and accuracy verifier: \\n\")\n",
    "    pprint(chatlog_chat)\n",
    "    evaluation = candidate_evaluator.chat(str(chatlog_chat))\n",
    "    return evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------1725380720-0------------------------\n",
      "Current working directory: d:\\Kent\\University Of Kent UK\\Projects\\Disso\\Screening-LLM\n",
      "Full audio directory path: d:\\Kent\\University Of Kent UK\\Projects\\Disso\\Screening-LLM\\data\\interviews\\1725380720\\audio\n",
      "attempting to generate searc queries from answers\n",
      "Warning: No documents were split. The retriever will be empty.\n",
      "No documents retrieved from webscrapping \n",
      "\n",
      "Feedback is being returned from accuracy verifier\n",
      "The Feedback JSON from the sentiment analyser and accuracy verifier: \n",
      "\n",
      "[]\n",
      "---------------------------1725380720-0------------------------\n"
     ]
    }
   ],
   "source": [
    "    # --- Main Execution Flow ---\n",
    "for i in range(1):\n",
    "        print(f'---------------------------{timestamp}-{i}------------------------')\n",
    "        chatlog_chat = reformat_chatlog(chatlog)  # Process the loaded chatlog\n",
    "        chatlog_chat = process_sentiments(chatlog_chat, timestamp) # Analyze sentiments\n",
    "\n",
    "        #chatlog_chat_copy = chatlog_chat[1]\n",
    "        evaluation = evaluate_candidate(chatlog_chat) # Get the final evaluation\n",
    "\n",
    "\n",
    "        chatlog_file_path = f\"data/interviews/{timestamp}-{i}/outcome/\"\n",
    "\n",
    "        if not os.path.exists(chatlog_file_path):\n",
    "            os.makedirs(chatlog_file_path)\n",
    "\n",
    "        with open(chatlog_file_path+\"chatlog.json\", \"w\") as file:\n",
    "            json.dump(chatlog_chat, file, indent=4)\n",
    "        evaluation_file_path = f\"data/interviews/{timestamp}-{i}/outcome/\"\n",
    "        if not os.path.exists(chatlog_file_path):\n",
    "            os.makedirs(chatlog_file_path)\n",
    "        with open(evaluation_file_path+\"evaluation.txt\", \"w\") as file:\n",
    "            file.write(str(evaluation).replace(\"\\\\n\", \"\\n\"))\n",
    "        print(f'---------------------------{timestamp}-{i}------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------1725236280------------------------\n",
      "Current working directory: d:\\Kent\\University Of Kent UK\\Projects\\Disso\\Screening-LLM\n",
      "Full audio directory path: d:\\Kent\\University Of Kent UK\\Projects\\Disso\\Screening-LLM\\data\\interviews\\1725236280\\audio\n",
      "File found: audio_1_1725236280.wav\n",
      "Processing file: data\\interviews\\1725236280\\audio\\audio_1_1725236280.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing audio file: data\\interviews\\1725236280\\audio\\audio_1_1725236280.wav\n",
      "File exists: True\n",
      "Job submitted successfully\n",
      "Job completed\n",
      "[{'source': {'type': 'file', 'filename': 'audio_1_1725236280.wav', 'content_type': 'audio/wav', 'md5sum': '64933daa432855048bca1d9b44268a8b'}, 'results': {'predictions': [{'file': 'audio_1_1725236280.wav', 'file_type': 'audio', 'models': {'language': {'metadata': {'confidence': 0.79833984, 'detected_language': 'hi'}, 'grouped_predictions': [{'id': 'unknown', 'predictions': [{'text': 'Hello.', 'position': {'begin': 0, 'end': 6}, 'time': {'begin': 0.62, 'end': 0.74}, 'confidence': 0.99072266, 'speaker_confidence': None, 'emotions': [{'name': 'Admiration', 'score': 0.01251170877367258}, {'name': 'Adoration', 'score': 0.008131410926580429}, {'name': 'Aesthetic Appreciation', 'score': 0.016512403264641762}, {'name': 'Amusement', 'score': 0.0907270684838295}, {'name': 'Anger', 'score': 0.0005581923178397119}, {'name': 'Annoyance', 'score': 0.014846810139715672}, {'name': 'Anxiety', 'score': 0.0011913252528756857}, {'name': 'Awe', 'score': 0.008423087187111378}, {'name': 'Awkwardness', 'score': 0.06354702264070511}, {'name': 'Boredom', 'score': 0.10851363092660904}, {'name': 'Calmness', 'score': 0.31933408975601196}, {'name': 'Concentration', 'score': 0.016252553090453148}, {'name': 'Confusion', 'score': 0.029891543090343475}, {'name': 'Contemplation', 'score': 0.02187623828649521}, {'name': 'Contempt', 'score': 0.018504859879612923}, {'name': 'Contentment', 'score': 0.08336649090051651}, {'name': 'Craving', 'score': 0.0006236955523490906}, {'name': 'Desire', 'score': 0.000760009977966547}, {'name': 'Determination', 'score': 0.0022584907710552216}, {'name': 'Disappointment', 'score': 0.0025702782440930605}, {'name': 'Disapproval', 'score': 0.007185309659689665}, {'name': 'Disgust', 'score': 0.0015889910282567143}, {'name': 'Distress', 'score': 0.0006113385898061097}, {'name': 'Doubt', 'score': 0.00666783144697547}, {'name': 'Ecstasy', 'score': 0.0021341179963201284}, {'name': 'Embarrassment', 'score': 0.0033599617891013622}, {'name': 'Empathic Pain', 'score': 0.0008289636461995542}, {'name': 'Enthusiasm', 'score': 0.09442762285470963}, {'name': 'Entrancement', 'score': 0.006641392130404711}, {'name': 'Envy', 'score': 0.0008029191521927714}, {'name': 'Excitement', 'score': 0.05306636542081833}, {'name': 'Fear', 'score': 0.00027591444086283445}, {'name': 'Gratitude', 'score': 0.010404795408248901}, {'name': 'Guilt', 'score': 0.00038117836811579764}, {'name': 'Horror', 'score': 0.00014820862270426005}, {'name': 'Interest', 'score': 0.22310522198677063}, {'name': 'Joy', 'score': 0.08868356049060822}, {'name': 'Love', 'score': 0.005399726331233978}, {'name': 'Nostalgia', 'score': 0.004958468955010176}, {'name': 'Pain', 'score': 0.00010659849067451432}, {'name': 'Pride', 'score': 0.0036682302597910166}, {'name': 'Realization', 'score': 0.053931184113025665}, {'name': 'Relief', 'score': 0.0077752480283379555}, {'name': 'Romance', 'score': 0.001546808984130621}, {'name': 'Sadness', 'score': 0.0003105304786004126}, {'name': 'Sarcasm', 'score': 0.025866815820336342}, {'name': 'Satisfaction', 'score': 0.05627468600869179}, {'name': 'Shame', 'score': 0.0010352996177971363}, {'name': 'Surprise (negative)', 'score': 0.017590997740626335}, {'name': 'Surprise (positive)', 'score': 0.1599823534488678}, {'name': 'Sympathy', 'score': 0.002042335458099842}, {'name': 'Tiredness', 'score': 0.004060816951096058}, {'name': 'Triumph', 'score': 0.00503922114148736}], 'sentiment': [{'name': '1', 'score': 0.0005626916536130011}, {'name': '2', 'score': 0.0006312259938567877}, {'name': '3', 'score': 0.0011379551142454147}, {'name': '4', 'score': 0.0038008831907063723}, {'name': '5', 'score': 0.36965522170066833}, {'name': '6', 'score': 0.2254335731267929}, {'name': '7', 'score': 0.13478495180606842}, {'name': '8', 'score': 0.11552125215530396}, {'name': '9', 'score': 0.11766091734170914}], 'toxicity': [{'name': 'identity_hate', 'score': 0.002974089467898011}, {'name': 'insult', 'score': 0.0027754041366279125}, {'name': 'obscene', 'score': 0.002369341906160116}, {'name': 'severe_toxic', 'score': 0.0023268223740160465}, {'name': 'threat', 'score': 0.002879881300032139}, {'name': 'toxic', 'score': 0.006132675334811211}]}]}]}}}], 'errors': []}}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m chatlog_chat \u001b[38;5;241m=\u001b[39m reformat_chatlog(chatlog)  \u001b[38;5;66;03m# Process the loaded chatlog\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m chatlog_chat \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_sentiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchatlog_chat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Analyze sentiments\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#chatlog_chat_copy = chatlog_chat[1]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m evaluate_candidate(chatlog_chat) \u001b[38;5;66;03m# Get the final evaluation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m, in \u001b[0;36mprocess_sentiments\u001b[1;34m(chatlog_chat, timestamp)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     result \u001b[38;5;241m=\u001b[39m sentiment_analyser\u001b[38;5;241m.\u001b[39manalyze_audio(full_file_path)\n\u001b[1;32m---> 28\u001b[0m     sentiment_summary \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_summariser\u001b[49m\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;28mstr\u001b[39m(result))\n\u001b[0;32m     29\u001b[0m     sentiments\u001b[38;5;241m.\u001b[39mappend((result, sentiment_summary))\n\u001b[0;32m     30\u001b[0m     chatlog_chat[count\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sentiment_summary\n",
      "File \u001b[1;32mc:\\Users\\debo1\\miniconda3\\envs\\disso\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:1197\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_line:\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_suspend(thread, step_cmd, original_step_cmd\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mpydev_original_step_cmd)\n\u001b[1;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_return:  \u001b[38;5;66;03m# return event\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m     back \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[1;32mc:\\Users\\debo1\\miniconda3\\envs\\disso\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\debo1\\miniconda3\\envs\\disso\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\debo1\\miniconda3\\envs\\disso\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'---------------------------{timestamp}------------------------')\n",
    "chatlog_chat = reformat_chatlog(chatlog)  # Process the loaded chatlog\n",
    "chatlog_chat = process_sentiments(chatlog_chat, timestamp) # Analyze sentiments\n",
    "\n",
    "#chatlog_chat_copy = chatlog_chat[1]\n",
    "evaluation = evaluate_candidate(chatlog_chat) # Get the final evaluation\n",
    "\n",
    "\n",
    "chatlog_file_path = f\"data/interviews/{timestamp}/outcome/\"\n",
    "\n",
    "if not os.path.exists(chatlog_file_path):\n",
    "    os.makedirs(chatlog_file_path)\n",
    "\n",
    "with open(chatlog_file_path+\"chatlog.json\", \"w\") as file:\n",
    "    json.dump(chatlog_chat, file, indent=4)\n",
    "evaluation_file_path = f\"data/interviews/{timestamp}/outcome/\"\n",
    "if not os.path.exists(chatlog_file_path):\n",
    "    os.makedirs(chatlog_file_path)\n",
    "with open(evaluation_file_path+\"evaluation.txt\", \"w\") as file:\n",
    "    file.write(str(evaluation).replace(\"\\\\n\", \"\\n\"))\n",
    "print(f'---------------------------{timestamp}------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatlog_chat = [\n",
    "    {\n",
    "        \"interviewer\": \"Hello! Thank you for taking the time to speak with me today about the Entry Level RAG Engineer position. I'd like to ask you a few questions to learn more about your experience and skills. Could you tell me about your experience with retrieval-augmented generation (RAG) pipelines?\",\n",
    "        \"candidate\": \" Yes, sure. I have some experience in retrieval of augmented generation pipelines. Mainly I used RAG to do my final thesis project, which is an automated screening system. I used RAG for the verification process to put up-to-date information from the internet in the context of an LLM so that it can verify all the information that is available currently.\",\n",
    "        \"sentiment\": \"For this particular response, the candidate exhibited a balanced mix of emotions, with notable levels of calmness (0.32), interest (0.22), and positive surprise (0.16), alongside moderate levels of boredom (0.11) and enthusiasm (0.09), suggesting an engaged yet somewhat reserved demeanor during the interview.\",\n",
    "        \"feedback\": \"The candidate is well versed in all aspects of the question asked\"\n",
    "    },\n",
    "    {\n",
    "        \"interviewer\": \"That's interesting. Can you elaborate on the specific challenges you faced while implementing RAG in your thesis project, and how you overcame them?\",\n",
    "        \"candidate\": \" Sure, so breaking down a candidate's answer into queries wasn't my first approach. I couldn't find a way to break down the answer or like provide a search query for getting information on the relevant topics and then through query decomposition I got relevant answers like by breaking down the string into sub queries and then searching for it. That expanded the search space so that is how I solved it.\",\n",
    "        \"sentiment\": \"For this particular response, the candidate exhibited a high level of concentration (0.70) and determination (0.39), coupled with significant feelings of triumph (0.47) and satisfaction (0.35), suggesting a focused and confident demeanor during the interview, while maintaining a generally neutral sentiment (0.89 in sentiment level 5) and showing no signs of toxicity, which are all positive indicators for a successful interview performance.\",\n",
    "        \"feedback\": \"The candidate is well versed in all aspects of the question asked\"\n",
    "    },\n",
    "    {\n",
    "        \"interviewer\": \"Thank you for sharing that. Moving on, can you describe your experience with different large language models (LLMs) and how you've compared their performance for specific tasks?\",\n",
    "        \"candidate\": \" I'm sure I've worked with JadGPT, Claude, Sonnet and Lama. I would rank them as Claude Sonnet is the highest for reasoning, JadGPT comes in second and Lama comes in third.\",\n",
    "        \"sentiment\": \"For this particular response, the candidate exhibited a high level of concentration (0.39) and satisfaction (0.40), coupled with moderate levels of calmness (0.20) and contentment (0.19), suggesting a focused and positive demeanor during the interview, while also displaying some interest (0.15) and determination (0.15) which are favorable traits in an interview setting.\",\n",
    "        \"feedback\": \"The candidate is well versed in all aspects of the question asked\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------1725380262-rec-man-pass------------------------\n"
     ]
    }
   ],
   "source": [
    "timestamp = \"1725380262-rec-man-pass\"\n",
    "#evaluation = evaluate_candidate(chatlog_chat) # Get the final evaluation\n",
    "evaluation = candidate_evaluator.chat(str(chatlog_chat))\n",
    "    \n",
    "chatlog_file_path = f\"data/interviews/{timestamp}/outcome/\"\n",
    "\n",
    "if not os.path.exists(chatlog_file_path):\n",
    "    os.makedirs(chatlog_file_path)\n",
    "\n",
    "with open(chatlog_file_path+\"chatlog.json\", \"w\") as file:\n",
    "    json.dump(chatlog_chat, file, indent=4)\n",
    "evaluation_file_path = f\"data/interviews/{timestamp}/outcome/\"\n",
    "if not os.path.exists(chatlog_file_path):\n",
    "    os.makedirs(chatlog_file_path)\n",
    "with open(evaluation_file_path+\"evaluation.txt\", \"w\") as file:\n",
    "    file.write(str(evaluation).replace(\"\\\\n\", \"\\n\"))\n",
    "print(f'---------------------------{timestamp}------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
